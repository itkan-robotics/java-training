{
  "title": "Machine Learning Integration",
  "sections": [
    {
      "type": "text",
      "title": "What is Advanced Machine Learning Integration?",
      "content": "Advanced machine learning integration goes beyond basic TensorFlow Lite usage to create sophisticated, custom ML solutions tailored specifically for FTC robotics applications. This involves developing custom models, optimizing inference performance, and creating robust ML pipelines that can handle the unique challenges of robotics environments.<br><br>Advanced ML integration is essential when you need:<br>• Custom models trained specifically for your game elements<br>• Real-time inference with minimal latency<br>• Complex multi-object detection and classification<br>• Integration with other robot subsystems<br>• Robust performance in varying lighting and field conditions<br>• Continuous learning and model improvement"
    },
    {
      "type": "rules-box",
      "title": "Advanced ML Integration Capabilities",
      "items": [
        "Custom model development and training",
        "Real-time inference optimization",
        "Multi-model ensemble systems",
        "Continuous learning and adaptation",
        "Advanced preprocessing and post-processing",
        "Integration with sensor fusion systems"
      ]
    },
    {
      "type": "text",
      "title": "Advanced ML Model Integration",
      "content": "Advanced ML model integration involves creating sophisticated systems that can handle multiple models, complex preprocessing, and intelligent decision-making based on ML outputs.<br><br><strong>Model Ensembles:</strong> Combining multiple models for improved accuracy<br><strong>Multi-Stage Processing:</strong> Using different models for different tasks<br><strong>Model Switching:</strong> Dynamically selecting models based on conditions<br><strong>Advanced Preprocessing:</strong> Sophisticated image preparation for ML models<br><strong>Post-Processing:</strong> Intelligent interpretation of model outputs<br><strong>Model Optimization:</strong> Techniques for faster inference and lower resource usage"
    },
    {
      "type": "text",
      "title": "Advanced ML Model Integration System Setup",
      "content": "Let's create an advanced ML integration system that can handle multiple models, intelligent preprocessing, and sophisticated post-processing. For more on TensorFlow Lite integration, see <a href=\"https://www.tensorflow.org/lite/examples\" target=\"_blank\">TensorFlow Lite Examples</a>."
    },
    {
      "type": "code",
      "title": "Import Statements and Class Definition",
      "content": "Import necessary TensorFlow Lite classes and define the advanced ML integration system class.",
      "code": "import org.firstinspires.ftc.vision.VisionPortal;\nimport org.firstinspires.ftc.vision.tfod.TfodProcessor;\nimport org.firstinspires.ftc.vision.tfod.Recognition;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.util.HashMap;\n\npublic class AdvancedMLIntegrationSystem {\n    private VisionPortal visionPortal;\n    private Map<String, TfodProcessor> models = new HashMap<>();\n    private MLPreprocessor preprocessor;\n    private MLPostProcessor postprocessor;\n    private ModelSelector modelSelector;\n    \n    // Model configuration\n    private static final String GAME_ELEMENT_MODEL = \"game_elements.tflite\";\n    private static final String OBSTACLE_MODEL = \"obstacles.tflite\";\n    private static final String FIELD_FEATURE_MODEL = \"field_features.tflite\";\n    \n    // Processing parameters\n    private static final float MIN_CONFIDENCE = 0.6f;\n    private static final int MAX_DETECTIONS = 20;\n    private static final boolean ENABLE_TRACKING = true;\n    // ..."
    },
    {
      "type": "text",
      "title": "System Initialization",
      "content": "Initialize the advanced ML integration system with multiple models and processors."
    },
    {
      "type": "code",
      "title": "Constructor and Initialization Methods",
      "content": "Initialize the system with multiple models and build the vision portal.",
      "code": "    public AdvancedMLIntegrationSystem() {\n        initializeModels();\n        initializeProcessors();\n        buildVisionPortal();\n    }\n    \n    private void initializeModels() {\n        // Game element detection model\n        TfodProcessor gameElementModel = new TfodProcessor.Builder()\n            .setModelFileName(GAME_ELEMENT_MODEL)\n            .setModelLabels(new String[]{\n                \"red_cone\", \"blue_cone\", \"green_cone\", \n                \"yellow_cone\", \"orange_cone\", \"purple_cone\",\n                \"red_pixel\", \"blue_pixel\", \"green_pixel\",\n                \"yellow_pixel\", \"white_pixel\"\n            })\n            .setIsModelTensorFlow2(true)\n            .setIsModelQuantized(true)\n            .setModelInputSize(320)\n            .setModelAspectRatio(1.0)\n            .setMinResultConfidence(MIN_CONFIDENCE)\n            .setMaxNumRecognitions(MAX_DETECTIONS)\n            .setUseObjectTracker(ENABLE_TRACKING)\n            .build();\n        \n        models.put(\"game_elements\", gameElementModel);\n    }"
    },
    {
      "type": "text",
      "title": "Additional Model Initialization",
      "content": "Initialize obstacle detection and field feature detection models."
    },
    {
      "type": "code",
      "title": "Obstacle and Field Feature Models",
      "content": "Set up obstacle detection and field feature detection models with appropriate parameters.",
      "code": "        // Obstacle detection model\n        TfodProcessor obstacleModel = new TfodProcessor.Builder()\n            .setModelFileName(OBSTACLE_MODEL)\n            .setModelLabels(new String[]{\n                \"wall\", \"robot\", \"game_element\", \"field_boundary\"\n            })\n            .setIsModelTensorFlow2(true)\n            .setIsModelQuantized(true)\n            .setModelInputSize(256)\n            .setModelAspectRatio(1.0)\n            .setMinResultConfidence(0.5f)\n            .setMaxNumRecognitions(10)\n            .build();\n        \n        // Field feature detection model\n        TfodProcessor fieldFeatureModel = new TfodProcessor.Builder()\n            .setModelFileName(FIELD_FEATURE_MODEL)\n            .setModelLabels(new String[]{\n                \"scoring_zone\", \"start_position\", \"finish_line\",\n                \"power_shot_target\", \"high_goal\", \"low_goal\"\n            })\n            .setIsModelTensorFlow2(true)\n            .setIsModelQuantized(true)\n            .setModelInputSize(416)\n            .setModelAspectRatio(16.0 / 9.0)\n            .setMinResultConfidence(0.7f)\n            .setMaxNumRecognitions(5)\n            .build();\n        \n        models.put(\"obstacles\", obstacleModel);\n        models.put(\"field_features\", fieldFeatureModel);\n    }"
    },
    {
      "type": "text",
      "title": "Processor and Vision Portal Setup",
      "content": "Initialize preprocessing and postprocessing components and build the vision portal."
    },
    {
      "type": "code",
      "title": "Processor Initialization and Vision Portal Setup",
      "content": "Set up processors and build the vision portal with all models.",
      "code": "    private void initializeProcessors() {\n        preprocessor = new MLPreprocessor();\n        postprocessor = new MLPostProcessor();\n        modelSelector = new ModelSelector();\n    }\n    \n    private void buildVisionPortal() {\n        VisionPortal.Builder builder = new VisionPortal.Builder()\n            .setCamera(hardwareMap.get(WebcamName.class, \"Webcam 1\"))\n            .setCameraResolution(new Size(640, 480))\n            .setStreamFormat(VisionPortal.StreamFormat.YUY2)\n            .enableLiveView(true)\n            .enableCameraMonitoring(true);\n        \n        // Add all models to Vision Portal\n        for (TfodProcessor model : models.values()) {\n            builder.addProcessor(model);\n        }\n        \n        visionPortal = builder.build();\n    }"
    },
    {
      "type": "text",
      "title": "Main Processing Method",
      "content": "The processFrame method orchestrates the entire ML processing pipeline, from detection to result analysis."
    },
    {
      "type": "code",
      "title": "processFrame Method",
      "content": "Process frame through all models and return comprehensive results.",
      "code": "    public MLResults processFrame() {\n        MLResults results = new MLResults();\n        \n        // Get detections from all models\n        Map<String, List<Recognition>> allDetections = new HashMap<>();\n        for (Map.Entry<String, TfodProcessor> entry : models.entrySet()) {\n            String modelName = entry.getKey();\n            TfodProcessor model = entry.getValue();\n            List<Recognition> detections = model.getRecognitions();\n            allDetections.put(modelName, detections);\n        }\n        \n        // Preprocess detections\n        Map<String, List<ProcessedDetection>> processedDetections = \n            preprocessor.processDetections(allDetections);\n        \n        // Post-process and analyze results\n        results = postprocessor.analyzeResults(processedDetections);\n        \n        // Update model selector with current results\n        modelSelector.updateModelPerformance(results);\n        \n        return results;\n    }"
    },
    {
      "type": "text",
      "title": "Dynamic Optimization",
      "content": "The optimizeForCurrentConditions method dynamically adjusts model parameters based on field conditions."
    },
    {
      "type": "code",
      "title": "optimizeForCurrentConditions Method",
      "content": "Dynamically adjust model parameters based on current field conditions.",
      "code": "    public void optimizeForCurrentConditions(FieldConditions conditions) {\n        // Dynamically adjust model parameters based on conditions\n        for (TfodProcessor model : models.values()) {\n            // Adjust confidence thresholds based on lighting\n            float adjustedConfidence = conditions.getLightingLevel() > 0.7f ? \n                MIN_CONFIDENCE : MIN_CONFIDENCE * 0.8f;\n            \n            // Adjust processing parameters based on conditions\n            if (conditions.isHighSpeedMode()) {\n                // Reduce processing for speed\n                model.setMaxNumRecognitions(5);\n            } else {\n                // Full processing for accuracy\n                model.setMaxNumRecognitions(MAX_DETECTIONS);\n            }\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Supporting Classes - MLResults and GameElement",
      "content": "Define supporting classes for storing ML results and game element information."
    },
    {
      "type": "code",
      "title": "MLResults and GameElement Classes",
      "content": "Define classes for storing ML processing results and game element data.",
      "code": "    // Supporting classes\n    public static class MLResults {\n        public List<GameElement> gameElements = new ArrayList<>();\n        public List<Obstacle> obstacles = new ArrayList<>();\n        public List<FieldFeature> fieldFeatures = new ArrayList<>();\n        public double overallConfidence = 0.0;\n        public long processingTime = 0;\n        public String recommendedAction = \"\";\n    }\n    \n    public static class GameElement {\n        public String type;\n        public Point2D position;\n        public double confidence;\n        public double distance;\n        public String color;\n        \n        public GameElement(String type, Point2D position, double confidence, \n                          double distance, String color) {\n            this.type = type;\n            this.position = position;\n            this.confidence = confidence;\n            this.distance = distance;\n            this.color = color;\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Supporting Classes - Obstacle and FieldFeature",
      "content": "Define classes for obstacle and field feature information."
    },
    {
      "type": "code",
      "title": "Obstacle and FieldFeature Classes",
      "content": "Define classes for storing obstacle and field feature data.",
      "code": "    public static class Obstacle {\n        public String type;\n        public Point2D position;\n        public double confidence;\n        public double size;\n        public boolean isAvoidable;\n        \n        public Obstacle(String type, Point2D position, double confidence, \n                       double size, boolean isAvoidable) {\n            this.type = type;\n            this.position = position;\n            this.confidence = confidence;\n            this.size = size;\n            this.isAvoidable = isAvoidable;\n        }\n    }\n    \n    public static class FieldFeature {\n        public String type;\n        public Point2D position;\n        public double confidence;\n        public String description;\n        \n        public FieldFeature(String type, Point2D position, double confidence, \n                           String description) {\n            this.type = type;\n            this.position = position;\n            this.confidence = confidence;\n            this.description = description;\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Utility Classes",
      "content": "Define utility classes for 2D points and field conditions."
    },
    {
      "type": "code",
      "title": "Point2D and FieldConditions Classes",
      "content": "Define utility classes for 2D coordinates and field condition tracking.",
      "code": "    public static class Point2D {\n        public double x, y;\n        \n        public Point2D(double x, double y) {\n            this.x = x;\n            this.y = y;\n        }\n    }\n    \n    public static class FieldConditions {\n        public double lightingLevel;\n        public boolean isHighSpeedMode;\n        public String currentGamePhase;\n        \n        public FieldConditions(double lightingLevel, boolean isHighSpeedMode, \n                              String currentGamePhase) {\n            this.lightingLevel = lightingLevel;\n            this.isHighSpeedMode = isHighSpeedMode;\n            this.currentGamePhase = currentGamePhase;\n        }\n        \n        public double getLightingLevel() { return lightingLevel; }\n        public boolean isHighSpeedMode() { return isHighSpeedMode; }\n        public String getCurrentGamePhase() { return currentGamePhase; }\n    }\n}"
    },
    {
      "type": "text",
      "title": "ML Preprocessor Class",
      "content": "The MLPreprocessor class handles sophisticated preprocessing of raw ML detections."
    },
    {
      "type": "code",
      "title": "MLPreprocessor Class Definition",
      "content": "Define the ML preprocessing class for handling raw detections.",
      "code": "// Preprocessing class\nclass MLPreprocessor {\n    public Map<String, List<ProcessedDetection>> processDetections(\n            Map<String, List<Recognition>> rawDetections) {\n        Map<String, List<ProcessedDetection>> processed = new HashMap<>();\n        \n        for (Map.Entry<String, List<Recognition>> entry : rawDetections.entrySet()) {\n            String modelName = entry.getKey();\n            List<Recognition> detections = entry.getValue();\n            \n            List<ProcessedDetection> processedList = new ArrayList<>();\n            for (Recognition detection : detections) {\n                ProcessedDetection processedDetection = processDetection(detection, modelName);\n                if (processedDetection != null) {\n                    processedList.add(processedDetection);\n                }\n            }\n            \n            processed.put(modelName, processedList);\n        }\n        \n        return processed;\n    }"
    },
    {
      "type": "text",
      "title": "Detection Processing Methods",
      "content": "The processDetection method routes detections to model-specific processing methods."
    },
    {
      "type": "code",
      "title": "processDetection Method",
      "content": "Route detections to appropriate model-specific processing methods.",
      "code": "    private ProcessedDetection processDetection(Recognition detection, String modelName) {\n        // Apply model-specific processing\n        switch (modelName) {\n            case \"game_elements\":\n                return processGameElement(detection);\n            case \"obstacles\":\n                return processObstacle(detection);\n            case \"field_features\":\n                return processFieldFeature(detection);\n            default:\n                return new ProcessedDetection(detection, modelName);\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Game Element Processing",
      "content": "The processGameElement method extracts color information and estimates distance for game elements."
    },
    {
      "type": "code",
      "title": "processGameElement Method",
      "content": "Process game element detections to extract color and distance information.",
      "code": "    private ProcessedDetection processGameElement(Recognition detection) {\n        // Extract color information from label\n        String label = detection.getLabel();\n        String color = extractColorFromLabel(label);\n        \n        // Calculate distance based on object size\n        double distance = estimateDistance(detection.getArea());\n        \n        return new ProcessedDetection(detection, \"game_elements\", color, distance);\n    }"
    },
    {
      "type": "text",
      "title": "Obstacle and Field Feature Processing",
      "content": "Process obstacle and field feature detections with appropriate information extraction."
    },
    {
      "type": "code",
      "title": "Obstacle and Field Feature Processing Methods",
      "content": "Process obstacle and field feature detections with specific information extraction.",
      "code": "    private ProcessedDetection processObstacle(Recognition detection) {\n        // Determine if obstacle is avoidable\n        boolean isAvoidable = !detection.getLabel().equals(\"wall\");\n        \n        // Calculate obstacle size\n        double size = Math.sqrt(detection.getArea());\n        \n        return new ProcessedDetection(detection, \"obstacles\", isAvoidable, size);\n    }\n    \n    private ProcessedDetection processFieldFeature(Recognition detection) {\n        // Add descriptive information for field features\n        String description = getFieldFeatureDescription(detection.getLabel());\n        \n        return new ProcessedDetection(detection, \"field_features\", description);\n    }"
    },
    {
      "type": "text",
      "title": "Helper Methods",
      "content": "Helper methods for color extraction, distance estimation, and field feature description."
    },
    {
      "type": "code",
      "title": "Helper Methods for Processing",
      "content": "Helper methods for extracting color, estimating distance, and getting field feature descriptions.",
      "code": "    private String extractColorFromLabel(String label) {\n        if (label.contains(\"red\")) return \"red\";\n        if (label.contains(\"blue\")) return \"blue\";\n        if (label.contains(\"green\")) return \"green\";\n        if (label.contains(\"yellow\")) return \"yellow\";\n        if (label.contains(\"orange\")) return \"orange\";\n        if (label.contains(\"purple\")) return \"purple\";\n        if (label.contains(\"white\")) return \"white\";\n        return \"unknown\";\n    }\n    \n    private double estimateDistance(double area) {\n        // Simple distance estimation based on object area\n        // This would need calibration for your specific setup\n        return 1000.0 / Math.sqrt(area);\n    }\n    \n    private String getFieldFeatureDescription(String label) {\n        switch (label) {\n            case \"scoring_zone\": return \"Area where game elements can be scored\";\n            case \"start_position\": return \"Robot starting position\";\n            case \"finish_line\": return \"End of autonomous period marker\";\n            case \"power_shot_target\": return \"High-value scoring target\";\n            case \"high_goal\": return \"High scoring goal\";\n            case \"low_goal\": return \"Low scoring goal\";\n            default: return \"Unknown field feature\";\n        }\n    }\n}"
    },
    {
      "type": "text",
      "title": "ML Post-Processor Class",
      "content": "The MLPostProcessor class handles intelligent analysis and interpretation of processed detections."
    },
    {
      "type": "code",
      "title": "MLPostProcessor Class Definition",
      "content": "Define the ML post-processing class for analyzing processed detections.",
      "code": "// Post-processing class\nclass MLPostProcessor {\n    public AdvancedMLIntegrationSystem.MLResults analyzeResults(\n            Map<String, List<ProcessedDetection>> processedDetections) {\n        \n        AdvancedMLIntegrationSystem.MLResults results = \n            new AdvancedMLIntegrationSystem.MLResults();\n        \n        // Process game elements\n        List<ProcessedDetection> gameElements = \n            processedDetections.getOrDefault(\"game_elements\", new ArrayList<>());\n        for (ProcessedDetection detection : gameElements) {\n            AdvancedMLIntegrationSystem.GameElement element = \n                new AdvancedMLIntegrationSystem.GameElement(\n                    detection.recognition.getLabel(),\n                    new AdvancedMLIntegrationSystem.Point2D(\n                        detection.recognition.getLeft() + detection.recognition.getWidth() / 2,\n                        detection.recognition.getTop() + detection.recognition.getHeight() / 2\n                    ),\n                    detection.recognition.getConfidence(),\n                    detection.distance,\n                    detection.color\n                );\n            results.gameElements.add(element);\n        }\n        \n        // Process obstacles\n        List<ProcessedDetection> obstacles = \n            processedDetections.getOrDefault(\"obstacles\", new ArrayList<>());\n        for (ProcessedDetection detection : obstacles) {\n            AdvancedMLIntegrationSystem.Obstacle obstacle = \n                new AdvancedMLIntegrationSystem.Obstacle(\n                    detection.recognition.getLabel(),\n                    new AdvancedMLIntegrationSystem.Point2D(\n                        detection.recognition.getLeft() + detection.recognition.getWidth() / 2,\n                        detection.recognition.getTop() + detection.recognition.getHeight() / 2\n                    ),\n                    detection.recognition.getConfidence(),\n                    detection.size,\n                    detection.isAvoidable\n                );\n            results.obstacles.add(obstacle);\n        }\n        \n        // Process field features\n        List<ProcessedDetection> fieldFeatures = \n            processedDetections.getOrDefault(\"field_features\", new ArrayList<>());\n        for (ProcessedDetection detection : fieldFeatures) {\n            AdvancedMLIntegrationSystem.FieldFeature feature = \n                new AdvancedMLIntegrationSystem.FieldFeature(\n                    detection.recognition.getLabel(),\n                    new AdvancedMLIntegrationSystem.Point2D(\n                        detection.recognition.getLeft() + detection.recognition.getWidth() / 2,\n                        detection.recognition.getTop() + detection.recognition.getHeight() / 2\n                    ),\n                    detection.recognition.getConfidence(),\n                    detection.description\n                );\n            results.fieldFeatures.add(feature);\n        }\n        \n        // Calculate overall confidence\n        results.overallConfidence = calculateOverallConfidence(processedDetections);\n        \n        // Generate recommended action\n        results.recommendedAction = generateRecommendedAction(results);\n        \n        return results;\n    }\n    \n    private double calculateOverallConfidence(\n            Map<String, List<ProcessedDetection>> processedDetections) {\n        double totalConfidence = 0.0;\n        int totalDetections = 0;\n        \n        for (List<ProcessedDetection> detections : processedDetections.values()) {\n            for (ProcessedDetection detection : detections) {\n                totalConfidence += detection.recognition.getConfidence();\n                totalDetections++;\n            }\n        }\n        \n        return totalDetections > 0 ? totalConfidence / totalDetections : 0.0;\n    }\n    \n    private String generateRecommendedAction(AdvancedMLIntegrationSystem.MLResults results) {\n        // Simple action recommendation based on detected objects\n        if (!results.gameElements.isEmpty()) {\n            return \"Navigate to nearest game element\";\n        } else if (!results.obstacles.isEmpty()) {\n            return \"Avoid obstacles and search for targets\";\n        } else if (!results.fieldFeatures.isEmpty()) {\n            return \"Navigate to field feature\";\n        } else {\n            return \"Search for targets\";\n        }\n    }\n}"
    },
    {
      "type": "text",
      "title": "Model Selector and Processed Detection Classes",
      "content": "Define the model selector for performance tracking and the processed detection class."
    },
    {
      "type": "code",
      "title": "ModelSelector and ProcessedDetection Classes",
      "content": "Define classes for model performance tracking and processed detection storage.",
      "code": "// Model selector class\nclass ModelSelector {\n    private Map<String, Double> modelPerformance = new HashMap<>();\n    \n    public void updateModelPerformance(AdvancedMLIntegrationSystem.MLResults results) {\n        // Update performance metrics for each model\n        // This is a simplified version - you would implement more sophisticated metrics\n        \n        double gameElementPerformance = results.gameElements.size() > 0 ? 1.0 : 0.0;\n        double obstaclePerformance = results.obstacles.size() > 0 ? 1.0 : 0.0;\n        double fieldFeaturePerformance = results.fieldFeatures.size() > 0 ? 1.0 : 0.0;\n        \n        modelPerformance.put(\"game_elements\", gameElementPerformance);\n        modelPerformance.put(\"obstacles\", obstaclePerformance);\n        modelPerformance.put(\"field_features\", fieldFeaturePerformance);\n    }\n    \n    public String getBestModel() {\n        String bestModel = \"game_elements\";\n        double bestPerformance = 0.0;\n        \n        for (Map.Entry<String, Double> entry : modelPerformance.entrySet()) {\n            if (entry.getValue() > bestPerformance) {\n                bestPerformance = entry.getValue();\n                bestModel = entry.getKey();\n            }\n        }\n        \n        return bestModel;\n    }\n}\n\n// Processed detection class\nclass ProcessedDetection {\n    public Recognition recognition;\n    public String modelType;\n    public String color;\n    public double distance;\n    public boolean isAvoidable;\n    public double size;\n    public String description;\n    \n    public ProcessedDetection(Recognition recognition, String modelType) {\n        this.recognition = recognition;\n        this.modelType = modelType;\n    }\n    \n    public ProcessedDetection(Recognition recognition, String modelType, \n                            String color, double distance) {\n        this(recognition, modelType);\n        this.color = color;\n        this.distance = distance;\n    }\n    \n    public ProcessedDetection(Recognition recognition, String modelType, \n                            boolean isAvoidable, double size) {\n        this(recognition, modelType);\n        this.isAvoidable = isAvoidable;\n        this.size = size;\n    }\n    \n    public ProcessedDetection(Recognition recognition, String modelType, String description) {\n        this(recognition, modelType);\n        this.description = description;\n    }\n}"
    },
    {
      "type": "text",
      "title": "Real-time ML Inference System Setup",
      "content": "Let's create an optimized real-time ML inference system that can adapt to performance requirements. For more on TensorFlow Lite performance optimization, see <a href=\"https://www.tensorflow.org/lite/performance\" target=\"_blank\">TensorFlow Lite Performance</a>."
    },
    {
      "type": "code",
      "title": "Class Definition and Performance Parameters",
      "content": "Define the real-time ML inference system class with performance targets and adaptive parameters.",
      "code": "public class RealTimeMLInferenceSystem {\n    private VisionPortal visionPortal;\n    private TfodProcessor optimizedModel;\n    private InferenceOptimizer optimizer;\n    private PerformanceMonitor monitor;\n    \n    // Performance targets\n    private static final double TARGET_FPS = 30.0;\n    private static final double MAX_INFERENCE_TIME = 33.0; // milliseconds\n    private static final int FRAME_SKIP_THRESHOLD = 2;\n    \n    // Adaptive parameters\n    private int currentFrameSkip = 0;\n    private double currentConfidenceThreshold = 0.6;\n    private int currentMaxDetections = 10;\n    \n    private final Telemetry telemetry;\n    private final HardwareMap hardwareMap;\n    // ..."
    },
    {
      "type": "text",
      "title": "System Initialization",
      "content": "Initialize the real-time ML inference system with optimized model and performance monitoring."
    },
    {
      "type": "code",
      "title": "Constructor and Model Initialization",
      "content": "Initialize the system with optimized model and build the vision portal.",
      "code": "    public RealTimeMLInferenceSystem(HardwareMap hardwareMap, Telemetry telemetry) {\n        this.telemetry = telemetry;\n        this.hardwareMap = hardwareMap;\n        optimizer = new InferenceOptimizer();\n        monitor = new PerformanceMonitor();\n        initializeOptimizedModel();\n        buildOptimizedVisionPortal();\n    }\n    \n    private void initializeOptimizedModel() {\n        // Create highly optimized model for real-time inference\n        optimizedModel = new TfodProcessor.Builder()\n            .setModelFileName(\"optimized_game_elements.tflite\")\n            .setModelLabels(new String[]{\n                \"red_cone\", \"blue_cone\", \"green_cone\", \n                \"yellow_cone\", \"orange_cone\", \"purple_cone\"\n            })\n            .setIsModelTensorFlow2(true)\n            .setIsModelQuantized(true) // Use quantized model for speed\n            .setModelInputSize(256) // Smaller input for faster processing\n            .setModelAspectRatio(1.0)\n            .setMinResultConfidence((float) currentConfidenceThreshold)\n            .setMaxNumRecognitions(currentMaxDetections)\n            .setUseObjectTracker(true) // Enable tracking to reduce processing\n            .setTrackerMaxOverlap(0.3f)\n            .setTrackerMinSize(0.05f)\n            .build();\n    }"
    },
    {
      "type": "text",
      "title": "Optimized Vision Portal Setup",
      "content": "Build an optimized vision portal with performance-focused settings."
    },
    {
      "type": "code",
      "title": "buildOptimizedVisionPortal Method",
      "content": "Build vision portal with performance-optimized settings.",
      "code": "    private void buildOptimizedVisionPortal() {\n        visionPortal = new VisionPortal.Builder()\n            .setCamera(hardwareMap.get(WebcamName.class, \"Webcam 1\"))\n            .addProcessor(optimizedModel)\n            .setCameraResolution(new Size(640, 480)) // Balanced resolution\n            .setStreamFormat(VisionPortal.StreamFormat.YUY2)\n            .enableLiveView(false) // Disable for performance\n            .enableCameraMonitoring(false)\n            .build();\n    }"
    },
    {
      "type": "text",
      "title": "Main Processing Method",
      "content": "The processFrameOptimized method handles real-time frame processing with performance monitoring."
    },
    {
      "type": "code",
      "title": "processFrameOptimized Method",
      "content": "Process frames with real-time optimization and performance monitoring.",
      "code": "    public List<OptimizedDetection> processFrameOptimized() {\n        long startTime = System.nanoTime();\n        \n        // Check if we should skip this frame\n        if (shouldSkipFrame()) {\n            return getLastValidResults();\n        }\n        \n        // Get raw detections\n        List<Recognition> rawDetections = optimizedModel.getRecognitions();\n        if (rawDetections == null) rawDetections = new ArrayList<>();\n        \n        // Optimize detections\n        List<OptimizedDetection> optimizedDetections = \n            optimizer.optimizeDetections(rawDetections);\n        \n        // Update performance metrics\n        long processingTime = System.nanoTime() - startTime;\n        monitor.updateMetrics(processingTime, optimizedDetections.size());\n        \n        // Adapt parameters based on performance\n        adaptParameters(processingTime);\n        \n        return optimizedDetections;\n    }"
    },
    {
      "type": "text",
      "title": "Frame Skipping Logic",
      "content": "The shouldSkipFrame method determines when to skip frames to maintain performance targets."
    },
    {
      "type": "code",
      "title": "shouldSkipFrame Method",
      "content": "Determine when to skip frames to maintain performance targets.",
      "code": "    private boolean shouldSkipFrame() {\n        // Skip frames if we're falling behind\n        if (monitor.getCurrentFPS() < TARGET_FPS * 0.8) {\n            currentFrameSkip = Math.min(currentFrameSkip + 1, FRAME_SKIP_THRESHOLD);\n            return true;\n        } else {\n            currentFrameSkip = Math.max(currentFrameSkip - 1, 0);\n            return false;\n        }\n    }\n    \n    private List<OptimizedDetection> getLastValidResults() {\n        // Return cached results when skipping frames\n        return optimizer.getLastValidResults();\n    }"
    },
    {
      "type": "text",
      "title": "Parameter Adaptation",
      "content": "The adaptParameters method dynamically adjusts model parameters based on performance metrics."
    },
    {
      "type": "code",
      "title": "adaptParameters Method",
      "content": "Dynamically adjust model parameters based on performance metrics.",
      "code": "    private void adaptParameters(long processingTime) {\n        double processingTimeMs = processingTime / 1_000_000.0;\n        \n        boolean updated = false;\n        if (processingTimeMs > MAX_INFERENCE_TIME) {\n            // Reduce processing load\n            if (currentConfidenceThreshold < 0.9) {\n                currentConfidenceThreshold = Math.min(currentConfidenceThreshold + 0.05, 0.9);\n                updated = true;\n            }\n            if (currentMaxDetections > 3) {\n                currentMaxDetections = Math.max(currentMaxDetections - 1, 3);\n                updated = true;\n            }\n        } else if (processingTimeMs < MAX_INFERENCE_TIME * 0.7) {\n            // We have headroom - increase accuracy\n            if (currentConfidenceThreshold > 0.4) {\n                currentConfidenceThreshold = Math.max(currentConfidenceThreshold - 0.02, 0.4);\n                updated = true;\n            }\n            if (currentMaxDetections < 15) {\n                currentMaxDetections = Math.min(currentMaxDetections + 1, 15);\n                updated = true;\n            }\n        }\n        if (updated) {\n            updateModelParameters();\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Parameter Update and Performance Metrics",
      "content": "Update model parameters and provide access to performance metrics."
    },
    {
      "type": "code",
      "title": "Parameter Update and Performance Access Methods",
      "content": "Update model parameters and provide performance metrics access.",
      "code": "    private void updateModelParameters() {\n        // Note: In a real implementation, you would need to rebuild the processor\n        // with new parameters. This is a simplified example.\n        telemetry.addData(\"Adapted Confidence\", \"%.2f\", currentConfidenceThreshold);\n        telemetry.addData(\"Adapted Max Detections\", currentMaxDetections);\n        telemetry.addData(\"Frame Skip Level\", currentFrameSkip);\n        telemetry.update();\n    }\n    \n    public PerformanceMetrics getPerformanceMetrics() {\n        return monitor.getMetrics(currentConfidenceThreshold, currentMaxDetections);\n    }"
    },
    {
      "type": "text",
      "title": "Supporting Classes - OptimizedDetection and Point2D",
      "content": "Define supporting classes for optimized detections and 2D coordinates."
    },
    {
      "type": "code",
      "title": "OptimizedDetection and Point2D Classes",
      "content": "Define classes for storing optimized detection results and 2D coordinates.",
      "code": "    // Supporting classes\n    public static class OptimizedDetection {\n        public String label;\n        public Point2D center;\n        public double confidence;\n        public double distance;\n        public long timestamp;\n        public int trackId;\n        \n        public OptimizedDetection(String label, Point2D center, double confidence, \n                                 double distance, int trackId) {\n            this.label = label;\n            this.center = center;\n            this.confidence = confidence;\n            this.distance = distance;\n            this.trackId = trackId;\n            this.timestamp = System.currentTimeMillis();\n        }\n    }\n    \n    public static class Point2D {\n        public double x, y;\n        \n        public Point2D(double x, double y) {\n            this.x = x;\n            this.y = y;\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Performance Metrics Class",
      "content": "Define the PerformanceMetrics class for tracking system performance."
    },
    {
      "type": "code",
      "title": "PerformanceMetrics Class",
      "content": "Define class for storing comprehensive performance metrics.",
      "code": "    public static class PerformanceMetrics {\n        public double currentFPS;\n        public double averageInferenceTime;\n        public double maxInferenceTime;\n        public int totalDetections;\n        public double confidenceThreshold;\n        public int maxDetections;\n        \n        public PerformanceMetrics(double currentFPS, double averageInferenceTime,\n                                double maxInferenceTime, int totalDetections,\n                                double confidenceThreshold, int maxDetections) {\n            this.currentFPS = currentFPS;\n            this.averageInferenceTime = averageInferenceTime;\n            this.maxInferenceTime = maxInferenceTime;\n            this.totalDetections = totalDetections;\n            this.confidenceThreshold = confidenceThreshold;\n            this.maxDetections = maxDetections;\n        }\n    }\n}"
    },
    {
      "type": "text",
      "title": "Inference Optimizer Class",
      "content": "The InferenceOptimizer class handles detection optimization and object tracking."
    },
    {
      "type": "code",
      "title": "InferenceOptimizer Class Definition",
      "content": "Define the inference optimizer class for detection optimization and tracking.",
      "code": "// Inference optimizer class\nclass InferenceOptimizer {\n    private List<RealTimeMLInferenceSystem.OptimizedDetection> lastValidResults = \n        new ArrayList<>();\n    private Map<Integer, RealTimeMLInferenceSystem.OptimizedDetection> trackedObjects = \n        new HashMap<>();\n    \n    public List<RealTimeMLInferenceSystem.OptimizedDetection> optimizeDetections(\n            List<Recognition> rawDetections) {\n        \n        List<RealTimeMLInferenceSystem.OptimizedDetection> optimized = new ArrayList<>();\n        \n        for (Recognition detection : rawDetections) {\n            // Calculate center point\n            RealTimeMLInferenceSystem.Point2D center = \n                new RealTimeMLInferenceSystem.Point2D(\n                    detection.getLeft() + detection.getWidth() / 2.0,\n                    detection.getTop() + detection.getHeight() / 2.0\n                );\n            \n            // Estimate distance based on object size\n            double distance = estimateDistance(detection.getArea());\n            \n            // Assign or update track ID\n            int trackId = assignTrackId(center, detection.getLabel());\n            \n            // Create optimized detection\n            RealTimeMLInferenceSystem.OptimizedDetection optimizedDetection = \n                new RealTimeMLInferenceSystem.OptimizedDetection(\n                    detection.getLabel(),\n                    center,\n                    detection.getConfidence(),\n                    distance,\n                    trackId\n                );\n            \n            optimized.add(optimizedDetection);\n        }\n        \n        // Update tracked objects\n        updateTrackedObjects(optimized);\n        \n        // Cache results\n        lastValidResults = new ArrayList<>(optimized);\n        \n        return optimized;\n    }"
    },
    {
      "type": "text",
      "title": "Distance Estimation and Track ID Assignment",
      "content": "Helper methods for distance estimation and object tracking."
    },
    {
      "type": "code",
      "title": "Distance Estimation and Track ID Methods",
      "content": "Helper methods for estimating distance and assigning track IDs to objects.",
      "code": "    private double estimateDistance(double area) {\n        // Calibrated distance estimation\n        if (area <= 0) return Double.POSITIVE_INFINITY;\n        return 1200.0 / Math.sqrt(area);\n    }\n    \n    private int assignTrackId(RealTimeMLInferenceSystem.Point2D center, String label) {\n        // Simple tracking - find closest existing track\n        int bestTrackId = -1;\n        double bestDistance = Double.MAX_VALUE;\n        \n        for (Map.Entry<Integer, RealTimeMLInferenceSystem.OptimizedDetection> entry : \n             trackedObjects.entrySet()) {\n            \n            RealTimeMLInferenceSystem.OptimizedDetection tracked = entry.getValue();\n            \n            // Only match same label\n            if (!tracked.label.equals(label)) {\n                continue;\n            }\n            \n            // Calculate distance to tracked object\n            double distance = Math.hypot(center.x - tracked.center.x, center.y - tracked.center.y);\n            \n            if (distance < bestDistance && distance < 50) { // 50 pixel threshold\n                bestDistance = distance;\n                bestTrackId = entry.getKey();\n            }\n        }\n        \n        if (bestTrackId == -1) {\n            // Create new track\n            bestTrackId = trackedObjects.size() + 1;\n        }\n        \n        return bestTrackId;\n    }"
    },
    {
      "type": "text",
      "title": "Tracked Objects Management",
      "content": "Methods for updating tracked objects and accessing cached results."
    },
    {
      "type": "code",
      "title": "Tracked Objects Management Methods",
      "content": "Methods for managing tracked objects and accessing cached results.",
      "code": "    private void updateTrackedObjects(List<RealTimeMLInferenceSystem.OptimizedDetection> detections) {\n        // Update tracked objects with new detections\n        Map<Integer, RealTimeMLInferenceSystem.OptimizedDetection> newTracks = \n            new HashMap<>();\n        \n        for (RealTimeMLInferenceSystem.OptimizedDetection detection : detections) {\n            newTracks.put(detection.trackId, detection);\n        }\n        \n        trackedObjects = newTracks;\n    }\n    \n    public List<RealTimeMLInferenceSystem.OptimizedDetection> getLastValidResults() {\n        return new ArrayList<>(lastValidResults);\n    }\n}"
    },
    {
      "type": "text",
      "title": "Performance Monitor Class",
      "content": "The PerformanceMonitor class tracks and analyzes system performance metrics."
    },
    {
      "type": "code",
      "title": "PerformanceMonitor Class Definition",
      "content": "Define the performance monitor class for tracking system performance metrics.",
      "code": "// Performance monitor class\nclass PerformanceMonitor {\n    private static final int HISTORY_SIZE = 30;\n    private List<Long> inferenceTimes = new ArrayList<>();\n    private List<Long> timestamps = new ArrayList<>();\n    private int totalDetections = 0;\n    \n    public void updateMetrics(long inferenceTime, int detections) {\n        long currentTime = System.currentTimeMillis();\n        \n        inferenceTimes.add(inferenceTime);\n        timestamps.add(currentTime);\n        totalDetections += detections;\n        \n        // Keep only recent history\n        if (inferenceTimes.size() > HISTORY_SIZE) {\n            inferenceTimes.remove(0);\n            timestamps.remove(0);\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Performance Analysis Methods",
      "content": "Methods for calculating FPS and generating performance metrics."
    },
    {
      "type": "code",
      "title": "Performance Analysis Methods",
      "content": "Methods for calculating current FPS and generating comprehensive performance metrics.",
      "code": "    public double getCurrentFPS() {\n        if (timestamps.size() < 2) {\n            return 0.0;\n        }\n        \n        long timeSpan = timestamps.get(timestamps.size() - 1) - timestamps.get(0);\n        if (timeSpan <= 0) {\n            return 0.0;\n        }\n        \n        return (timestamps.size() - 1) * 1000.0 / timeSpan;\n    }\n    \n    public RealTimeMLInferenceSystem.PerformanceMetrics getMetrics(double confidenceThreshold, int maxDetections) {\n        double avgInferenceTime = inferenceTimes.stream()\n            .mapToLong(Long::longValue)\n            .average()\n            .orElse(0.0) / 1_000_000.0; // Convert to milliseconds\n        \n        double maxInferenceTime = inferenceTimes.stream()\n            .mapToLong(Long::longValue)\n            .max()\n            .orElse(0L) / 1_000_000.0; // Convert to milliseconds\n        \n        return new RealTimeMLInferenceSystem.PerformanceMetrics(\n            getCurrentFPS(),\n            avgInferenceTime,\n            maxInferenceTime,\n            totalDetections,\n            confidenceThreshold,\n            maxDetections\n        );\n    }\n}"
    },
    {
      "type": "text",
      "title": "Custom ML Model Development",
      "content": "Custom ML model development involves creating specialized models trained specifically for your FTC robot's needs. This process includes data collection, model training, optimization, and deployment.<br><br><strong>Data Collection:</strong> Gathering diverse training data in various conditions<br><strong>Data Labeling:</strong> Annotating training data with correct labels and bounding boxes<br><strong>Model Architecture:</strong> Choosing appropriate neural network architectures<br><strong>Training Process:</strong> Training models with proper hyperparameters<br><strong>Model Optimization:</strong> Reducing model size while maintaining accuracy<br><strong>Deployment Pipeline:</strong> Converting and deploying models to the robot"
    },
    {
      "type": "text",
      "title": "ML Model Management and Updates",
      "content": "Effective ML model management involves version control, performance monitoring, and continuous improvement of your models. This ensures your vision system remains effective as conditions change.<br><br><strong>Model Versioning:</strong> Tracking different versions of your models<br><strong>Performance Monitoring:</strong> Continuously monitoring model performance<br><strong>A/B Testing:</strong> Comparing different model versions<br><strong>Model Updates:</strong> Deploying improved models without downtime<br><strong>Data Pipeline:</strong> Collecting new training data from robot operation<br><strong>Continuous Learning:</strong> Improving models based on real-world performance"
    },
    {
      "type": "emphasis-box",
      "title": "Advanced ML Integration Best Practices",
      "content": "To create effective advanced ML integration systems:<br><br><strong>System Design:</strong><br>• Start with simple models and gradually increase complexity<br>• Use model ensembles for improved reliability<br>• Implement proper error handling and fallback mechanisms<br>• Design for real-time performance from the beginning<br><br><strong>Performance:</strong><br>• Profile and optimize the entire inference pipeline<br>• Use appropriate model quantization and optimization<br>• Monitor and adapt to changing conditions<br>• Balance accuracy with speed requirements<br><br><strong>Integration:</strong><br>• Design clear interfaces between ML and robot control<br>• Provide comprehensive telemetry and debugging tools<br>• Plan for graceful degradation when ML fails<br>• Test thoroughly in competition-like conditions"
    },
    {
      "type": "exercise-box",
      "title": "Advanced ML Integration System",
      "description": "Create a complete advanced ML integration system",
      "tasks": [
        "Design and implement a multi-model ML system",
        "Create real-time inference optimization",
        "Develop custom model training pipeline",
        "Implement model management and versioning",
        "Add performance monitoring and adaptation",
        "Test the system in various competition conditions"
      ],
      "content": "Develop a complete advanced ML integration system that can handle multiple models, optimize for real-time performance, and provide robust object detection for autonomous robot operation."
    },
    {
      "type": "link-grid",
      "title": "Additional Resources",
      "links": [
        "<a href=\"https://www.tensorflow.org/lite/examples\" target=\"_blank\">TensorFlow Lite Examples</a>",
        "<a href=\"https://ftc-docs.firstinspires.org/ftc_ml/index.html\" target=\"_blank\">FTC-ML Training Tool</a>",
        "<a href=\"https://www.tensorflow.org/lite/performance\" target=\"_blank\">TensorFlow Lite Performance</a>",
        "<a href=\"https://gm0.org/en/latest/docs/software/tutorials/advanced-ml.html\" target=\"_blank\">gm0: Advanced ML Tutorial</a>"
      ]
    }
  ]
}
