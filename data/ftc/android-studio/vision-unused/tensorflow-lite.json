{
  "title": "TensorFlow Lite",
  "sections": [
    {
      "type": "text",
      "title": "What is TensorFlow Lite?",
      "content": "TensorFlow Lite is a lightweight version of Google's TensorFlow machine learning framework, specifically designed to run on mobile and embedded devices. In FTC robotics, TensorFlow Lite enables your robot to perform sophisticated object detection and classification using pre-trained neural networks.<br><br>TensorFlow Lite is particularly valuable for FTC applications because it:<br>• Runs efficiently on the Control Hub's limited processing power<br>• Provides pre-trained models for common object detection tasks<br>• Supports custom model training for specific game elements<br>• Offers real-time inference suitable for autonomous operation<br>• Integrates seamlessly with the FTC Vision Portal"
    },
    {
      "type": "rules-box",
      "title": "TensorFlow Lite Advantages in FTC",
      "items": [
        "Pre-trained models for common objects (people, objects, etc.)",
        "Custom model training for game-specific elements",
        "Real-time object detection and classification",
        "High accuracy with proper training data",
        "Integration with Vision Portal for easy implementation",
        "Support for multiple object detection simultaneously"
      ]
    },
    {
      "type": "text",
      "title": "Machine Learning Basics for Vision",
      "content": "Understanding the fundamentals of machine learning is crucial for effectively using TensorFlow Lite in FTC applications.<br><br><strong>Neural Networks:</strong> Computational models inspired by biological neural networks<br><strong>Training vs. Inference:</strong> Training creates the model, inference uses it for predictions<br><strong>Object Detection:</strong> Identifying and locating objects in images<br><strong>Classification:</strong> Categorizing objects into predefined classes<br><strong>Confidence Scores:</strong> Probability that a detection is correct<br><strong>Bounding Boxes:</strong> Rectangular regions that contain detected objects"
    },
    {
      "type": "text",
      "title": "Basic TensorFlow Lite OpMode Setup",
      "content": "Let's create a basic OpMode for TensorFlow Lite object detection. For more on TensorFlow Lite in FTC, see <a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/tensorflow_ff_2021/tensorflow-ff-2021.html\" target=\"_blank\">FTC TensorFlow Documentation</a>."
    },
    {
      "type": "code",
      "title": "Import Statements and Class Definition",
      "content": "Import the necessary TensorFlow Lite classes and define the OpMode class.",
      "code": "import org.firstinspires.ftc.vision.VisionPortal;\nimport org.firstinspires.ftc.vision.tfod.TfodProcessor;\nimport org.firstinspires.ftc.vision.tfod.TfodProcessor.Builder;\nimport org.firstinspires.ftc.vision.tfod.Recognition;\nimport java.util.List;\n\npublic class BasicTensorFlowOpMode extends LinearOpMode {\n    private VisionPortal visionPortal;\n    private TfodProcessor tfod;\n    // ..."
    },
    {
      "type": "text",
      "title": "TensorFlow Lite Processor Initialization",
      "content": "Initialize the TensorFlow Lite processor with model configuration. For more on model configuration, see <a href=\"https://www.tensorflow.org/lite/examples\" target=\"_blank\">TensorFlow Lite Examples</a>."
    },
    {
      "type": "code",
      "title": "Processor Initialization Code",
      "content": "Configure the TensorFlow Lite processor with model file, labels, and settings.",
      "code": "    @Override\n    public void runOpMode() {\n        // Initialize TensorFlow Lite processor\n        tfod = new TfodProcessor.Builder()\n            .setModelFileName(\"model.tflite\")\n            .setModelLabels(new String[]{\"label1\", \"label2\", \"label3\"})\n            .setIsModelTensorFlow2(true)\n            .setIsModelQuantized(true)\n            .setModelInputSize(300)\n            .setModelAspectRatio(16.0 / 9.0)\n            .build();"
    },
    {
      "type": "text",
      "title": "Vision Portal Setup",
      "content": "Build the Vision Portal with the TensorFlow Lite processor and camera configuration. For more on Vision Portal, see <a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/vision-portal.html\" target=\"_blank\">FTC Vision Portal Documentation</a>."
    },
    {
      "type": "code",
      "title": "Vision Portal Configuration",
      "content": "Configure Vision Portal with camera and TensorFlow Lite processor.",
      "code": "        // Build Vision Portal with TensorFlow processor\n        visionPortal = new VisionPortal.Builder()\n            .setCamera(hardwareMap.get(WebcamName.class, \"Webcam 1\"))\n            .addProcessor(tfod)\n            .setCameraResolution(new Size(640, 480))\n            .enableLiveView(true)\n            .build();"
    },
    {
      "type": "text",
      "title": "Main Detection Loop",
      "content": "The main loop retrieves TensorFlow Lite detections and processes them. For more on accessing detections, see <a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/tensorflow_ff_2021/tensorflow-ff-2021.html#accessing-detection-results\" target=\"_blank\">FTC TensorFlow: Accessing Results</a>."
    },
    {
      "type": "code",
      "title": "Main Detection Loop Implementation",
      "content": "Get TensorFlow Lite detections and process them in the main loop.",
      "code": "        waitForStart();\n        \n        while (opModeIsActive()) {\n            // Get TensorFlow detections\n            List<Recognition> recognitions = tfod.getRecognitions();\n            \n            // Process detections\n            processTensorFlowDetections(recognitions);\n            \n            telemetry.update();\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Detection Processing Method",
      "content": "Process the detected objects and display their information on telemetry. For more on recognition objects, see <a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/tensorflow_ff_2021/tensorflow-ff-2021.html#recognition-object\" target=\"_blank\">FTC TensorFlow Recognition Object</a>."
    },
    {
      "type": "code",
      "title": "processTensorFlowDetections Method",
      "content": "Process detected objects and display detection information on telemetry.",
      "code": "    private void processTensorFlowDetections(List<Recognition> recognitions) {\n        if (recognitions.isEmpty()) {\n            telemetry.addData(\"TensorFlow\", \"No objects detected\");\n            return;\n        }\n        \n        // Process each detected object\n        for (Recognition recognition : recognitions) {\n            String label = recognition.getLabel();\n            float confidence = recognition.getConfidence();\n            \n            // Get bounding box coordinates\n            float left = recognition.getLeft();\n            float top = recognition.getTop();\n            float right = recognition.getRight();\n            float bottom = recognition.getBottom();\n            \n            // Calculate center point\n            float centerX = (left + right) / 2.0f;\n            float centerY = (top + bottom) / 2.0f;\n            \n            // Display detection information\n            telemetry.addData(\"Object\", label);\n            telemetry.addData(\"Confidence\", \"%.2f\", confidence);\n            telemetry.addData(\"Center\", \"(%.0f, %.0f)\", centerX, centerY);\n            telemetry.addData(\"Size\", \"%.0f x %.0f\", right - left, bottom - top);\n        }\n    }\n}"
    },
    {
      "type": "text",
      "title": "TensorFlow Lite Model Integration",
      "content": "Integrating TensorFlow Lite models into your FTC robot requires understanding model formats, loading procedures, and inference optimization.<br><br><strong>Model Formats:</strong> TensorFlow Lite models are stored as .tflite files<br><strong>Model Loading:</strong> Models are loaded into memory during initialization<br><strong>Input Preprocessing:</strong> Images must be resized and normalized for the model<br><strong>Inference Execution:</strong> Running the model to get predictions<br><strong>Output Interpretation:</strong> Converting model outputs to usable information<br><strong>Performance Optimization:</strong> Techniques to improve inference speed"
    },
    {
      "type": "text",
      "title": "Advanced TensorFlow Lite OpMode Setup",
      "content": "Let's create an advanced TensorFlow Lite OpMode with custom settings and optimization. For more on advanced configuration, see <a href=\"https://www.tensorflow.org/lite/performance\" target=\"_blank\">TensorFlow Lite Performance</a>."
    },
    {
      "type": "code",
      "title": "Class Definition and Constants",
      "content": "Define the advanced OpMode class and set up detection parameters.",
      "code": "public class AdvancedTensorFlowOpMode extends LinearOpMode {\n    private VisionPortal visionPortal;\n    private TfodProcessor tfod;\n    \n    // Detection parameters\n    private static final float MIN_CONFIDENCE = 0.5f;\n    private static final int MAX_NUM_RECOGNITIONS = 10;\n    // ..."
    },
    {
      "type": "text",
      "title": "Advanced Processor Configuration",
      "content": "Configure the TensorFlow Lite processor with advanced settings including object tracking and performance optimization."
    },
    {
      "type": "code",
      "title": "Advanced Processor Setup",
      "content": "Configure the processor with custom model, labels, and advanced settings.",
      "code": "    @Override\n    public void runOpMode() {\n        // Configure TensorFlow Lite processor with advanced settings\n        tfod = new TfodProcessor.Builder()\n            .setModelFileName(\"custom_model.tflite\")\n            .setModelLabels(new String[]{\n                \"red_cone\", \"blue_cone\", \"green_cone\", \n                \"yellow_cone\", \"orange_cone\", \"purple_cone\"\n            })\n            .setIsModelTensorFlow2(true)\n            .setIsModelQuantized(true)\n            .setModelInputSize(320)  // Smaller input for faster processing\n            .setModelAspectRatio(1.0)  // Square input\n            .setMinResultConfidence(MIN_CONFIDENCE)\n            .setMaxNumRecognitions(MAX_NUM_RECOGNITIONS)\n            .setUseObjectTracker(true)  // Enable object tracking\n            .setTrackerMaxOverlap(0.2f)  // Maximum overlap for tracking\n            .setTrackerMinSize(0.1f)  // Minimum object size\n            .build();"
    },
    {
      "type": "text",
      "title": "Optimized Vision Portal Setup",
      "content": "Build Vision Portal with optimized settings for better performance and monitoring."
    },
    {
      "type": "code",
      "title": "Optimized Vision Portal Configuration",
      "content": "Configure Vision Portal with optimized settings and monitoring features.",
      "code": "        // Build Vision Portal with optimized settings\n        visionPortal = new VisionPortal.Builder()\n            .setCamera(hardwareMap.get(WebcamName.class, \"Webcam 1\"))\n            .addProcessor(tfod)\n            .setCameraResolution(new Size(640, 480))\n            .setStreamFormat(VisionPortal.StreamFormat.YUY2)\n            .enableLiveView(true)\n            .enableCameraMonitoring(true)\n            .build();"
    },
    {
      "type": "text",
      "title": "Main Detection Loop",
      "content": "The main loop processes advanced detections with sorting and filtering capabilities."
    },
    {
      "type": "code",
      "title": "Main Detection Loop Implementation",
      "content": "Get detections and process them with advanced analysis.",
      "code": "        waitForStart();\n        \n        while (opModeIsActive()) {\n            List<Recognition> recognitions = tfod.getRecognitions();\n            processAdvancedDetections(recognitions);\n            telemetry.update();\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Advanced Detection Processing",
      "content": "Process detections with confidence sorting and detailed analysis. For more on recognition processing, see <a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/tensorflow_ff_2021/tensorflow-ff-2021.html#processing-recognitions\" target=\"_blank\">FTC TensorFlow: Processing Recognitions</a>."
    },
    {
      "type": "code",
      "title": "Advanced Detection Processing Method",
      "content": "Process detections with confidence sorting and detailed analysis.",
      "code": "    private void processAdvancedDetections(List<Recognition> recognitions) {\n        if (recognitions.isEmpty()) {\n            telemetry.addData(\"TensorFlow\", \"No objects detected\");\n            return;\n        }\n        \n        // Sort recognitions by confidence\n        recognitions.sort((r1, r2) -> Float.compare(r2.getConfidence(), r1.getConfidence()));"
    },
    {
      "type": "text",
      "title": "Top Detection Processing",
      "content": "Process the top detections and calculate detailed object properties for analysis."
    },
    {
      "type": "code",
      "title": "Top Detection Processing Loop",
      "content": "Process the top 5 detections and calculate object properties.",
      "code": "        // Process top detections\n        for (int i = 0; i < Math.min(recognitions.size(), 5); i++) {\n            Recognition recognition = recognitions.get(i);\n            \n            String label = recognition.getLabel();\n            float confidence = recognition.getConfidence();\n            \n            // Calculate object properties\n            float width = recognition.getRight() - recognition.getLeft();\n            float height = recognition.getBottom() - recognition.getTop();\n            float area = width * height;\n            float centerX = (recognition.getLeft() + recognition.getRight()) / 2.0f;\n            float centerY = (recognition.getTop() + recognition.getBottom()) / 2.0f;"
    },
    {
      "type": "text",
      "title": "Detailed Information Display",
      "content": "Display detailed information about each detected object including confidence, position, and size."
    },
    {
      "type": "code",
      "title": "Detailed Information Display Code",
      "content": "Display detailed information for each detected object.",
      "code": "            // Display detailed information\n            telemetry.addData(\"Object %d\", i + 1);\n            telemetry.addData(\"  Label\", label);\n            telemetry.addData(\"  Confidence\", \"%.3f\", confidence);\n            telemetry.addData(\"  Center\", \"(%.0f, %.0f)\", centerX, centerY);\n            telemetry.addData(\"  Size\", \"%.0f x %.0f\", width, height);\n            telemetry.addData(\"  Area\", \"%.0f pixels\", area);\n        }\n    }\n}"
    },
    {
      "type": "text",
      "title": "Object Detection with TensorFlow Lite",
      "content": "Object detection is one of the most powerful applications of TensorFlow Lite in FTC robotics. It allows your robot to identify and locate multiple objects in a single image, providing both classification and spatial information.<br><br><strong>Detection Process:</strong> The model analyzes the entire image to find objects<br><strong>Bounding Boxes:</strong> Rectangular regions that contain detected objects<br><strong>Confidence Scores:</strong> Probability that each detection is correct<br><strong>Multiple Objects:</strong> Detecting several objects simultaneously<br><strong>Real-time Processing:</strong> Processing frames quickly enough for robot control<br><strong>Object Tracking:</strong> Following objects across multiple frames"
    },
    {
      "type": "text",
      "title": "TensorFlow Control OpMode Setup",
      "content": "Let's create an OpMode that uses TensorFlow Lite detections for robot control. For more on robot control, see <a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/hardware_basics/motors.html\" target=\"_blank\">FTC Motor Documentation</a>."
    },
    {
      "type": "code",
      "title": "Class Definition and Target Properties",
      "content": "Define the control OpMode class and set up target object properties.",
      "code": "public class TensorFlowControlOpMode extends LinearOpMode {\n    private VisionPortal visionPortal;\n    private TfodProcessor tfod;\n    private DcMotor leftDrive, rightDrive;\n    \n    // Target object properties\n    private static final String TARGET_OBJECT = \"red_cone\";\n    private static final float TARGET_CONFIDENCE = 0.7f;\n    private static final float TARGET_CENTER_X = 320.0f; // Center of camera view\n    // ..."
    },
    {
      "type": "text",
      "title": "Hardware and TensorFlow Initialization",
      "content": "Initialize the drive motors and TensorFlow Lite processor for robot control."
    },
    {
      "type": "code",
      "title": "Hardware and Processor Initialization",
      "content": "Initialize drive motors and TensorFlow Lite processor with cone detection model.",
      "code": "    @Override\n    public void runOpMode() {\n        // Initialize hardware\n        leftDrive = hardwareMap.get(DcMotor.class, \"left_drive\");\n        rightDrive = hardwareMap.get(DcMotor.class, \"right_drive\");\n        \n        // Initialize TensorFlow Lite\n        tfod = new TfodProcessor.Builder()\n            .setModelFileName(\"cone_detection_model.tflite\")\n            .setModelLabels(new String[]{\"red_cone\", \"blue_cone\", \"green_cone\"})\n            .setIsModelTensorFlow2(true)\n            .setIsModelQuantized(true)\n            .setModelInputSize(320)\n            .setMinResultConfidence(TARGET_CONFIDENCE)\n            .build();"
    },
    {
      "type": "text",
      "title": "Vision Portal Setup",
      "content": "Build Vision Portal with the TensorFlow Lite processor for robot control."
    },
    {
      "type": "code",
      "title": "Vision Portal Configuration",
      "content": "Configure Vision Portal with camera and TensorFlow Lite processor.",
      "code": "        visionPortal = new VisionPortal.Builder()\n            .setCamera(hardwareMap.get(WebcamName.class, \"Webcam 1\"))\n            .addProcessor(tfod)\n            .setCameraResolution(new Size(640, 480))\n            .build();"
    },
    {
      "type": "text",
      "title": "Main Control Loop",
      "content": "The main loop finds target objects and navigates toward them or searches if none are found."
    },
    {
      "type": "code",
      "title": "Main Control Loop Implementation",
      "content": "Find target objects and navigate toward them or search if none found.",
      "code": "        waitForStart();\n        \n        while (opModeIsActive()) {\n            List<Recognition> recognitions = tfod.getRecognitions();\n            \n            // Find target object\n            Recognition targetRecognition = findTargetObject(recognitions);\n            \n            if (targetRecognition != null) {\n                // Navigate toward target object\n                navigateToObject(targetRecognition);\n            } else {\n                // No target found, search behavior\n                searchForTarget();\n            }\n            \n            telemetry.update();\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Target Object Finding",
      "content": "The findTargetObject method searches through detections to find the best target object based on label and confidence."
    },
    {
      "type": "code",
      "title": "findTargetObject Method",
      "content": "Find the best target object among detections based on label and confidence.",
      "code": "    private Recognition findTargetObject(List<Recognition> recognitions) {\n        Recognition bestTarget = null;\n        float bestConfidence = 0.0f;\n        \n        for (Recognition recognition : recognitions) {\n            if (recognition.getLabel().equals(TARGET_OBJECT)) {\n                if (recognition.getConfidence() > bestConfidence) {\n                    bestConfidence = recognition.getConfidence();\n                    bestTarget = recognition;\n                }\n            }\n        }\n        \n        return bestTarget;\n    }"
    },
    {
      "type": "text",
      "title": "Navigation Method Setup",
      "content": "The navigateToObject method uses TensorFlow Lite detection information to control robot movement toward the target object."
    },
    {
      "type": "code",
      "title": "Navigation Method Definition",
      "content": "Define the navigation method that uses detection information for robot control.",
      "code": "    private void navigateToObject(Recognition target) {\n        // Calculate object center\n        float centerX = (target.getLeft() + target.getRight()) / 2.0f;\n        float centerY = (target.getTop() + target.getBottom()) / 2.0f;\n        \n        // Calculate horizontal error (how far off-center)\n        float horizontalError = centerX - TARGET_CENTER_X;"
    },
    {
      "type": "text",
      "title": "Object Size Calculation",
      "content": "Calculate object size to approximate distance and determine navigation parameters."
    },
    {
      "type": "code",
      "title": "Object Size Calculation Code",
      "content": "Calculate object size for distance approximation.",
      "code": "        // Calculate object size (distance approximation)\n        float objectWidth = target.getRight() - target.getLeft();\n        float objectHeight = target.getBottom() - target.getTop();\n        float objectSize = Math.max(objectWidth, objectHeight);"
    },
    {
      "type": "text",
      "title": "Proportional Control Implementation",
      "content": "Apply proportional control to calculate motor powers based on horizontal error and forward movement."
    },
    {
      "type": "code",
      "title": "Proportional Control Code",
      "content": "Apply proportional control to calculate motor powers for navigation.",
      "code": "        // Simple proportional control\n        double turnPower = -0.01 * horizontalError; // Negative for correct direction\n        double forwardPower = 0.3; // Constant forward power\n        \n        // Apply motor commands\n        double leftPower = forwardPower + turnPower;\n        double rightPower = forwardPower - turnPower;"
    },
    {
      "type": "text",
      "title": "Power Limiting and Motor Control",
      "content": "Limit the motor powers to valid ranges and apply them to the drive motors."
    },
    {
      "type": "code",
      "title": "Power Limiting and Motor Control Code",
      "content": "Limit power values and apply them to the drive motors.",
      "code": "        // Limit power\n        leftPower = Math.max(-1.0, Math.min(1.0, leftPower));\n        rightPower = Math.max(-1.0, Math.min(1.0, rightPower));\n        \n        leftDrive.setPower(leftPower);\n        rightDrive.setPower(rightPower);"
    },
    {
      "type": "text",
      "title": "Navigation Information Display",
      "content": "Display navigation information on telemetry for debugging and monitoring purposes."
    },
    {
      "type": "code",
      "title": "Telemetry Display Code",
      "content": "Display navigation information including target details and motor powers.",
      "code": "        // Display navigation information\n        telemetry.addData(\"Target Found\", target.getLabel());\n        telemetry.addData(\"Confidence\", \"%.3f\", target.getConfidence());\n        telemetry.addData(\"Horizontal Error\", \"%.1f pixels\", horizontalError);\n        telemetry.addData(\"Object Size\", \"%.0f pixels\", objectSize);\n        telemetry.addData(\"Left Power\", \"%.2f\", leftPower);\n        telemetry.addData(\"Right Power\", \"%.2f\", rightPower);\n    }"
    },
    {
      "type": "text",
      "title": "Search Behavior Method",
      "content": "The searchForTarget method provides fallback behavior when no target object is detected."
    },
    {
      "type": "code",
      "title": "searchForTarget Method",
      "content": "Implement simple search behavior when no target is detected.",
      "code": "    private void searchForTarget() {\n        // Simple search behavior - turn slowly\n        leftDrive.setPower(0.2);\n        rightDrive.setPower(-0.2);\n        \n        telemetry.addData(\"Status\", \"Searching for target...\");\n    }\n}"
    },
    {
      "type": "text",
      "title": "Custom Model Training and Deployment",
      "content": "While pre-trained models are useful, custom models trained specifically for your FTC game elements can provide much better performance. Training custom models requires data collection, model training, and deployment.<br><br><strong>Data Collection:</strong> Gathering images of your target objects<br><strong>Data Labeling:</strong> Marking object locations and classes in images<br><strong>Model Training:</strong> Training the neural network on your data<br><strong>Model Conversion:</strong> Converting to TensorFlow Lite format<br><strong>Model Deployment:</strong> Loading and using the model on your robot<br><strong>Performance Validation:</strong> Testing the model in real conditions"
    },
    {
      "type": "emphasis-box",
      "title": "TensorFlow Lite Best Practices",
      "content": "To get the best results from TensorFlow Lite in FTC applications:<br><br><strong>Model Selection:</strong><br>• Choose appropriate model size for your processing requirements<br>• Consider quantized models for faster inference<br>• Balance accuracy with speed for real-time applications<br><br><strong>Camera Setup:</strong><br>• Ensure consistent lighting conditions<br>• Position camera for optimal object visibility<br>• Use appropriate resolution for your detection range<br><br><strong>Processing:</strong><br>• Filter detections by confidence threshold<br>• Implement object tracking for smooth operation<br>• Plan for cases where objects are not detected<br><br><strong>Training:</strong><br>• Collect diverse training data in various conditions<br>• Use data augmentation to improve model robustness<br>• Validate model performance in competition-like conditions"
    },
    {
      "type": "exercise-box",
      "title": "TensorFlow Lite Object Detection System",
      "description": "Create a complete TensorFlow Lite object detection system",
      "tasks": [
        "Set up TensorFlow Lite with a pre-trained model",
        "Implement object detection and classification",
        "Create robot control logic based on detections",
        "Add confidence filtering and object tracking",
        "Implement search behavior when objects are not detected",
        "Test the system with different objects and conditions"
      ],
      "content": "Develop a complete TensorFlow Lite object detection system that can identify game elements, track their positions, and control the robot to interact with them. Include error handling and fallback behaviors for robust operation."
    },
    {
        "type": "text",
        "title": "Additional Resources",
        "content": "For more information, see the <a href=\"https://www.tensorflow.org/lite\" target=\"_blank\">TensorFlow Lite Documentation</a>"
    }
  ]
}
