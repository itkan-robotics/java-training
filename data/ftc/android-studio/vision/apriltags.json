{
  "title": "AprilTags",
  "sections": [
    {
      "type": "text",
      "title": "What are AprilTags?",
      "content": "AprilTags are fiducial markers - special patterns that can be easily detected and identified by computer vision systems. They're widely used in robotics for precise positioning, navigation, and object tracking.<br><br>AprilTags work like QR codes but are designed specifically for robotics applications. Each tag has a unique ID and known size, allowing robots to determine their position and orientation relative to the tag with high accuracy."
    },
    {
      "type": "rules-box",
      "title": "AprilTag Advantages in FTC",
      "items": [
        "High accuracy positioning and orientation detection",
        "Robust detection in various lighting conditions",
        "Fast processing suitable for real-time applications",
        "Unique identification of multiple tags",
        "Standardized format for consistent results",
        "Integration with FTC's built-in AprilTag processor"
      ]
    },
    {
      "type": "text",
      "title": "AprilTag Theory and Applications",
      "content": "AprilTags use a specific pattern design that allows for reliable detection even when partially occluded or viewed from different angles. The pattern consists of a black border with a unique binary code in the center.<br><br><strong>Key Components:</strong><br>• <strong>Border:</strong> Black border that helps with detection<br>• <strong>Code Region:</strong> Inner area containing the unique binary pattern<br>• <strong>Orientation:</strong> L-shaped pattern in one corner for orientation detection<br><br><strong>FTC Applications:</strong><br>• <strong>Robot Localization:</strong> Determine robot position on the field<br>• <strong>Game Element Detection:</strong> Identify specific game elements<br>• <strong>Navigation Aid:</strong> Provide absolute positioning references<br>• <strong>Alignment Assistance:</strong> Help with precise robot positioning"
    },
    {
      "type": "code",
      "title": "Basic AprilTag Detection Setup",
      "content": "Setting up AprilTag detection in FTC is straightforward using the built-in processor:",
      "code": "public class AprilTagDetectionOpMode extends LinearOpMode {\n    private VisionPortal visionPortal;\n    private AprilTagProcessor aprilTagProcessor;\n    \n    @Override\n    public void runOpMode() {\n        // Initialize AprilTag processor\n        aprilTagProcessor = new AprilTagProcessor.Builder()\n            .setTagLibrary(AprilTagLibrary.getCurrentGameTagLibrary())\n            .setTagFamily(AprilTagProcessor.TagFamily.TAG_36h11)\n            .setTagModel(AprilTagProcessor.TagModel.TAG_36h11)\n            .setSingleTagFamilySmoothingWindow(3)\n            .setMultiTagFamilySmoothingWindow(1)\n            .build();\n        \n        // Build Vision Portal\n        visionPortal = new VisionPortal.Builder()\n            .setCamera(hardwareMap.get(WebcamName.class, \"Webcam 1\"))\n            .addProcessor(aprilTagProcessor)\n            .setCameraResolution(new Size(640, 480))\n            .setStreamFormat(VisionPortal.StreamFormat.YUY2)\n            .enableLiveView(true)\n            .enableCameraMonitoring(true)\n            .build();\n        \n        waitForStart();\n        \n        while (opModeIsActive()) {\n            // Get AprilTag detections\n            List<AprilTagDetection> detections = aprilTagProcessor.getDetections();\n            \n            // Process detections\n            processAprilTagDetections(detections);\n            \n            telemetry.update();\n        }\n    }\n    \n    private void processAprilTagDetections(List<AprilTagDetection> detections) {\n        if (detections.isEmpty()) {\n            telemetry.addData(\"AprilTags\", \"No tags detected\");\n            return;\n        }\n        \n        for (AprilTagDetection detection : detections) {\n            if (detection.metadata != null) {\n                telemetry.addData(\"Tag ID\", detection.id);\n                telemetry.addData(\"Tag Name\", detection.metadata.name);\n                telemetry.addData(\"Tag Position\", \n                    \"X: %.2f, Y: %.2f, Z: %.2f\", \n                    detection.ftcPose.x, detection.ftcPose.y, detection.ftcPose.z);\n                telemetry.addData(\"Tag Rotation\", \n                    \"Roll: %.2f, Pitch: %.2f, Yaw: %.2f\", \n                    detection.ftcPose.roll, detection.ftcPose.pitch, detection.ftcPose.yaw);\n                telemetry.addData(\"Tag Distance\", \"%.2f inches\", detection.ftcPose.range);\n                telemetry.addData(\"Tag Bearing\", \"%.2f degrees\", detection.ftcPose.bearing);\n                telemetry.addData(\"Tag Elevation\", \"%.2f degrees\", detection.ftcPose.elevation);\n            }\n        }\n    }\n}"
    },
    {
      "type": "text",
      "title": "AprilTag Detection Setup",
      "content": "Proper setup is crucial for reliable AprilTag detection. Several factors affect detection performance:<br><br><strong>Camera Positioning:</strong><br>• <strong>Distance:</strong> Optimal detection range is typically 1-10 feet<br>• <strong>Angle:</strong> Tags should be viewed within ±45 degrees for best results<br>• <strong>Height:</strong> Position camera to minimize occlusion<br><br><strong>Lighting Considerations:</strong><br>• <strong>Consistent Lighting:</strong> Avoid shadows and glare on tags<br>• <strong>Contrast:</strong> Ensure good contrast between tag and background<br>• <strong>No Flashing:</strong> Avoid strobe lights or rapidly changing lighting<br><br><strong>Tag Placement:</strong><br>• <strong>Secure Mounting:</strong> Tags should be firmly attached and not move<br>• <strong>Clean Surface:</strong> Keep tags clean and free of damage<br>• <strong>Proper Orientation:</strong> Mount tags vertically and facing the camera"
    },
    {
      "type": "code",
      "title": "Advanced AprilTag Configuration",
      "content": "Advanced configuration options for optimizing AprilTag detection:",
      "code": "public class AdvancedAprilTagOpMode extends LinearOpMode {\n    private VisionPortal visionPortal;\n    private AprilTagProcessor aprilTagProcessor;\n    \n    @Override\n    public void runOpMode() {\n        // Advanced AprilTag processor configuration\n        aprilTagProcessor = new AprilTagProcessor.Builder()\n            .setTagLibrary(AprilTagLibrary.getCurrentGameTagLibrary())\n            .setTagFamily(AprilTagProcessor.TagFamily.TAG_36h11)\n            .setTagModel(AprilTagProcessor.TagModel.TAG_36h11)\n            .setSingleTagFamilySmoothingWindow(5) // Increased smoothing\n            .setMultiTagFamilySmoothingWindow(3)  // Multi-tag smoothing\n            .setPoseSolver(new SingleTagPoseSolver(\n                new Size(6, 6), // Tag size in inches\n                578.272,       // Focal length X (from camera calibration)\n                578.272,       // Focal length Y\n                402.145,       // Principal point X\n                221.506        // Principal point Y\n            ))\n            .setPoseAmbiguityFunction((detection) -> {\n                // Custom ambiguity function for pose estimation\n                return detection.pose.poseIsAmbiguous ? 0.2 : 0.0;\n            })\n            .build();\n        \n        // Advanced Vision Portal configuration\n        visionPortal = new VisionPortal.Builder()\n            .setCamera(hardwareMap.get(WebcamName.class, \"Webcam 1\"))\n            .addProcessor(aprilTagProcessor)\n            .setCameraResolution(new Size(1280, 720)) // Higher resolution\n            .setStreamFormat(VisionPortal.StreamFormat.YUY2)\n            .enableLiveView(true)\n            .enableCameraMonitoring(true)\n            .setAutoStopLiveView(false)\n            .build();\n        \n        waitForStart();\n        \n        while (opModeIsActive()) {\n            List<AprilTagDetection> detections = aprilTagProcessor.getDetections();\n            processAdvancedDetections(detections);\n            telemetry.update();\n        }\n    }\n    \n    private void processAdvancedDetections(List<AprilTagDetection> detections) {\n        if (detections.isEmpty()) {\n            telemetry.addData(\"Status\", \"No tags detected\");\n            return;\n        }\n        \n        // Sort detections by confidence or distance\n        detections.sort((a, b) -> Double.compare(b.ftcPose.range, a.ftcPose.range));\n        \n        for (AprilTagDetection detection : detections) {\n            // Check pose ambiguity\n            if (detection.pose.poseIsAmbiguous) {\n                telemetry.addData(\"Tag %d\", \"Pose ambiguous - low confidence\", detection.id);\n                continue;\n            }\n            \n            // Calculate tag center in image coordinates\n            Point tagCenter = detection.center;\n            telemetry.addData(\"Tag %d Center\", \"(%.0f, %.0f)\", \n                detection.id, tagCenter.x, tagCenter.y);\n            \n            // Calculate tag corners for precise positioning\n            Point[] corners = detection.corners;\n            for (int i = 0; i < corners.length; i++) {\n                telemetry.addData(\"Tag %d Corner %d\", \"(%.0f, %.0f)\", \n                    detection.id, i, corners[i].x, corners[i].y);\n            }\n        }\n    }\n}"
    },
    {
      "type": "text",
      "title": "Tag Pose Estimation",
      "content": "Pose estimation determines the 3D position and orientation of AprilTags relative to the camera. This is crucial for robot localization and navigation.<br><br><strong>Pose Components:</strong><br>• <strong>Translation (X, Y, Z):</strong> Position of tag relative to camera<br>• <strong>Rotation (Roll, Pitch, Yaw):</strong> Orientation of tag relative to camera<br>• <strong>Range:</strong> Distance from camera to tag center<br>• <strong>Bearing:</strong> Horizontal angle from camera to tag<br>• <strong>Elevation:</strong> Vertical angle from camera to tag<br><br><strong>Coordinate Systems:</strong><br>• <strong>Camera Coordinates:</strong> X-right, Y-down, Z-forward<br>• <strong>FTC Coordinates:</strong> X-forward, Y-left, Z-up<br>• <strong>Field Coordinates:</strong> Based on field layout and tag placement"
    },
    {
      "type": "code",
      "title": "Pose Estimation and Coordinate Transformations",
      "content": "Example of pose estimation and coordinate transformations:",
      "code": "public class PoseEstimationOpMode extends LinearOpMode {\n    private VisionPortal visionPortal;\n    private AprilTagProcessor aprilTagProcessor;\n    \n    // Camera calibration parameters (obtain from camera calibration)\n    private static final double FOCAL_LENGTH_X = 578.272;\n    private static final double FOCAL_LENGTH_Y = 578.272;\n    private static final double PRINCIPAL_POINT_X = 402.145;\n    private static final double PRINCIPAL_POINT_Y = 221.506;\n    \n    // Tag size in inches\n    private static final double TAG_SIZE = 6.0;\n    \n    @Override\n    public void runOpMode() {\n        // Configure processor with precise calibration\n        aprilTagProcessor = new AprilTagProcessor.Builder()\n            .setTagLibrary(AprilTagLibrary.getCurrentGameTagLibrary())\n            .setPoseSolver(new SingleTagPoseSolver(\n                new Size(TAG_SIZE, TAG_SIZE),\n                FOCAL_LENGTH_X, FOCAL_LENGTH_Y,\n                PRINCIPAL_POINT_X, PRINCIPAL_POINT_Y\n            ))\n            .build();\n        \n        visionPortal = new VisionPortal.Builder()\n            .setCamera(hardwareMap.get(WebcamName.class, \"Webcam 1\"))\n            .addProcessor(aprilTagProcessor)\n            .build();\n        \n        waitForStart();\n        \n        while (opModeIsActive()) {\n            List<AprilTagDetection> detections = aprilTagProcessor.getDetections();\n            processPoseEstimations(detections);\n            telemetry.update();\n        }\n    }\n    \n    private void processPoseEstimations(List<AprilTagDetection> detections) {\n        for (AprilTagDetection detection : detections) {\n            // Get pose in camera coordinates\n            Pose2d cameraPose = detection.ftcPose.toPose2d();\n            \n            // Convert to FTC coordinates (if needed)\n            Pose2d ftcPose = convertToFTCCoordinates(cameraPose);\n            \n            // Calculate field position based on known tag positions\n            Pose2d fieldPose = calculateFieldPosition(detection.id, ftcPose);\n            \n            telemetry.addData(\"Tag %d Camera Pose\", \n                \"X: %.2f, Y: %.2f, Heading: %.2f\", \n                cameraPose.getX(), cameraPose.getY(), Math.toDegrees(cameraPose.getHeading()));\n            \n            telemetry.addData(\"Tag %d FTC Pose\", \n                \"X: %.2f, Y: %.2f, Heading: %.2f\", \n                ftcPose.getX(), ftcPose.getY(), Math.toDegrees(ftcPose.getHeading()));\n            \n            telemetry.addData(\"Tag %d Field Pose\", \n                \"X: %.2f, Y: %.2f, Heading: %.2f\", \n                fieldPose.getX(), fieldPose.getY(), Math.toDegrees(fieldPose.getHeading()));\n        }\n    }\n    \n    private Pose2d convertToFTCCoordinates(Pose2d cameraPose) {\n        // Convert from camera coordinates to FTC coordinates\n        // Camera: X-right, Y-down, Z-forward\n        // FTC: X-forward, Y-left, Z-up\n        double ftcX = cameraPose.getY(); // Camera Y becomes FTC X\n        double ftcY = -cameraPose.getX(); // Negative camera X becomes FTC Y\n        double ftcHeading = -cameraPose.getHeading(); // Invert heading\n        \n        return new Pose2d(ftcX, ftcY, ftcHeading);\n    }\n    \n    private Pose2d calculateFieldPosition(int tagId, Pose2d relativePose) {\n        // This would contain the known field positions of each tag\n        // For now, return a placeholder\n        return relativePose;\n    }\n}"
    },
    {
      "type": "text",
      "title": "Multi-Tag Fusion and Filtering",
      "content": "When multiple AprilTags are visible, you can combine their information for more robust and accurate positioning. Multi-tag fusion provides redundancy and improved accuracy.<br><br><strong>Fusion Strategies:</strong><br>• <strong>Weighted Averaging:</strong> Combine poses based on detection confidence<br>• <strong>Outlier Rejection:</strong> Remove inconsistent detections<br>• <strong>Kalman Filtering:</strong> Smooth pose estimates over time<br>• <strong>Consensus Methods:</strong> Use majority agreement for reliability<br><br><strong>Filtering Techniques:</strong><br>• <strong>Distance Filtering:</strong> Prefer closer tags for better accuracy<br>• <strong>Confidence Filtering:</strong> Use only high-confidence detections<br>• <strong>Temporal Filtering:</strong> Smooth results over multiple frames<br>• <strong>Spatial Filtering:</strong> Check for reasonable pose consistency"
    },
    {
      "type": "code",
      "title": "Multi-Tag Fusion Implementation",
      "content": "Example of multi-tag fusion and filtering:",
      "code": "public class MultiTagFusionOpMode extends LinearOpMode {\n    private VisionPortal visionPortal;\n    private AprilTagProcessor aprilTagProcessor;\n    \n    // Filtering parameters\n    private static final double MIN_CONFIDENCE = 0.8;\n    private static final double MAX_DISTANCE = 120.0; // inches\n    private static final double POSE_CONSISTENCY_THRESHOLD = 10.0; // inches\n    \n    @Override\n    public void runOpMode() {\n        aprilTagProcessor = new AprilTagProcessor.Builder()\n            .setTagLibrary(AprilTagLibrary.getCurrentGameTagLibrary())\n            .build();\n        \n        visionPortal = new VisionPortal.Builder()\n            .setCamera(hardwareMap.get(WebcamName.class, \"Webcam 1\"))\n            .addProcessor(aprilTagProcessor)\n            .build();\n        \n        waitForStart();\n        \n        while (opModeIsActive()) {\n            List<AprilTagDetection> detections = aprilTagProcessor.getDetections();\n            Pose2d fusedPose = fuseMultipleTags(detections);\n            \n            if (fusedPose != null) {\n                telemetry.addData(\"Fused Pose\", \n                    \"X: %.2f, Y: %.2f, Heading: %.2f\", \n                    fusedPose.getX(), fusedPose.getY(), Math.toDegrees(fusedPose.getHeading()));\n            } else {\n                telemetry.addData(\"Fused Pose\", \"No valid tags\");\n            }\n            \n            telemetry.update();\n        }\n    }\n    \n    private Pose2d fuseMultipleTags(List<AprilTagDetection> detections) {\n        if (detections.isEmpty()) {\n            return null;\n        }\n        \n        // Filter detections\n        List<AprilTagDetection> validDetections = filterDetections(detections);\n        \n        if (validDetections.isEmpty()) {\n            return null;\n        }\n        \n        // Simple weighted average based on distance\n        double totalWeight = 0.0;\n        double weightedX = 0.0;\n        double weightedY = 0.0;\n        double weightedHeading = 0.0;\n        \n        for (AprilTagDetection detection : validDetections) {\n            // Weight inversely proportional to distance\n            double weight = 1.0 / (detection.ftcPose.range + 1.0);\n            \n            Pose2d pose = detection.ftcPose.toPose2d();\n            \n            weightedX += pose.getX() * weight;\n            weightedY += pose.getY() * weight;\n            weightedHeading += pose.getHeading() * weight;\n            totalWeight += weight;\n        }\n        \n        if (totalWeight > 0) {\n            return new Pose2d(\n                weightedX / totalWeight,\n                weightedY / totalWeight,\n                weightedHeading / totalWeight\n            );\n        }\n        \n        return null;\n    }\n    \n    private List<AprilTagDetection> filterDetections(List<AprilTagDetection> detections) {\n        List<AprilTagDetection> filtered = new ArrayList<>();\n        \n        for (AprilTagDetection detection : detections) {\n            // Check for pose ambiguity\n            if (detection.pose.poseIsAmbiguous) {\n                continue;\n            }\n            \n            // Check distance\n            if (detection.ftcPose.range > MAX_DISTANCE) {\n                continue;\n            }\n            \n            // Check confidence (if available)\n            if (detection.ftcPose.confidence < MIN_CONFIDENCE) {\n                continue;\n            }\n            \n            filtered.add(detection);\n        }\n        \n        return filtered;\n    }\n}"
    },
    {
      "type": "exercise-box",
      "title": "AprilTag Localization Exercise",
      "description": "Create a robot localization system using AprilTags",
      "tasks": [
        "Set up AprilTag detection with proper camera calibration",
        "Implement pose estimation for detected tags",
        "Create a multi-tag fusion system for improved accuracy",
        "Add filtering to handle detection noise and outliers",
        "Test the system with multiple tags in different positions"
      ],
      "content": "Build a complete robot localization system using AprilTags. The system should provide accurate position and orientation estimates by fusing information from multiple detected tags."
    },
    {
      "type": "link-grid",
      "title": "Additional Resources",
      "links": [
        "<a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/apriltag.html\" target=\"_blank\">FTC AprilTag Documentation</a>",
        "<a href=\"https://gm0.org/en/latest/docs/software/tutorials/apriltag.html\" target=\"_blank\">gm0: AprilTag Tutorial</a>",
        "<a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/apriltag.html#pose-estimation\" target=\"_blank\">FTC Pose Estimation</a>",
        "<a href=\"https://gm0.org/en/latest/docs/software/tutorials/apriltag.html#multiple-tags\" target=\"_blank\">gm0: Multiple Tags</a>"
      ]
    }
  ]
} 