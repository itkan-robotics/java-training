{
  "title": "Vision Introduction",
  "sections": [
    {
      "type": "text",
      "title": "What is Computer Vision?",
      "content": "Computer vision is the field of artificial intelligence that enables computers to interpret and understand visual information from the world around them. In FTC robotics, computer vision allows your robot to 'see' and make intelligent decisions based on what it observes through its camera.<br><br>Think of computer vision like human vision: just as your eyes capture light and your brain processes that information to understand what you're seeing, a robot's camera captures images and computer vision algorithms process that data to extract meaningful information."
    },
    {
      "type": "rules-box",
      "title": "Why Computer Vision Matters in FTC",
      "items": [
        "Autonomous navigation and positioning using visual landmarks",
        "Object detection and classification for game elements",
        "Precise alignment and targeting for scoring mechanisms",
        "Obstacle detection and avoidance",
        "Team element identification and tracking",
        "Field state analysis and strategic decision making"
      ]
    },
    {
      "type": "text",
      "title": "FTC Vision System Overview",
      "content": "FTC provides a comprehensive vision system built around the Control Hub's integrated camera and the Expansion Hub's processing capabilities. The system is designed to be both powerful and accessible, offering multiple approaches from simple color detection to advanced machine learning.<br><br>The FTC vision ecosystem includes:<br>• <strong>Control Hub Camera:</strong> Built-in camera for image capture<br>• <strong>Vision Portal:</strong> User-friendly interface for vision processing<br>• <strong>OpenCV Integration:</strong> Advanced computer vision library<br>• <strong>TensorFlow Lite:</strong> Machine learning capabilities<br>• <strong>AprilTag Support:</strong> Fiducial marker detection"
    },
    {
      "type": "code",
      "title": "Basic Vision Pipeline Structure",
      "content": "Every vision system follows a basic pipeline structure. Here's a simple example of how to set up a basic vision pipeline in FTC:",
      "code": "public class BasicVisionPipeline extends OpenCvPipeline {\n    @Override\n    public Mat processFrame(Mat input) {\n        // 1. Image Capture (handled automatically)\n        // 2. Preprocessing\n        Mat processed = preprocessImage(input);\n        \n        // 3. Feature Detection\n        detectFeatures(processed);\n        \n        // 4. Analysis\n        analyzeResults();\n        \n        // 5. Output\n        return processed;\n    }\n    \n    private Mat preprocessImage(Mat input) {\n        // Convert to different color space if needed\n        Mat converted = new Mat();\n        Imgproc.cvtColor(input, converted, Imgproc.COLOR_RGB2HSV);\n        return converted;\n    }\n    \n    private void detectFeatures(Mat image) {\n        // Add your detection logic here\n        // This could be color detection, contour finding, etc.\n    }\n    \n    private void analyzeResults() {\n        // Analyze detected features and make decisions\n        // Update telemetry with results\n    }\n}"
    },
    {
      "type": "text",
      "title": "Vision Pipeline Architecture",
      "content": "A vision pipeline is a series of processing stages that transform raw camera images into actionable information. Understanding this architecture is crucial for designing efficient and reliable vision systems.<br><br>The standard FTC vision pipeline consists of four main stages:<br><br><strong>1. Image Capture:</strong> The camera captures a frame from the environment<br><strong>2. Preprocessing:</strong> Image enhancement, noise reduction, and format conversion<br><strong>3. Feature Detection:</strong> Identifying relevant objects, colors, or patterns<br><strong>4. Analysis & Output:</strong> Interpreting results and providing data to the robot"
    },
    {
      "type": "emphasis-box",
      "title": "Performance Considerations",
      "content": "Vision processing is computationally intensive and can significantly impact your robot's performance. Key considerations include:<br><br><strong>Frame Rate:</strong> Higher frame rates provide more responsive vision but require more processing power<br><strong>Resolution:</strong> Higher resolution provides more detail but increases processing time<br><strong>Processing Complexity:</strong> More complex algorithms provide better results but take longer to execute<br><strong>Memory Usage:</strong> Vision processing can consume significant memory resources<br><br>For FTC applications, aim for 10-30 FPS with reasonable resolution (640x480 or 1280x720) to balance performance and responsiveness."
    },
    {
      "type": "code",
      "title": "Performance Monitoring Example",
      "content": "Here's how to monitor vision processing performance in your FTC code:",
      "code": "public class PerformanceMonitoringPipeline extends OpenCvPipeline {\n    private long frameStartTime;\n    private int frameCount = 0;\n    private double averageFPS = 0;\n    \n    @Override\n    public Mat processFrame(Mat input) {\n        frameStartTime = System.nanoTime();\n        \n        // Your vision processing here\n        Mat result = performVisionProcessing(input);\n        \n        // Calculate performance metrics\n        long processingTime = System.nanoTime() - frameStartTime;\n        frameCount++;\n        \n        // Update FPS calculation every 30 frames\n        if (frameCount % 30 == 0) {\n            averageFPS = 1.0 / (processingTime / 1_000_000_000.0);\n        }\n        \n        // Display performance metrics\n        displayPerformanceMetrics(processingTime, averageFPS);\n        \n        return result;\n    }\n    \n    private void displayPerformanceMetrics(long processingTime, double fps) {\n        telemetry.addData(\"Vision Processing Time\", \"%.2f ms\", processingTime / 1_000_000.0);\n        telemetry.addData(\"Vision FPS\", \"%.1f\", fps);\n        telemetry.update();\n    }\n}"
    },
    {
      "type": "exercise-box",
      "title": "Vision System Planning Exercise",
      "description": "Plan a vision system for a hypothetical FTC game scenario",
      "tasks": [
        "Identify what visual information your robot needs to detect",
        "Determine the optimal camera placement and orientation",
        "Choose appropriate vision processing techniques (color detection, AprilTags, ML, etc.)",
        "Estimate the required frame rate and resolution",
        "Plan how vision data will integrate with other robot subsystems"
      ],
      "content": "Scenario: Your robot needs to detect game elements of different colors and navigate to specific positions marked by AprilTags. The robot operates in varying lighting conditions and must respond quickly to changing field conditions."
    },
    {
      "type": "link-grid",
      "title": "Additional Resources",
      "links": [
        "<a href=\"https://gm0.org/en/latest/docs/software/tutorials/vision.html\" target=\"_blank\">gm0: Vision Tutorial</a>",
        "<a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/vision-overview.html\" target=\"_blank\">FTC Vision Overview</a>",
        "<a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/vision-pipeline.html\" target=\"_blank\">FTC Vision Pipeline</a>",
        "<a href=\"https://gm0.org/en/latest/docs/software/tutorials/vision.html#performance-considerations\" target=\"_blank\">gm0: Performance Considerations</a>"
      ]
    }
  ]
}
