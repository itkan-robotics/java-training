{
  "title": "FTC Vision Portal",
  "sections": [
    {
      "type": "text",
      "title": "What is Vision Portal?",
      "content": "FTC Vision Portal is a powerful, user-friendly interface that allows you to create and configure vision processing pipelines without extensive programming knowledge. It provides a visual drag-and-drop interface for building complex vision systems using pre-built processors and filters.<br><br>Vision Portal is particularly valuable for teams that want to implement vision quickly or for students who are learning computer vision concepts. It abstracts away much of the complexity while still providing access to advanced features."
    },
    {
      "type": "rules-box",
      "title": "Vision Portal Advantages",
      "items": [
        "No programming required for basic vision tasks",
        "Real-time preview and testing capabilities",
        "Built-in processors for common FTC vision needs",
        "Easy parameter tuning and optimization",
        "Visual pipeline design and debugging",
        "Export capabilities for integration with robot code"
      ]
    },
    {
      "type": "text",
      "title": "Setting Up Vision Portal",
      "content": "Vision Portal is accessed through the FTC Driver Station app. To get started:<br><br><strong>1. Connect to Robot:</strong> Ensure your Driver Station is connected to the Control Hub<br><strong>2. Access Vision Portal:</strong> In the Driver Station, tap the 'Vision Portal' button<br><strong>3. Create New Pipeline:</strong> Start with a blank pipeline or use a template<br><strong>4. Configure Camera:</strong> Set up camera parameters and calibration<br><strong>5. Add Processors:</strong> Drag and drop processors to build your pipeline<br><strong>6. Test and Tune:</strong> Use live preview to test and optimize your pipeline"
    },
    {
      "type": "code",
      "title": "Vision Portal Integration in Robot Code",
      "content": "Once you've created a pipeline in Vision Portal, you can integrate it into your robot code:",
      "code": "public class VisionPortalOpMode extends LinearOpMode {\n    private VisionPortal visionPortal;\n    private AprilTagProcessor aprilTagProcessor;\n    private ColorBlobProcessor colorBlobProcessor;\n    \n    @Override\n    public void runOpMode() {\n        // Initialize vision processors\n        aprilTagProcessor = new AprilTagProcessor.Builder()\n            .setTagLibrary(AprilTagLibrary.getCurrentGameTagLibrary())\n            .build();\n            \n        colorBlobProcessor = new ColorBlobProcessor.Builder()\n            .setColor(Color.RED)\n            .setColorSpace(ColorSpace.HSV)\n            .build();\n        \n        // Build Vision Portal with processors\n        visionPortal = new VisionPortal.Builder()\n            .setCamera(hardwareMap.get(WebcamName.class, \"Webcam 1\"))\n            .addProcessor(aprilTagProcessor)\n            .addProcessor(colorBlobProcessor)\n            .setCameraResolution(new Size(640, 480))\n            .setStreamFormat(VisionPortal.StreamFormat.YUY2)\n            .enableLiveView(true)\n            .enableCameraMonitoring(true)\n            .build();\n        \n        waitForStart();\n        \n        while (opModeIsActive()) {\n            // Access processor results\n            List<AprilTagDetection> aprilTagDetections = aprilTagProcessor.getDetections();\n            List<Recognition> colorDetections = colorBlobProcessor.getRecognitions();\n            \n            // Process results and control robot\n            processVisionResults(aprilTagDetections, colorDetections);\n            \n            telemetry.update();\n        }\n    }\n    \n    private void processVisionResults(List<AprilTagDetection> tags, List<Recognition> colors) {\n        // Your vision-based control logic here\n        if (!tags.isEmpty()) {\n            AprilTagDetection tag = tags.get(0);\n            telemetry.addData(\"AprilTag ID\", tag.id);\n            telemetry.addData(\"Tag Position\", \"X: %.2f, Y: %.2f\", tag.ftcPose.x, tag.ftcPose.y);\n        }\n        \n        if (!colors.isEmpty()) {\n            Recognition color = colors.get(0);\n            telemetry.addData(\"Color Detected\", color.getLabel());\n            telemetry.addData(\"Confidence\", \"%.2f\", color.getConfidence());\n        }\n    }\n}"
    },
    {
      "type": "text",
      "title": "Camera Configuration and Calibration",
      "content": "Proper camera configuration is essential for reliable vision processing. Vision Portal provides tools for camera setup and calibration.<br><br><strong>Camera Parameters:</strong><br>• <strong>Resolution:</strong> Choose appropriate resolution (640x480, 1280x720, etc.)<br>• <strong>Frame Rate:</strong> Set frame rate based on processing requirements<br>• <strong>Exposure:</strong> Adjust exposure for different lighting conditions<br>• <strong>Gain:</strong> Control sensor sensitivity<br><br><strong>Calibration:</strong><br>• <strong>Intrinsic Calibration:</strong> Correct lens distortion and focal length<br>• <strong>Extrinsic Calibration:</strong> Determine camera position and orientation<br>• <strong>Color Calibration:</strong> Adjust for lighting variations"
    },
    {
      "type": "emphasis-box",
      "title": "Built-in Vision Processors",
      "content": "Vision Portal includes several powerful built-in processors designed specifically for FTC applications:<br><br><strong>AprilTag Processor:</strong> Detects and tracks AprilTag fiducial markers for precise positioning<br><strong>Color Blob Processor:</strong> Identifies regions of specific colors in the image<br><strong>Object Detection Processor:</strong> Uses machine learning models to detect objects<br><strong>Contour Processor:</strong> Finds and analyzes shapes and contours<br><strong>Template Matching Processor:</strong> Locates specific patterns or templates in images<br><strong>Custom Color Thresholding:</strong> Advanced color detection with multiple thresholds"
    },
    {
      "type": "code",
      "title": "AprilTag Processor Configuration",
      "content": "Here's how to configure an AprilTag processor in your robot code:",
      "code": "// Configure AprilTag processor with specific settings\nAprilTagProcessor aprilTagProcessor = new AprilTagProcessor.Builder()\n    .setTagLibrary(AprilTagLibrary.getCurrentGameTagLibrary())\n    .setTagFamily(AprilTagProcessor.TagFamily.TAG_36h11)\n    .setTagModel(AprilTagProcessor.TagModel.TAG_36h11)\n    .setSingleTagFamilySmoothingWindow(3)\n    .setMultiTagFamilySmoothingWindow(1)\n    .setPoseSolver(new SingleTagPoseSolver(\n        new Size(6, 6), // Tag size in inches\n        578.272,       // Focal length X\n        578.272,       // Focal length Y\n        402.145,       // Principal point X\n        221.506        // Principal point Y\n    ))\n    .build();\n\n// Add processor to Vision Portal\nvisionPortal = new VisionPortal.Builder()\n    .setCamera(hardwareMap.get(WebcamName.class, \"Webcam 1\"))\n    .addProcessor(aprilTagProcessor)\n    .setCameraResolution(new Size(640, 480))\n    .build();\n\n// Access detection results\nList<AprilTagDetection> detections = aprilTagProcessor.getDetections();\nfor (AprilTagDetection detection : detections) {\n    if (detection.metadata != null) {\n        telemetry.addData(\"Tag ID\", detection.id);\n        telemetry.addData(\"Tag Name\", detection.metadata.name);\n        telemetry.addData(\"Tag Position\", \n            \"X: %.2f, Y: %.2f, Z: %.2f\", \n            detection.ftcPose.x, detection.ftcPose.y, detection.ftcPose.z);\n        telemetry.addData(\"Tag Rotation\", \n            \"Roll: %.2f, Pitch: %.2f, Yaw: %.2f\", \n            detection.ftcPose.roll, detection.ftcPose.pitch, detection.ftcPose.yaw);\n    }\n}"
    },
    {
      "type": "code",
      "title": "Color Blob Processor Example",
      "content": "Example of configuring a color blob processor for detecting specific colors:",
      "code": "// Configure color blob processor for red detection\nColorBlobProcessor redBlobProcessor = new ColorBlobProcessor.Builder()\n    .setColor(Color.RED)\n    .setColorSpace(ColorSpace.HSV)\n    .setMinArea(500) // Minimum blob area in pixels\n    .setMaxArea(10000) // Maximum blob area in pixels\n    .setMinCircularity(0.3) // Minimum circularity (0-1)\n    .setMaxCircularity(1.0) // Maximum circularity (0-1)\n    .build();\n\n// Configure color blob processor for blue detection\nColorBlobProcessor blueBlobProcessor = new ColorBlobProcessor.Builder()\n    .setColor(Color.BLUE)\n    .setColorSpace(ColorSpace.HSV)\n    .setMinArea(500)\n    .setMaxArea(10000)\n    .build();\n\n// Add both processors to Vision Portal\nvisionPortal = new VisionPortal.Builder()\n    .setCamera(hardwareMap.get(WebcamName.class, \"Webcam 1\"))\n    .addProcessor(redBlobProcessor)\n    .addProcessor(blueBlobProcessor)\n    .build();\n\n// Process color detection results\nList<Recognition> redDetections = redBlobProcessor.getRecognitions();\nList<Recognition> blueDetections = blueBlobProcessor.getRecognitions();\n\nfor (Recognition red : redDetections) {\n    telemetry.addData(\"Red Blob\", \"Area: %.0f, Center: (%.0f, %.0f)\", \n        red.getArea(), red.getLeft(), red.getTop());\n}\n\nfor (Recognition blue : blueDetections) {\n    telemetry.addData(\"Blue Blob\", \"Area: %.0f, Center: (%.0f, %.0f)\", \n        blue.getArea(), blue.getLeft(), blue.getTop());\n}"
    },
    {
      "type": "text",
      "title": "Pipeline Configuration and Testing",
      "content": "Building an effective vision pipeline requires careful planning and testing. Start simple and gradually add complexity.<br><br><strong>Pipeline Design Principles:</strong><br>• <strong>Start Simple:</strong> Begin with basic detection and add complexity as needed<br>• <strong>Test Incrementally:</strong> Test each processor individually before combining<br>• <strong>Optimize Parameters:</strong> Use live preview to tune parameters for your environment<br>• <strong>Consider Performance:</strong> Monitor processing time and adjust complexity accordingly<br>• <strong>Plan for Failure:</strong> Include fallback strategies when vision detection fails"
    },
    {
      "type": "exercise-box",
      "title": "Vision Portal Pipeline Design",
      "description": "Design a vision pipeline for detecting game elements and AprilTags",
      "tasks": [
        "Create a pipeline that detects red and blue game elements",
        "Add AprilTag detection for robot positioning",
        "Configure appropriate camera settings for your environment",
        "Test the pipeline in different lighting conditions",
        "Optimize parameters for maximum reliability and speed"
      ],
      "content": "Use Vision Portal to create a pipeline that can detect colored game elements and AprilTags simultaneously. Test it in various lighting conditions and document the optimal parameters for your setup."
    },
    {
      "type": "link-grid",
      "title": "Additional Resources",
      "links": [
        "<a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/vision-portal.html\" target=\"_blank\">FTC Vision Portal Documentation</a>",
        "<a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/vision-portal.html#camera-configuration\" target=\"_blank\">FTC Camera Configuration</a>",
        "<a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/vision-portal.html#processors\" target=\"_blank\">FTC Vision Processors</a>",
        "<a href=\"https://gm0.org/en/latest/docs/software/tutorials/vision-portal.html\" target=\"_blank\">gm0: Vision Portal Tutorial</a>"
      ]
    }
  ]
} 