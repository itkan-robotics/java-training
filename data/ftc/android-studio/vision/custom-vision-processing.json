{
  "title": "Custom Vision Processing",
  "sections": [
    {
      "type": "text",
      "title": "Custom Vision Pipeline Design",
      "content": "While built-in processors are powerful, custom vision pipelines allow you to create specialized solutions for your specific robot and game requirements. Custom pipelines give you complete control over the image processing workflow, enabling you to optimize for your particular use case.<br><br>Designing effective custom pipelines requires understanding of both the technical requirements and the practical constraints of FTC robotics. A well-designed pipeline should be efficient, reliable, and maintainable."
    },
    {
      "type": "rules-box",
      "title": "Pipeline Design Principles",
      "items": [
        "Modular design with clear separation of concerns",
        "Efficient memory management and resource usage",
        "Robust error handling and graceful degradation",
        "Configurable parameters for easy tuning",
        "Comprehensive testing and validation",
        "Documentation of design decisions and trade-offs"
      ]
    },
    {
      "type": "text",
      "title": "Vision Pipeline Architecture",
      "content": "A well-designed vision pipeline follows a clear structure that transforms raw camera input into actionable robot control data.<br><br><strong>Pipeline Stages:</strong><br>• <strong>Input Stage:</strong> Image capture and initial preprocessing<br>• <strong>Processing Stage:</strong> Feature detection and analysis<br>• <strong>Analysis Stage:</strong> Data interpretation and decision making<br>• <strong>Output Stage:</strong> Results formatting and robot control data<br><br><strong>Design Considerations:</strong><br>• <strong>Performance:</strong> Each stage should be optimized for speed<br>• <strong>Reliability:</strong> Pipeline should handle edge cases gracefully<br>• <strong>Maintainability:</strong> Code should be clear and well-documented<br>• <strong>Flexibility:</strong> Parameters should be easily adjustable"
    },
    {
      "type": "code",
      "title": "Custom Vision Pipeline Framework",
      "content": "A framework for building custom vision pipelines:",
      "code": "public abstract class CustomVisionPipeline extends OpenCvPipeline {\n    // Pipeline configuration\n    protected PipelineConfig config;\n    protected PipelineState state;\n    \n    // Processing stages\n    protected Mat inputImage;\n    protected Mat processedImage;\n    protected Mat outputImage;\n    \n    // Results storage\n    protected List<DetectionResult> detections;\n    protected PipelineMetrics metrics;\n    \n    public CustomVisionPipeline(PipelineConfig config) {\n        this.config = config;\n        this.state = new PipelineState();\n        this.detections = new ArrayList<>();\n        this.metrics = new PipelineMetrics();\n    }\n    \n    @Override\n    public Mat processFrame(Mat input) {\n        long startTime = System.nanoTime();\n        \n        try {\n            // Stage 1: Input processing\n            inputImage = input.clone();\n            preprocessInput(inputImage);\n            \n            // Stage 2: Feature detection\n            processedImage = detectFeatures(inputImage);\n            \n            // Stage 3: Analysis\n            analyzeFeatures(processedImage);\n            \n            // Stage 4: Output generation\n            outputImage = generateOutput(inputImage);\n            \n            // Update metrics\n            updateMetrics(System.nanoTime() - startTime);\n            \n        } catch (Exception e) {\n            // Handle errors gracefully\n            handleProcessingError(e);\n            outputImage = input.clone();\n        }\n        \n        return outputImage;\n    }\n    \n    // Abstract methods to be implemented by subclasses\n    protected abstract void preprocessInput(Mat input);\n    protected abstract Mat detectFeatures(Mat input);\n    protected abstract void analyzeFeatures(Mat processed);\n    protected abstract Mat generateOutput(Mat input);\n    \n    // Utility methods\n    protected void updateMetrics(long processingTime) {\n        metrics.updateProcessingTime(processingTime);\n        metrics.updateDetectionCount(detections.size());\n    }\n    \n    protected void handleProcessingError(Exception e) {\n        telemetry.addData(\"Pipeline Error\", e.getMessage());\n        detections.clear();\n    }\n    \n    // Getter methods for accessing results\n    public List<DetectionResult> getDetections() {\n        return new ArrayList<>(detections);\n    }\n    \n    public PipelineMetrics getMetrics() {\n        return metrics;\n    }\n    \n    public PipelineState getState() {\n        return state;\n    }\n}\n\n// Supporting classes\nclass PipelineConfig {\n    public double minConfidence = 0.7;\n    public int maxDetections = 10;\n    public boolean enableDebug = false;\n    // Add other configuration parameters as needed\n}\n\nclass PipelineState {\n    public boolean isProcessing = false;\n    public long lastUpdateTime = 0;\n    public int frameCount = 0;\n}\n\nclass PipelineMetrics {\n    private double averageProcessingTime = 0;\n    private int totalDetections = 0;\n    private int frameCount = 0;\n    \n    public void updateProcessingTime(long time) {\n        averageProcessingTime = (averageProcessingTime * 0.9) + \n            (time / 1_000_000.0 * 0.1);\n    }\n    \n    public void updateDetectionCount(int count) {\n        totalDetections += count;\n        frameCount++;\n    }\n    \n    public double getAverageProcessingTime() { return averageProcessingTime; }\n    public int getTotalDetections() { return totalDetections; }\n    public int getFrameCount() { return frameCount; }\n}\n\nclass DetectionResult {\n    public String label;\n    public double confidence;\n    public Point center;\n    public Rect boundingBox;\n    public Map<String, Object> properties;\n    \n    public DetectionResult(String label, double confidence, Point center, Rect bbox) {\n        this.label = label;\n        this.confidence = confidence;\n        this.center = center;\n        this.boundingBox = bbox;\n        this.properties = new HashMap<>();\n    }\n}"
    },
    {
      "type": "text",
      "title": "Custom Filter Development",
      "content": "Custom filters are the building blocks of vision pipelines. They perform specific operations on images to extract the information you need.<br><br><strong>Filter Types:</strong><br>• <strong>Preprocessing Filters:</strong> Noise reduction, normalization, format conversion<br>• <strong>Feature Detection Filters:</strong> Edge detection, corner detection, blob detection<br>• <strong>Segmentation Filters:</strong> Color-based segmentation, thresholding, watershed<br>• <strong>Analysis Filters:</strong> Shape analysis, texture analysis, pattern matching<br>• <strong>Post-processing Filters:</strong> Filtering, smoothing, result validation<br><br><strong>Filter Design Principles:</strong><br>• <strong>Single Responsibility:</strong> Each filter should do one thing well<br>• <strong>Configurable Parameters:</strong> Filters should be easily tunable<br>• <strong>Error Handling:</strong> Filters should handle edge cases gracefully<br>• <strong>Performance Optimization:</strong> Filters should be efficient"
    },
    {
      "type": "code",
      "title": "Custom Filter Implementation",
      "content": "Example of implementing custom filters:",
      "code": "public class CustomFilters {\n    \n    // Color-based segmentation filter\n    public static Mat colorSegmentationFilter(Mat input, Scalar lowerBound, Scalar upperBound) {\n        Mat hsv = new Mat();\n        Mat mask = new Mat();\n        Mat result = new Mat();\n        \n        try {\n            // Convert to HSV color space\n            Imgproc.cvtColor(input, hsv, Imgproc.COLOR_RGB2HSV);\n            \n            // Create color mask\n            Core.inRange(hsv, lowerBound, upperBound, mask);\n            \n            // Apply morphological operations to clean up mask\n            Mat kernel = Imgproc.getStructuringElement(Imgproc.MORPH_ELLIPSE, new Size(5, 5));\n            Imgproc.morphologyEx(mask, mask, Imgproc.MORPH_CLOSE, kernel);\n            Imgproc.morphologyEx(mask, mask, Imgproc.MORPH_OPEN, kernel);\n            \n            // Apply mask to original image\n            Core.bitwise_and(input, input, result, mask);\n            \n        } finally {\n            hsv.release();\n            mask.release();\n        }\n        \n        return result;\n    }\n    \n    // Edge detection filter\n    public static Mat edgeDetectionFilter(Mat input, double threshold1, double threshold2) {\n        Mat gray = new Mat();\n        Mat blurred = new Mat();\n        Mat edges = new Mat();\n        \n        try {\n            // Convert to grayscale\n            Imgproc.cvtColor(input, gray, Imgproc.COLOR_RGB2GRAY);\n            \n            // Apply Gaussian blur\n            Imgproc.GaussianBlur(gray, blurred, new Size(5, 5), 0);\n            \n            // Apply Canny edge detection\n            Imgproc.Canny(blurred, edges, threshold1, threshold2);\n            \n        } finally {\n            gray.release();\n            blurred.release();\n        }\n        \n        return edges;\n    }\n    \n    // Contour analysis filter\n    public static List<MatOfPoint> contourAnalysisFilter(Mat input, double minArea, double maxArea) {\n        List<MatOfPoint> contours = new ArrayList<>();\n        Mat hierarchy = new Mat();\n        \n        try {\n            // Find contours\n            Imgproc.findContours(input, contours, hierarchy, \n                Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);\n            \n            // Filter contours by area\n            contours = contours.stream()\n                .filter(contour -> {\n                    double area = Imgproc.contourArea(contour);\n                    return area >= minArea && area <= maxArea;\n                })\n                .collect(Collectors.toList());\n            \n        } finally {\n            hierarchy.release();\n        }\n        \n        return contours;\n    }\n    \n    // Shape analysis filter\n    public static ShapeAnalysisResult shapeAnalysisFilter(MatOfPoint contour) {\n        ShapeAnalysisResult result = new ShapeAnalysisResult();\n        \n        // Calculate basic properties\n        result.area = Imgproc.contourArea(contour);\n        result.perimeter = Imgproc.arcLength(new MatOfPoint2f(contour.toArray()), true);\n        \n        // Calculate bounding rectangle\n        result.boundingRect = Imgproc.boundingRect(contour);\n        \n        // Calculate aspect ratio\n        result.aspectRatio = (double) result.boundingRect.width / result.boundingRect.height;\n        \n        // Calculate circularity\n        result.circularity = (4 * Math.PI * result.area) / (result.perimeter * result.perimeter);\n        \n        // Determine shape type\n        result.shapeType = determineShapeType(result);\n        \n        return result;\n    }\n    \n    private static String determineShapeType(ShapeAnalysisResult result) {\n        if (result.circularity > 0.8) {\n            return \"CIRCLE\";\n        } else if (Math.abs(result.aspectRatio - 1.0) < 0.2) {\n            return \"SQUARE\";\n        } else if (result.aspectRatio > 2.0 || result.aspectRatio < 0.5) {\n            return \"RECTANGLE\";\n        } else {\n            return \"UNKNOWN\";\n        }\n    }\n}\n\nclass ShapeAnalysisResult {\n    public double area;\n    public double perimeter;\n    public Rect boundingRect;\n    public double aspectRatio;\n    public double circularity;\n    public String shapeType;\n}"
    },
    {
      "type": "text",
      "title": "Multi-Stage Processing Pipelines",
      "content": "Complex vision tasks often require multiple processing stages that build upon each other. Multi-stage pipelines allow you to break down complex problems into manageable steps.<br><br><strong>Pipeline Composition:</strong><br>• <strong>Sequential Processing:</strong> Each stage processes the output of the previous stage<br>• <strong>Parallel Processing:</strong> Multiple stages process the same input simultaneously<br>• <strong>Conditional Processing:</strong> Stages are executed based on conditions<br>• <strong>Feedback Loops:</strong> Later stages can influence earlier stages<br><br><strong>Data Flow Management:</strong><br>• <strong>Intermediate Results:</strong> Store and manage data between stages<br>• <strong>Error Propagation:</strong> Handle errors that occur in later stages<br>• <strong>Performance Monitoring:</strong> Track performance of individual stages<br>• <strong>Result Validation:</strong> Verify results at each stage"
    },
    {
      "type": "code",
      "title": "Multi-Stage Pipeline Example",
      "content": "Example of a multi-stage vision pipeline:",
      "code": "public class MultiStageVisionPipeline extends CustomVisionPipeline {\n    \n    // Stage results\n    private Mat colorSegmented;\n    private Mat edgeDetected;\n    private List<MatOfPoint> contours;\n    private List<DetectionResult> shapeDetections;\n    \n    public MultiStageVisionPipeline(PipelineConfig config) {\n        super(config);\n    }\n    \n    @Override\n    protected void preprocessInput(Mat input) {\n        // Stage 1: Color segmentation\n        Scalar lowerRed = new Scalar(0, 100, 100);\n        Scalar upperRed = new Scalar(10, 255, 255);\n        colorSegmented = CustomFilters.colorSegmentationFilter(input, lowerRed, upperRed);\n        \n        // Stage 2: Edge detection\n        edgeDetected = CustomFilters.edgeDetectionFilter(colorSegmented, 50, 150);\n    }\n    \n    @Override\n    protected Mat detectFeatures(Mat input) {\n        // Stage 3: Contour detection\n        contours = CustomFilters.contourAnalysisFilter(edgeDetected, 1000, 50000);\n        \n        // Stage 4: Shape analysis\n        shapeDetections = new ArrayList<>();\n        for (MatOfPoint contour : contours) {\n            ShapeAnalysisResult shapeResult = CustomFilters.shapeAnalysisFilter(contour);\n            \n            // Create detection result\n            Point center = new Point(\n                shapeResult.boundingRect.x + shapeResult.boundingRect.width / 2,\n                shapeResult.boundingRect.y + shapeResult.boundingRect.height / 2\n            );\n            \n            DetectionResult detection = new DetectionResult(\n                shapeResult.shapeType,\n                shapeResult.circularity, // Use circularity as confidence\n                center,\n                shapeResult.boundingRect\n            );\n            \n            detection.properties.put(\"area\", shapeResult.area);\n            detection.properties.put(\"aspectRatio\", shapeResult.aspectRatio);\n            \n            shapeDetections.add(detection);\n        }\n        \n        // Update pipeline detections\n        detections.clear();\n        detections.addAll(shapeDetections);\n        \n        return edgeDetected; // Return processed image for visualization\n    }\n    \n    @Override\n    protected void analyzeFeatures(Mat processed) {\n        // Stage 5: Result analysis and filtering\n        \n        // Filter detections by confidence\n        detections = detections.stream()\n            .filter(detection -> detection.confidence >= config.minConfidence)\n            .collect(Collectors.toList());\n        \n        // Sort by confidence\n        detections.sort((a, b) -> Double.compare(b.confidence, a.confidence));\n        \n        // Limit number of detections\n        if (detections.size() > config.maxDetections) {\n            detections = detections.subList(0, config.maxDetections);\n        }\n        \n        // Update pipeline state\n        state.frameCount++;\n        state.lastUpdateTime = System.currentTimeMillis();\n    }\n    \n    @Override\n    protected Mat generateOutput(Mat input) {\n        // Stage 6: Output generation and visualization\n        Mat output = input.clone();\n        \n        // Draw detection results\n        for (DetectionResult detection : detections) {\n            // Draw bounding rectangle\n            Imgproc.rectangle(output, detection.boundingBox, \n                new Scalar(0, 255, 0), 2);\n            \n            // Draw center point\n            Imgproc.circle(output, detection.center, 5, \n                new Scalar(255, 0, 0), -1);\n            \n            // Draw label\n            Point textPoint = new Point(\n                detection.boundingBox.x, \n                detection.boundingBox.y - 10\n            );\n            Imgproc.putText(output, \n                String.format(\"%s (%.2f)\", detection.label, detection.confidence),\n                textPoint, Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, \n                new Scalar(255, 255, 255), 1);\n        }\n        \n        // Add debug information if enabled\n        if (config.enableDebug) {\n            addDebugInfo(output);\n        }\n        \n        return output;\n    }\n    \n    private void addDebugInfo(Mat output) {\n        // Add processing metrics\n        String debugText = String.format(\n            \"Detections: %d, FPS: %.1f, Time: %.1fms\",\n            detections.size(),\n            1000.0 / metrics.getAverageProcessingTime(),\n            metrics.getAverageProcessingTime()\n        );\n        \n        Imgproc.putText(output, debugText, \n            new Point(10, 30), Imgproc.FONT_HERSHEY_SIMPLEX, \n            0.7, new Scalar(0, 255, 255), 2);\n    }\n    \n    // Cleanup method\n    public void cleanup() {\n        if (colorSegmented != null) colorSegmented.release();\n        if (edgeDetected != null) edgeDetected.release();\n        if (contours != null) contours.clear();\n    }\n}"
    },
    {
      "type": "text",
      "title": "Performance Profiling and Optimization",
      "content": "Vision processing must meet real-time requirements for effective robot control. Performance profiling helps identify bottlenecks and optimization opportunities.<br><br><strong>Profiling Techniques:</strong><br>• <strong>Timing Analysis:</strong> Measure execution time of each pipeline stage<br>• <strong>Memory Profiling:</strong> Monitor memory allocation and garbage collection<br>• <strong>CPU Profiling:</strong> Identify CPU-intensive operations<br>• <strong>Bottleneck Identification:</strong> Find the slowest parts of the pipeline<br><br><strong>Optimization Strategies:</strong><br>• <strong>Algorithm Optimization:</strong> Use more efficient algorithms<br>• <strong>Memory Management:</strong> Reuse objects and minimize allocations<br>• <strong>Parallel Processing:</strong> Use multiple threads where possible<br>• <strong>Resolution Reduction:</strong> Process smaller images for speed<br>• <strong>Selective Processing:</strong> Only process regions of interest"
    },
    {
      "type": "code",
      "title": "Performance Monitoring and Optimization",
      "content": "Example of performance monitoring and optimization:",
      "code": "public class OptimizedVisionPipeline extends CustomVisionPipeline {\n    \n    // Performance monitoring\n    private Map<String, Long> stageTimings;\n    private Map<String, Integer> stageCallCounts;\n    private long totalProcessingTime;\n    \n    // Optimization flags\n    private boolean enableROI = true;\n    private boolean enableDownsampling = true;\n    private boolean enableCaching = true;\n    \n    // Cached objects for reuse\n    private Mat cachedHsv;\n    private Mat cachedMask;\n    private Mat cachedKernel;\n    \n    public OptimizedVisionPipeline(PipelineConfig config) {\n        super(config);\n        stageTimings = new HashMap<>();\n        stageCallCounts = new HashMap<>();\n        \n        // Pre-allocate cached objects\n        if (enableCaching) {\n            cachedHsv = new Mat();\n            cachedMask = new Mat();\n            cachedKernel = Imgproc.getStructuringElement(\n                Imgproc.MORPH_ELLIPSE, new Size(5, 5));\n        }\n    }\n    \n    @Override\n    protected void preprocessInput(Mat input) {\n        long startTime = System.nanoTime();\n        \n        try {\n            // Apply region of interest if enabled\n            if (enableROI) {\n                applyROI(input);\n            }\n            \n            // Apply downsampling if enabled\n            if (enableDownsampling) {\n                applyDownsampling(input);\n            }\n            \n            // Optimized color conversion\n            if (enableCaching) {\n                Imgproc.cvtColor(input, cachedHsv, Imgproc.COLOR_RGB2HSV);\n            } else {\n                Mat hsv = new Mat();\n                Imgproc.cvtColor(input, hsv, Imgproc.COLOR_RGB2HSV);\n                hsv.release();\n            }\n            \n        } finally {\n            updateStageTiming(\"preprocessInput\", System.nanoTime() - startTime);\n        }\n    }\n    \n    @Override\n    protected Mat detectFeatures(Mat input) {\n        long startTime = System.nanoTime();\n        \n        try {\n            // Optimized feature detection\n            Mat result = optimizedFeatureDetection(input);\n            return result;\n            \n        } finally {\n            updateStageTiming(\"detectFeatures\", System.nanoTime() - startTime);\n        }\n    }\n    \n    @Override\n    protected void analyzeFeatures(Mat processed) {\n        long startTime = System.nanoTime();\n        \n        try {\n            // Optimized analysis\n            optimizedAnalysis(processed);\n            \n        } finally {\n            updateStageTiming(\"analyzeFeatures\", System.nanoTime() - startTime);\n        }\n    }\n    \n    @Override\n    protected Mat generateOutput(Mat input) {\n        long startTime = System.nanoTime();\n        \n        try {\n            Mat output = input.clone();\n            \n            // Optimized output generation\n            optimizedOutputGeneration(output);\n            \n            return output;\n            \n        } finally {\n            updateStageTiming(\"generateOutput\", System.nanoTime() - startTime);\n        }\n    }\n    \n    // Optimization methods\n    private void applyROI(Mat input) {\n        // Define region of interest (center 50% of image)\n        int roiWidth = input.cols() / 2;\n        int roiHeight = input.rows() / 2;\n        int roiX = (input.cols() - roiWidth) / 2;\n        int roiY = (input.rows() - roiHeight) / 2;\n        \n        Rect roi = new Rect(roiX, roiY, roiWidth, roiHeight);\n        Mat roiMat = new Mat(input, roi);\n        \n        // Process only the ROI\n        // ... processing logic here\n        \n        roiMat.release();\n    }\n    \n    private void applyDownsampling(Mat input) {\n        // Downsample image for faster processing\n        Mat downsampled = new Mat();\n        Imgproc.resize(input, downsampled, new Size(), 0.5, 0.5, Imgproc.INTER_LINEAR);\n        \n        // Process downsampled image\n        // ... processing logic here\n        \n        downsampled.release();\n    }\n    \n    private Mat optimizedFeatureDetection(Mat input) {\n        // Use cached objects for better performance\n        if (enableCaching) {\n            // Use cached HSV and mask\n            Core.inRange(cachedHsv, new Scalar(0, 100, 100), \n                new Scalar(10, 255, 255), cachedMask);\n            \n            // Use cached kernel for morphological operations\n            Imgproc.morphologyEx(cachedMask, cachedMask, \n                Imgproc.MORPH_CLOSE, cachedKernel);\n            \n            return cachedMask.clone();\n        } else {\n            // Standard processing without caching\n            Mat hsv = new Mat();\n            Mat mask = new Mat();\n            Mat kernel = Imgproc.getStructuringElement(\n                Imgproc.MORPH_ELLIPSE, new Size(5, 5));\n            \n            Imgproc.cvtColor(input, hsv, Imgproc.COLOR_RGB2HSV);\n            Core.inRange(hsv, new Scalar(0, 100, 100), \n                new Scalar(10, 255, 255), mask);\n            Imgproc.morphologyEx(mask, mask, Imgproc.MORPH_CLOSE, kernel);\n            \n            hsv.release();\n            kernel.release();\n            return mask;\n        }\n    }\n    \n    private void optimizedAnalysis(Mat processed) {\n        // Optimized analysis with minimal object creation\n        List<MatOfPoint> contours = new ArrayList<>();\n        Mat hierarchy = new Mat();\n        \n        Imgproc.findContours(processed, contours, hierarchy, \n            Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);\n        \n        // Process contours efficiently\n        detections.clear();\n        for (MatOfPoint contour : contours) {\n            double area = Imgproc.contourArea(contour);\n            if (area > 1000) { // Filter by area\n                Rect bbox = Imgproc.boundingRect(contour);\n                Point center = new Point(\n                    bbox.x + bbox.width / 2,\n                    bbox.y + bbox.height / 2\n                );\n                \n                detections.add(new DetectionResult(\n                    \"object\", area / 10000.0, center, bbox));\n            }\n        }\n        \n        hierarchy.release();\n    }\n    \n    private void optimizedOutputGeneration(Mat output) {\n        // Minimal drawing for performance\n        for (DetectionResult detection : detections) {\n            Imgproc.rectangle(output, detection.boundingBox, \n                new Scalar(0, 255, 0), 2);\n        }\n    }\n    \n    // Performance monitoring methods\n    private void updateStageTiming(String stageName, long duration) {\n        stageTimings.merge(stageName, duration, Long::sum);\n        stageCallCounts.merge(stageName, 1, Integer::sum);\n        totalProcessingTime += duration;\n    }\n    \n    public void printPerformanceReport() {\n        telemetry.addData(\"=== Performance Report ===\", \"\");\n        \n        for (Map.Entry<String, Long> entry : stageTimings.entrySet()) {\n            String stage = entry.getKey();\n            long totalTime = entry.getValue();\n            int callCount = stageCallCounts.get(stage);\n            double avgTime = totalTime / (double) callCount / 1_000_000.0; // Convert to ms\n            \n            telemetry.addData(stage, \"%.2f ms avg (%d calls)\", avgTime, callCount);\n        }\n        \n        double totalAvgTime = totalProcessingTime / (double) metrics.getFrameCount() / 1_000_000.0;\n        telemetry.addData(\"Total Average\", \"%.2f ms\", totalAvgTime);\n        telemetry.addData(\"FPS\", \"%.1f\", 1000.0 / totalAvgTime);\n    }\n    \n    @Override\n    public void cleanup() {\n        super.cleanup();\n        \n        // Release cached objects\n        if (cachedHsv != null) cachedHsv.release();\n        if (cachedMask != null) cachedMask.release();\n        if (cachedKernel != null) cachedKernel.release();\n    }\n}"
    },
    {
      "type": "exercise-box",
      "title": "Custom Vision Pipeline Exercise",
      "description": "Design and implement a custom vision pipeline for a specific FTC task",
      "tasks": [
        "Define the vision requirements for your specific robot task",
        "Design a multi-stage pipeline architecture",
        "Implement custom filters for each processing stage",
        "Add performance monitoring and optimization",
        "Test and validate the pipeline in real-world conditions"
      ],
      "content": "Create a complete custom vision pipeline tailored to your robot's specific needs. The pipeline should be efficient, reliable, and provide the visual information your robot needs for autonomous operation."
    },
    {
      "type": "link-grid",
      "title": "Additional Resources",
      "links": [
        "<a href=\"https://gm0.org/en/latest/docs/software/tutorials/vision.html#pipeline-design\" target=\"_blank\">gm0: Pipeline Design</a>",
        "<a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/opencv.html#custom-filters\" target=\"_blank\">FTC Custom Filters</a>",
        "<a href=\"https://gm0.org/en/latest/docs/software/tutorials/vision.html#multi-stage-pipelines\" target=\"_blank\">gm0: Multi-Stage Pipelines</a>",
        "<a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/vision-overview.html#performance\" target=\"_blank\">FTC Vision Performance</a>"
      ]
    }
  ]
} 