{
  "title": "Custom Vision Processing",
  "sections": [
    {
      "type": "text",
      "title": "What is Custom Vision Processing?",
      "content": "Custom vision processing allows you to create specialized computer vision algorithms tailored specifically to your FTC robot's needs. While Vision Portal provides excellent built-in processors, custom processing gives you complete control over every aspect of the vision pipeline.<br><br>Custom vision processing is essential when you need:<br>• Specialized algorithms for unique game elements<br>• Optimized performance for specific use cases<br>• Integration with other robot subsystems<br>• Advanced image analysis beyond standard processors<br>• Real-time processing with minimal latency"
    },
    {
      "type": "rules-box",
      "title": "When to Use Custom Vision Processing",
      "items": [
        "Built-in processors don't meet your specific requirements",
        "You need maximum performance and control",
        "Your vision algorithm is unique to your robot design",
        "You want to integrate vision with other sensors",
        "You need real-time processing with minimal overhead",
        "You want to implement advanced computer vision techniques"
      ]
    },
    {
      "type": "text",
      "title": "Custom Pipeline Development",
      "content": "Creating custom vision pipelines involves extending the OpenCvPipeline class and implementing your own image processing logic. This gives you complete control over the vision processing pipeline.<br><br><strong>Pipeline Structure:</strong> Each pipeline processes one frame at a time<br><strong>Input Processing:</strong> Raw camera images are provided as OpenCV Mat objects<br><strong>Custom Algorithms:</strong> Implement your own detection and analysis logic<br><strong>Output Generation:</strong> Return processed images and detection results<br><strong>Performance Optimization:</strong> Optimize for speed and accuracy<br><strong>Integration:</strong> Communicate results to other robot subsystems"
    },
    {
      "type": "text",
      "title": "Custom Vision Pipeline Setup",
      "content": "Let's create a basic custom vision pipeline structure. For more on OpenCV pipelines, see <a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/opencv.html\" target=\"_blank\">FTC OpenCV Documentation</a>."
    },
    {
      "type": "code",
      "title": "Import Statements and Class Definition",
      "content": "Import necessary OpenCV classes and define the custom vision pipeline class.",
      "code": "import org.opencv.core.*;\nimport org.opencv.imgproc.Imgproc;\nimport org.firstinspires.ftc.vision.OpenCvPipeline;\nimport java.util.List;\nimport java.util.ArrayList;\n\npublic class CustomVisionPipeline extends OpenCvPipeline {\n    \n    // Detection results that can be accessed by the OpMode\n    private List<DetectionResult> detectionResults = new ArrayList<>();\n    private boolean isProcessing = false;\n    // ..."
    },
    {
      "type": "text",
      "title": "processFrame Method Setup",
      "content": "The processFrame method is the main entry point for processing each camera frame. For more on pipeline processing, see <a href=\"https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html\" target=\"_blank\">OpenCV Tutorials</a>."
    },
    {
      "type": "code",
      "title": "processFrame Method Implementation",
      "content": "Implement the main processing pipeline with error handling and cleanup.",
      "code": "    @Override\n    public Mat processFrame(Mat input) {\n        // Create output image (can be modified or original)\n        Mat output = input.clone();\n        \n        try {\n            isProcessing = true;\n            \n            // Step 1: Preprocessing\n            Mat preprocessed = preprocessImage(input);\n            \n            // Step 2: Feature Detection\n            List<DetectionResult> results = detectFeatures(preprocessed);\n            \n            // Step 3: Analysis and Filtering\n            detectionResults = analyzeAndFilter(results);\n            \n            // Step 4: Visualization (optional)\n            drawResults(output, detectionResults);\n            \n            // Clean up temporary matrices\n            preprocessed.release();\n            \n        } catch (Exception e) {\n            // Handle any processing errors\n            telemetry.addData(\"Vision Error\", e.getMessage());\n        } finally {\n            isProcessing = false;\n        }\n        \n        return output;\n    }"
    },
    {
      "type": "text",
      "title": "Image Preprocessing",
      "content": "The preprocessImage method prepares the input image for feature detection by converting color spaces and applying noise reduction."
    },
    {
      "type": "code",
      "title": "preprocessImage Method",
      "content": "Convert to HSV color space and apply Gaussian blur for noise reduction.",
      "code": "    private Mat preprocessImage(Mat input) {\n        // Convert to HSV for better color detection\n        Mat hsv = new Mat();\n        Imgproc.cvtColor(input, hsv, Imgproc.COLOR_RGB2HSV);\n        \n        // Apply Gaussian blur to reduce noise\n        Mat blurred = new Mat();\n        Imgproc.GaussianBlur(hsv, blurred, new Size(5, 5), 0);\n        \n        return blurred;\n    }"
    },
    {
      "type": "text",
      "title": "Feature Detection",
      "content": "The detectFeatures method implements custom detection logic for finding objects in the preprocessed image."
    },
    {
      "type": "code",
      "title": "detectFeatures Method",
      "content": "Implement custom detection logic for finding features in the image.",
      "code": "    private List<DetectionResult> detectFeatures(Mat image) {\n        List<DetectionResult> results = new ArrayList<>();\n        \n        // Your custom detection logic here\n        // This could be color detection, shape detection, etc.\n        \n        return results;\n    }"
    },
    {
      "type": "text",
      "title": "Result Analysis and Filtering",
      "content": "The analyzeAndFilter method filters detection results based on validation criteria to remove false positives."
    },
    {
      "type": "code",
      "title": "analyzeAndFilter Method",
      "content": "Filter detection results based on validation criteria.",
      "code": "    private List<DetectionResult> analyzeAndFilter(List<DetectionResult> results) {\n        List<DetectionResult> filtered = new ArrayList<>();\n        \n        // Filter results based on criteria\n        for (DetectionResult result : results) {\n            if (isValidDetection(result)) {\n                filtered.add(result);\n            }\n        }\n        \n        return filtered;\n    }"
    },
    {
      "type": "text",
      "title": "Detection Validation",
      "content": "The isValidDetection method implements validation logic to determine if a detection result is valid."
    },
    {
      "type": "code",
      "title": "isValidDetection Method",
      "content": "Implement validation logic for detection results.",
      "code": "    private boolean isValidDetection(DetectionResult result) {\n        // Implement your validation logic\n        return result.getConfidence() > 0.5 && result.getArea() > 100;\n    }"
    },
    {
      "type": "text",
      "title": "Result Visualization",
      "content": "The drawResults method visualizes detection results on the output image for debugging and monitoring purposes."
    },
    {
      "type": "code",
      "title": "drawResults Method",
      "content": "Draw detection results on the output image with bounding boxes and labels.",
      "code": "    private void drawResults(Mat output, List<DetectionResult> results) {\n        // Draw detection results on output image\n        for (DetectionResult result : results) {\n            // Draw bounding box\n            Imgproc.rectangle(output, result.getBoundingBox(), \n                new Scalar(0, 255, 0), 2);\n            \n            // Draw center point\n            Imgproc.circle(output, result.getCenter(), 5, \n                new Scalar(255, 0, 0), -1);\n            \n            // Add text label\n            Imgproc.putText(output, result.getLabel(), \n                new Point(result.getCenter().x + 10, result.getCenter().y), \n                Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(255, 255, 255), 1);\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Public Access Methods",
      "content": "Public methods allow the OpMode to access detection results and pipeline status."
    },
    {
      "type": "code",
      "title": "Public Access Methods",
      "content": "Provide public methods for accessing detection results and pipeline status.",
      "code": "    // Public methods to access results from OpMode\n    public List<DetectionResult> getDetectionResults() {\n        return new ArrayList<>(detectionResults);\n    }\n    \n    public boolean isProcessing() {\n        return isProcessing;\n    }\n    \n    public void clearResults() {\n        detectionResults.clear();\n    }\n}"
    },
    {
      "type": "text",
      "title": "Detection Result Class",
      "content": "The DetectionResult class holds information about detected objects including label, confidence, position, and size."
    },
    {
      "type": "code",
      "title": "DetectionResult Class Definition",
      "content": "Define the DetectionResult class to hold detection information.",
      "code": "// Custom class to hold detection results\nclass DetectionResult {\n    private String label;\n    private double confidence;\n    private Point center;\n    private Rect boundingBox;\n    private double area;\n    \n    // Constructor and getter methods\n    public DetectionResult(String label, double confidence, Point center, \n                          Rect boundingBox, double area) {\n        this.label = label;\n        this.confidence = confidence;\n        this.center = center;\n        this.boundingBox = boundingBox;\n        this.area = area;\n    }\n    \n    // Getters\n    public String getLabel() { return label; }\n    public double getConfidence() { return confidence; }\n    public Point getCenter() { return center; }\n    public Rect getBoundingBox() { return boundingBox; }\n    public double getArea() { return area; }\n}"
    },
    {
      "type": "text",
      "title": "Advanced Image Processing Techniques",
      "content": "Custom vision processing enables you to implement sophisticated image processing techniques that go beyond basic color detection and contour finding.<br><br><strong>Advanced Filtering:</strong> Multi-stage filtering for noise reduction<br><strong>Feature Detection:</strong> Detecting specific patterns or features in images<br><strong>Pattern Matching:</strong> Finding specific templates or patterns<br><strong>Image Segmentation:</strong> Separating objects from background<br><strong>Edge Detection:</strong> Finding boundaries and edges for shape analysis<br><strong>Morphological Operations:</strong> Advanced shape-based processing"
    },
    {
      "type": "text",
      "title": "Advanced Image Processing Pipeline Setup",
      "content": "Let's create an advanced image processing pipeline that demonstrates sophisticated computer vision techniques. For more on advanced OpenCV techniques, see <a href=\"https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html\" target=\"_blank\">OpenCV Tutorials</a>."
    },
    {
      "type": "code",
      "title": "Class Definition and processFrame Method",
      "content": "Define the advanced processing pipeline class and set up the main processing method.",
      "code": "public class AdvancedProcessingPipeline extends OpenCvPipeline {\n    \n    @Override\n    public Mat processFrame(Mat input) {\n        Mat output = input.clone();\n        \n        // Step 1: Multi-stage preprocessing\n        Mat preprocessed = multiStagePreprocessing(input);\n        \n        // Step 2: Advanced feature detection\n        List<Feature> features = detectAdvancedFeatures(preprocessed);\n        \n        // Step 3: Pattern matching\n        List<PatternMatch> patterns = findPatterns(preprocessed);\n        \n        // Step 4: Edge-based analysis\n        List<EdgeFeature> edges = analyzeEdges(preprocessed);\n        \n        // Step 5: Combine results and visualize\n        combineAndVisualize(output, features, patterns, edges);\n        \n        preprocessed.release();\n        return output;\n    }"
    },
    {
      "type": "text",
      "title": "Multi-Stage Preprocessing",
      "content": "The multiStagePreprocessing method applies sophisticated image enhancement techniques including bilateral filtering and unsharp masking."
    },
    {
      "type": "code",
      "title": "multiStagePreprocessing Method",
      "content": "Apply multiple preprocessing stages for enhanced image quality.",
      "code": "    private Mat multiStagePreprocessing(Mat input) {\n        Mat result = input.clone();\n        \n        // Convert to different color spaces\n        Mat hsv = new Mat();\n        Mat lab = new Mat();\n        Imgproc.cvtColor(input, hsv, Imgproc.COLOR_RGB2HSV);\n        Imgproc.cvtColor(input, lab, Imgproc.COLOR_RGB2Lab);\n        \n        // Apply bilateral filter to preserve edges while smoothing\n        Mat bilateral = new Mat();\n        Imgproc.bilateralFilter(result, bilateral, 9, 75, 75);\n        \n        // Apply unsharp masking for edge enhancement\n        Mat blurred = new Mat();\n        Imgproc.GaussianBlur(bilateral, blurred, new Size(0, 0), 2.0);\n        \n        Mat unsharp = new Mat();\n        Core.addWeighted(bilateral, 1.5, blurred, -0.5, 0, unsharp);\n        \n        // Clean up\n        hsv.release();\n        lab.release();\n        bilateral.release();\n        blurred.release();\n        \n        return unsharp;\n    }"
    },
    {
      "type": "text",
      "title": "Advanced Feature Detection",
      "content": "The detectAdvancedFeatures method uses Harris corner detection to find distinctive points in the image."
    },
    {
      "type": "code",
      "title": "detectAdvancedFeatures Method",
      "content": "Detect corners using Harris corner detection algorithm.",
      "code": "    private List<Feature> detectAdvancedFeatures(Mat image) {\n        List<Feature> features = new ArrayList<>();\n        \n        // Detect corners using Harris corner detection\n        Mat gray = new Mat();\n        Imgproc.cvtColor(image, gray, Imgproc.COLOR_RGB2GRAY);\n        \n        Mat corners = new Mat();\n        Imgproc.cornerHarris(gray, corners, 2, 3, 0.04);\n        \n        // Find local maxima in corner response\n        Mat cornerMask = new Mat();\n        Core.compare(corners, new Scalar(0.01), cornerMask, Core.CMP_GT);\n        \n        // Extract corner points\n        List<Point> cornerPoints = new ArrayList<>();\n        for (int y = 0; y < cornerMask.rows(); y++) {\n            for (int x = 0; x < cornerMask.cols(); x++) {\n                if (cornerMask.get(y, x)[0] > 0) {\n                    cornerPoints.add(new Point(x, y));\n                }\n            }\n        }\n        \n        // Create feature objects\n        for (Point point : cornerPoints) {\n            features.add(new Feature(\"corner\", point, 1.0));\n        }\n        \n        // Clean up\n        gray.release();\n        corners.release();\n        cornerMask.release();\n        \n        return features;\n    }"
    },
    {
      "type": "text",
      "title": "Feature Creation and Cleanup",
      "content": "Create feature objects from detected corner points and clean up temporary matrices."
    },
    {
      "type": "code",
      "title": "Feature Creation and Cleanup Code",
      "content": "Create feature objects and clean up temporary matrices.",
      "code": "        // Create feature objects\n        for (Point point : cornerPoints) {\n            features.add(new Feature(\"corner\", point, 1.0));\n        }\n        \n        // Clean up\n        gray.release();\n        corners.release();\n        cornerMask.release();\n        \n        return features;\n    }"
    },
    {
      "type": "text",
      "title": "Pattern Matching",
      "content": "The findPatterns method performs template matching to find specific patterns in the image."
    },
    {
      "type": "code",
      "title": "findPatterns Method",
      "content": "Perform template matching to find specific patterns in the image.",
      "code": "    private List<PatternMatch> findPatterns(Mat image) {\n        List<PatternMatch> patterns = new ArrayList<>();\n        \n        // Template matching example\n        Mat template = loadTemplate(\"target_pattern.png\");\n        if (template != null) {\n            Mat result = new Mat();\n            Imgproc.matchTemplate(image, template, result, Imgproc.TM_CCOEFF_NORMED);\n            \n            // Find best matches\n            Core.MinMaxLocResult mmr = Core.minMaxLoc(result);\n            if (mmr.maxVal > 0.8) { // High confidence threshold\n                patterns.add(new PatternMatch(\"target\", mmr.maxLoc, mmr.maxVal));\n            }\n            \n            template.release();\n            result.release();\n        }\n        \n        return patterns;\n    }"
    },
    {
      "type": "text",
      "title": "Edge Analysis",
      "content": "The analyzeEdges method uses Canny edge detection and contour analysis to find edge-based features."
    },
    {
      "type": "code",
      "title": "analyzeEdges Method",
      "content": "Analyze edges using Canny edge detection and contour analysis.",
      "code": "    private List<EdgeFeature> analyzeEdges(Mat image) {\n        List<EdgeFeature> edges = new ArrayList<>();\n        \n        // Convert to grayscale\n        Mat gray = new Mat();\n        Imgproc.cvtColor(image, gray, Imgproc.COLOR_RGB2GRAY);\n        \n        // Apply Canny edge detection\n        Mat edgesMat = new Mat();\n        Imgproc.Canny(gray, edgesMat, 50, 150);\n        \n        // Find contours in edge image\n        List<MatOfPoint> contours = new ArrayList<>();\n        Mat hierarchy = new Mat();\n        Imgproc.findContours(edgesMat, contours, hierarchy, \n            Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);\n        \n        // Analyze contours\n        for (MatOfPoint contour : contours) {\n            double area = Imgproc.contourArea(contour);\n            if (area > 100) { // Filter small contours\n                double perimeter = Imgproc.arcLength(new MatOfPoint2f(contour.toArray()), true);\n                double circularity = 4 * Math.PI * area / (perimeter * perimeter);\n                \n                edges.add(new EdgeFeature(contour, area, perimeter, circularity));\n            }\n        }\n        \n        // Clean up\n        gray.release();\n        edgesMat.release();\n        hierarchy.release();\n        \n        return edges;\n    }"
    },
    {
      "type": "text",
      "title": "Edge Analysis Cleanup",
      "content": "Clean up temporary matrices used in edge analysis."
    },
    {
      "type": "code",
      "title": "Edge Analysis Cleanup Code",
      "content": "Clean up temporary matrices from edge analysis.",
      "code": "        // Clean up\n        gray.release();\n        edgesMat.release();\n        hierarchy.release();\n        \n        return edges;\n    }"
    },
    {
      "type": "text",
      "title": "Result Visualization",
      "content": "The combineAndVisualize method draws all detected features, patterns, and edges on the output image."
    },
    {
      "type": "code",
      "title": "combineAndVisualize Method",
      "content": "Draw all detected features, patterns, and edges on the output image.",
      "code": "    private void combineAndVisualize(Mat output, List<Feature> features, \n                                   List<PatternMatch> patterns, List<EdgeFeature> edges) {\n        // Draw features\n        for (Feature feature : features) {\n            Imgproc.circle(output, feature.getPoint(), 3, new Scalar(0, 255, 0), -1);\n        }\n        \n        // Draw pattern matches\n        for (PatternMatch pattern : patterns) {\n            Imgproc.circle(output, pattern.getPoint(), 10, new Scalar(255, 0, 0), 2);\n            Imgproc.putText(output, String.format(\"%.2f\", pattern.getConfidence()), \n                new Point(pattern.getPoint().x + 15, pattern.getPoint().y), \n                Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(255, 0, 0), 1);\n        }\n        \n        // Draw edge features\n        for (EdgeFeature edge : edges) {\n            if (edge.getCircularity() > 0.8) { // High circularity\n                Imgproc.drawContours(output, Arrays.asList(edge.getContour()), 0, \n                    new Scalar(0, 0, 255), 2);\n            }\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Template Loading Helper",
      "content": "The loadTemplate method loads template images for pattern matching (placeholder implementation)."
    },
    {
      "type": "code",
      "title": "loadTemplate Method",
      "content": "Load template image for pattern matching (placeholder implementation).",
      "code": "    private Mat loadTemplate(String filename) {\n        // Load template image (implementation depends on your setup)\n        // This is a placeholder - you would implement actual template loading\n        return null;\n    }\n}"
    },
    {
      "type": "text",
      "title": "Supporting Classes",
      "content": "Define supporting classes for features, pattern matches, and edge features."
    },
    {
      "type": "code",
      "title": "Supporting Classes Definition",
      "content": "Define supporting classes for the advanced processing pipeline.",
      "code": "// Supporting classes\nclass Feature {\n    private String type;\n    private Point point;\n    private double confidence;\n    \n    public Feature(String type, Point point, double confidence) {\n        this.type = type;\n        this.point = point;\n        this.confidence = confidence;\n    }\n    \n    public String getType() { return type; }\n    public Point getPoint() { return point; }\n    public double getConfidence() { return confidence; }\n}\n\nclass PatternMatch {\n    private String pattern;\n    private Point point;\n    private double confidence;\n    \n    public PatternMatch(String pattern, Point point, double confidence) {\n        this.pattern = pattern;\n        this.point = point;\n        this.confidence = confidence;\n    }\n    \n    public String getPattern() { return pattern; }\n    public Point getPoint() { return point; }\n    public double getConfidence() { return confidence; }\n}\n\nclass EdgeFeature {\n    private MatOfPoint contour;\n    private double area;\n    private double perimeter;\n    private double circularity;\n    \n    public EdgeFeature(MatOfPoint contour, double area, double perimeter, double circularity) {\n        this.contour = contour;\n        this.area = area;\n        this.perimeter = perimeter;\n        this.circularity = circularity;\n    }\n    \n    public MatOfPoint getContour() { return contour; }\n    public double getArea() { return area; }\n    public double getPerimeter() { return perimeter; }\n    public double getCircularity() { return circularity; }\n}"
    },
    {
      "type": "text",
      "title": "Multi-Stage Processing Pipelines",
      "content": "Complex vision tasks often require multiple processing stages that build upon each other. Multi-stage pipelines allow you to break down complex vision problems into manageable steps.<br><br><strong>Pipeline Design:</strong> Plan stages that progressively refine the image<br><strong>Stage Communication:</strong> Pass results between processing stages<br><strong>Error Handling:</strong> Handle failures at each stage gracefully<br><strong>Performance Monitoring:</strong> Track performance of each stage<br><strong>Parallel Processing:</strong> Run independent stages in parallel when possible<br><strong>Result Aggregation:</strong> Combine results from multiple stages"
    },
    {
      "type": "text",
      "title": "Multi-Stage Pipeline Setup",
      "content": "Let's create a multi-stage vision processing pipeline that breaks down complex vision tasks into manageable steps. For more on pipeline design, see <a href=\"https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html\" target=\"_blank\">OpenCV Tutorials</a>."
    },
    {
      "type": "code",
      "title": "Class Definition and Pipeline Stages",
      "content": "Define the multi-stage pipeline class and enumerate the processing stages.",
      "code": "public class MultiStagePipeline extends OpenCvPipeline {\n    \n    // Pipeline stages\n    private enum Stage {\n        PREPROCESSING,\n        COLOR_DETECTION,\n        SHAPE_ANALYSIS,\n        PATTERN_MATCHING,\n        RESULT_AGGREGATION\n    }\n    \n    // Stage results\n    private Map<Stage, Object> stageResults = new HashMap<>();\n    private List<FinalResult> finalResults = new ArrayList<>();\n    // ..."
    },
    {
      "type": "text",
      "title": "Main Processing Method",
      "content": "The processFrame method orchestrates the multi-stage processing pipeline, executing each stage in sequence."
    },
    {
      "type": "code",
      "title": "processFrame Method Implementation",
      "content": "Execute the multi-stage processing pipeline with error handling.",
      "code": "    @Override\n    public Mat processFrame(Mat input) {\n        Mat output = input.clone();\n        stageResults.clear();\n        \n        try {\n            // Stage 1: Preprocessing\n            Mat preprocessed = stagePreprocessing(input);\n            stageResults.put(Stage.PREPROCESSING, preprocessed);\n            \n            // Stage 2: Color Detection\n            List<ColorRegion> colorRegions = stageColorDetection(preprocessed);\n            stageResults.put(Stage.COLOR_DETECTION, colorRegions);\n            \n            // Stage 3: Shape Analysis\n            List<ShapeFeature> shapes = stageShapeAnalysis(preprocessed, colorRegions);\n            stageResults.put(Stage.SHAPE_ANALYSIS, shapes);\n            \n            // Stage 4: Pattern Matching\n            List<PatternMatch> patterns = stagePatternMatching(preprocessed);\n            stageResults.put(Stage.PATTERN_MATCHING, patterns);\n            \n            // Stage 5: Result Aggregation\n            finalResults = stageResultAggregation(colorRegions, shapes, patterns);\n            stageResults.put(Stage.RESULT_AGGREGATION, finalResults);\n            \n            // Visualize final results\n            visualizeResults(output, finalResults);\n            \n            // Clean up\n            preprocessed.release();\n            \n        } catch (Exception e) {\n            telemetry.addData(\"Pipeline Error\", e.getMessage());\n        }\n        \n        return output;\n    }"
    },
    {
      "type": "text",
      "title": "Preprocessing Stage",
      "content": "The stagePreprocessing method applies noise reduction and histogram equalization to enhance image quality."
    },
    {
      "type": "code",
      "title": "stagePreprocessing Method",
      "content": "Apply noise reduction and histogram equalization for enhanced image quality.",
      "code": "    private Mat stagePreprocessing(Mat input) {\n        Mat result = input.clone();\n        \n        // Convert to HSV\n        Mat hsv = new Mat();\n        Imgproc.cvtColor(result, hsv, Imgproc.COLOR_RGB2HSV);\n        \n        // Apply noise reduction\n        Mat denoised = new Mat();\n        Imgproc.medianBlur(hsv, denoised, 5);\n        \n        // Apply histogram equalization for better contrast\n        List<Mat> channels = new ArrayList<>();\n        Core.split(denoised, channels);\n        \n        Imgproc.equalizeHist(channels.get(2), channels.get(2)); // Equalize V channel\n        \n        Mat enhanced = new Mat();\n        Core.merge(channels, enhanced);\n        \n        // Clean up\n        hsv.release();\n        denoised.release();\n        for (Mat channel : channels) {\n            channel.release();\n        }\n        \n        return enhanced;\n    }"
    },
    {
      "type": "text",
      "title": "Color Detection Stage",
      "content": "The stageColorDetection method identifies regions of specific colors in the preprocessed image."
    },
    {
      "type": "code",
      "title": "stageColorDetection Method",
      "content": "Detect color regions using HSV color space thresholds.",
      "code": "    private List<ColorRegion> stageColorDetection(Mat preprocessed) {\n        List<ColorRegion> regions = new ArrayList<>();\n        \n        // Define color ranges for different objects\n        Scalar[] lowerBounds = {\n            new Scalar(0, 100, 100),    // Red lower\n            new Scalar(160, 100, 100),  // Red upper\n            new Scalar(100, 100, 100),  // Blue\n            new Scalar(40, 100, 100)    // Green\n        };\n        \n        Scalar[] upperBounds = {\n            new Scalar(10, 255, 255),   // Red lower\n            new Scalar(180, 255, 255),  // Red upper\n            new Scalar(130, 255, 255),  // Blue\n            new Scalar(80, 255, 255)    // Green\n        };\n        \n        String[] colorNames = {\"red\", \"red\", \"blue\", \"green\"};\n        \n        for (int i = 0; i < lowerBounds.length; i++) {\n            Mat mask = new Mat();\n            Core.inRange(preprocessed, lowerBounds[i], upperBounds[i], mask);\n            \n            // Find contours in color mask\n            List<MatOfPoint> contours = new ArrayList<>();\n            Mat hierarchy = new Mat();\n            Imgproc.findContours(mask, contours, hierarchy, \n                Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);\n            \n            // Create color regions\n            for (MatOfPoint contour : contours) {\n                double area = Imgproc.contourArea(contour);\n                if (area > 200) { // Filter small regions\n                    regions.add(new ColorRegion(colorNames[i], contour, area));\n                }\n            }\n            \n            mask.release();\n            hierarchy.release();\n        }\n        \n        return regions;\n    }"
    },
    {
      "type": "text",
      "title": "Color Region Processing",
      "content": "Process each color range to find contours and create color region objects."
    },
    {
      "type": "code",
      "title": "Color Region Processing Loop",
      "content": "Process each color range and find contours to create color regions.",
      "code": "        for (int i = 0; i < lowerBounds.length; i++) {\n            Mat mask = new Mat();\n            Core.inRange(preprocessed, lowerBounds[i], upperBounds[i], mask);\n            \n            // Find contours in color mask\n            List<MatOfPoint> contours = new ArrayList<>();\n            Mat hierarchy = new Mat();\n            Imgproc.findContours(mask, contours, hierarchy, \n                Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);\n            \n            // Create color regions\n            for (MatOfPoint contour : contours) {\n                double area = Imgproc.contourArea(contour);\n                if (area > 200) { // Filter small regions\n                    regions.add(new ColorRegion(colorNames[i], contour, area));\n                }\n            }\n            \n            mask.release();\n            hierarchy.release();\n        }\n        \n        return regions;\n    }"
    },
    {
      "type": "text",
      "title": "Shape Analysis Stage",
      "content": "The stageShapeAnalysis method analyzes the shape properties of detected color regions."
    },
    {
      "type": "code",
      "title": "stageShapeAnalysis Method",
      "content": "Analyze shape properties of color regions including circularity and rectangularity.",
      "code": "    private List<ShapeFeature> stageShapeAnalysis(Mat preprocessed, List<ColorRegion> regions) {\n        List<ShapeFeature> shapes = new ArrayList<>();\n        \n        for (ColorRegion region : regions) {\n            MatOfPoint contour = region.getContour();\n            \n            // Calculate shape properties\n            double area = Imgproc.contourArea(contour);\n            double perimeter = Imgproc.arcLength(new MatOfPoint2f(contour.toArray()), true);\n            \n            // Calculate circularity\n            double circularity = 4 * Math.PI * area / (perimeter * perimeter);\n            \n            // Calculate rectangularity\n            Rect boundingRect = Imgproc.boundingRect(contour);\n            double rectArea = boundingRect.width * boundingRect.height;\n            double rectangularity = area / rectArea;\n            \n            // Determine shape type\n            String shapeType = determineShapeType(circularity, rectangularity);\n            \n            shapes.add(new ShapeFeature(contour, shapeType, circularity, rectangularity));\n        }\n        \n        return shapes;\n    }"
    },
    {
      "type": "text",
      "title": "Shape Type Determination",
      "content": "The determineShapeType method classifies shapes based on their circularity and rectangularity values."
    },
    {
      "type": "code",
      "title": "determineShapeType Method",
      "content": "Classify shapes based on circularity and rectangularity measurements.",
      "code": "    private String determineShapeType(double circularity, double rectangularity) {\n        if (circularity > 0.8) {\n            return \"circle\";\n        } else if (rectangularity > 0.8) {\n            return \"rectangle\";\n        } else if (circularity > 0.6) {\n            return \"ellipse\";\n        } else {\n            return \"irregular\";\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Pattern Matching Stage",
      "content": "The stagePatternMatching method performs template matching for specific patterns (simplified example)."
    },
    {
      "type": "code",
      "title": "stagePatternMatching Method",
      "content": "Perform template matching for specific patterns (simplified implementation).",
      "code": "    private List<PatternMatch> stagePatternMatching(Mat preprocessed) {\n        List<PatternMatch> patterns = new ArrayList<>();\n        \n        // Template matching for specific patterns\n        // This is a simplified example - you would load actual templates\n        \n        return patterns;\n    }"
    },
    {
      "type": "text",
      "title": "Result Aggregation Stage",
      "content": "The stageResultAggregation method combines information from all stages to create final results."
    },
    {
      "type": "code",
      "title": "stageResultAggregation Method",
      "content": "Combine information from all processing stages to create final results.",
      "code": "    private List<FinalResult> stageResultAggregation(List<ColorRegion> regions, \n                                                    List<ShapeFeature> shapes, \n                                                    List<PatternMatch> patterns) {\n        List<FinalResult> results = new ArrayList<>();\n        \n        // Combine information from all stages\n        for (int i = 0; i < regions.size(); i++) {\n            ColorRegion region = regions.get(i);\n            ShapeFeature shape = shapes.get(i);\n            \n            // Create final result combining color and shape information\n            FinalResult result = new FinalResult(\n                region.getColor() + \"_\" + shape.getType(),\n                region.getContour(),\n                region.getArea(),\n                0.8 // Confidence based on detection quality\n            );\n            \n            results.add(result);\n        }\n        \n        return results;\n    }"
    },
    {
      "type": "text",
      "title": "Result Visualization",
      "content": "The visualizeResults method draws the final aggregated results on the output image."
    },
    {
      "type": "code",
      "title": "visualizeResults Method",
      "content": "Draw final aggregated results on the output image with bounding boxes and labels.",
      "code": "    private void visualizeResults(Mat output, List<FinalResult> results) {\n        for (FinalResult result : results) {\n            // Draw bounding box\n            Rect boundingRect = Imgproc.boundingRect(result.getContour());\n            Imgproc.rectangle(output, boundingRect, new Scalar(0, 255, 0), 2);\n            \n            // Draw label\n            Point center = new Point(boundingRect.x + boundingRect.width/2, \n                                   boundingRect.y + boundingRect.height/2);\n            Imgproc.putText(output, result.getLabel(), \n                new Point(center.x + 10, center.y), \n                Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(255, 255, 255), 1);\n        }\n    }"
    },
    {
      "type": "text",
      "title": "Public Access Methods",
      "content": "Public methods provide access to stage results and final results for external systems."
    },
    {
      "type": "code",
      "title": "Public Access Methods",
      "content": "Provide public methods to access stage results and final results.",
      "code": "    // Public methods to access results\n    public List<FinalResult> getFinalResults() {\n        return new ArrayList<>(finalResults);\n    }\n    \n    public Object getStageResult(Stage stage) {\n        return stageResults.get(stage);\n    }\n}"
    },
    {
      "type": "text",
      "title": "Supporting Classes for Multi-Stage Pipeline",
      "content": "Define supporting classes for color regions, shape features, and final results."
    },
    {
      "type": "code",
      "title": "Supporting Classes Definition",
      "content": "Define supporting classes for the multi-stage pipeline.",
      "code": "// Supporting classes\nclass ColorRegion {\n    private String color;\n    private MatOfPoint contour;\n    private double area;\n    \n    public ColorRegion(String color, MatOfPoint contour, double area) {\n        this.color = color;\n        this.contour = contour;\n        this.area = area;\n    }\n    \n    public String getColor() { return color; }\n    public MatOfPoint getContour() { return contour; }\n    public double getArea() { return area; }\n}\n\nclass ShapeFeature {\n    private MatOfPoint contour;\n    private String type;\n    private double circularity;\n    private double rectangularity;\n    \n    public ShapeFeature(MatOfPoint contour, String type, double circularity, double rectangularity) {\n        this.contour = contour;\n        this.type = type;\n        this.circularity = circularity;\n        this.rectangularity = rectangularity;\n    }\n    \n    public MatOfPoint getContour() { return contour; }\n    public String getType() { return type; }\n    public double getCircularity() { return circularity; }\n    public double getRectangularity() { return rectangularity; }\n}\n\nclass FinalResult {\n    private String label;\n    private MatOfPoint contour;\n    private double area;\n    private double confidence;\n    \n    public FinalResult(String label, MatOfPoint contour, double area, double confidence) {\n        this.label = label;\n        this.contour = contour;\n        this.area = area;\n        this.confidence = confidence;\n    }\n    \n    public String getLabel() { return label; }\n    public MatOfPoint getContour() { return contour; }\n    public double getArea() { return area; }\n    public double getConfidence() { return confidence; }\n}"
    },
    {
      "type": "text",
      "title": "Performance Optimization",
      "content": "Custom vision processing can be computationally expensive, so optimization is crucial for real-time performance. Effective optimization strategies can significantly improve processing speed and reduce latency.<br><br><strong>Algorithm Optimization:</strong> Choose efficient algorithms and data structures<br><strong>Memory Management:</strong> Properly allocate and release OpenCV Mat objects<br><strong>Processing Reduction:</strong> Skip unnecessary processing steps when possible<br><strong>Parallel Processing:</strong> Use multiple threads for independent operations<br><strong>Resolution Optimization:</strong> Balance resolution with processing speed<br><strong>Frame Skipping:</strong> Process every nth frame to reduce load"
    },
    {
      "type": "emphasis-box",
      "title": "Custom Vision Processing Best Practices",
      "content": "To create effective custom vision processing systems:<br><br><strong>Design Principles:</strong><br>• Start simple and add complexity incrementally<br>• Test each stage independently before combining<br>• Use modular design for easy debugging and modification<br>• Plan for error handling and edge cases<br><br><strong>Performance:</strong><br>• Profile your pipeline to identify bottlenecks<br>• Optimize the most time-consuming operations<br>• Use appropriate data structures and algorithms<br>• Monitor memory usage and prevent leaks<br><br><strong>Integration:</strong><br>• Design clear interfaces between pipeline and OpMode<br>• Provide comprehensive result data structures<br>• Include confidence scores and error estimates<br>• Plan for graceful degradation when vision fails"
    },
    {
      "type": "exercise-box",
      "title": "Custom Vision System Development",
      "description": "Create a complete custom vision processing system",
      "tasks": [
        "Design a multi-stage vision pipeline for your specific needs",
        "Implement advanced image processing techniques",
        "Create custom detection algorithms for game elements",
        "Add performance monitoring and optimization",
        "Integrate the pipeline with robot control logic",
        "Test and validate the system in various conditions"
      ],
      "content": "Develop a complete custom vision processing system tailored to your FTC robot's specific requirements. The system should be robust, efficient, and provide reliable detection results for autonomous operation."
    },
    {
      "type": "link-grid",
      "title": "Additional Resources",
      "links": [
        "<a href=\"https://opencv.org/\" target=\"_blank\">OpenCV Documentation</a>",
        "<a href=\"https://ftc-docs.firstinspires.org/en/latest/programming_resources/vision/opencv.html\" target=\"_blank\">FTC OpenCV Integration</a>",
        "<a href=\"https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html\" target=\"_blank\">OpenCV Tutorials</a>",
        "<a href=\"https://gm0.org/en/latest/docs/software/tutorials/opencv.html\" target=\"_blank\">gm0: OpenCV Tutorial</a>"
      ]
    }
  ]
}
