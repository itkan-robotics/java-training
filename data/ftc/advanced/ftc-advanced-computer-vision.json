{
  "title": "Advanced Computer Vision",
  "sections": [
    {
      "type": "text",
      "title": "Advanced Vision Processing",
      "content": "Advanced computer vision introduces sophisticated image processing techniques, multi-target detection, and complex vision-based autonomous strategies for competition-level robotics."
    },
    {
      "type": "rules-box",
      "title": "Advanced Features",
      "items": [
        "<strong>Multi-Target Detection:</strong> Detect and track multiple objects simultaneously",
        "<strong>Advanced Filtering:</strong> Sophisticated image processing and noise reduction",
        "<strong>3D Localization:</strong> Determine object positions in 3D space",
        "<strong>Dynamic Calibration:</strong> Real-time camera calibration and adjustment",
        "<strong>Vision-Based Navigation:</strong> Use vision for autonomous navigation",
        "<strong>Competition Vision Strategies:</strong> Vision optimized for game objectives"
      ],
      "subtitle": "Advanced computer vision includes:"
    },
    {
      "type": "text",
      "title": "Multi-Target Detection System",
      "content": "Advanced multi-target detection allows robots to identify and track multiple objects simultaneously for complex autonomous behaviors."
    },
    {
      "type": "code",
      "title": "Advanced Multi-Target Detector",
      "content": "package org.firstinspires.ftc.teamcode.vision.advanced;\n\nimport org.firstinspires.ftc.robotcore.external.tfod.TFObjectDetection;\nimport org.firstinspires.ftc.robotcore.external.tfod.Recognition;\nimport org.firstinspires.ftc.teamcode.vision.VisionProcessor;\nimport org.opencv.core.*;\nimport org.opencv.imgproc.Imgproc;\nimport java.util.*;\nimport java.util.concurrent.ConcurrentHashMap;\n\npublic class AdvancedMultiTargetDetector {\n    \n    private VisionProcessor visionProcessor;\n    private Map<String, TargetTracker> targetTrackers;\n    private List<DetectionFilter> filters;\n    private CameraCalibration calibration;\n    private DetectionConfig config;\n    \n    public AdvancedMultiTargetDetector(VisionProcessor visionProcessor) {\n        this.visionProcessor = visionProcessor;\n        this.targetTrackers = new ConcurrentHashMap<>();\n        this.filters = new ArrayList<>();\n        this.calibration = new CameraCalibration();\n        this.config = new DetectionConfig();\n        \n        initializeFilters();\n    }\n    \n    public List<DetectedTarget> detectAllTargets() {\n        List<DetectedTarget> allTargets = new ArrayList<>();\n        \n        // Detect AprilTags\n        List<DetectedTarget> aprilTags = detectAprilTags();\n        allTargets.addAll(aprilTags);\n        \n        // Detect TensorFlow objects\n        List<DetectedTarget> tfObjects = detectTensorFlowObjects();\n        allTargets.addAll(tfObjects);\n        \n        // Detect custom objects\n        List<DetectedTarget> customObjects = detectCustomObjects();\n        allTargets.addAll(customObjects);\n        \n        // Apply filters\n        List<DetectedTarget> filteredTargets = applyFilters(allTargets);\n        \n        // Update trackers\n        updateTrackers(filteredTargets);\n        \n        return filteredTargets;\n    }\n    \n    public DetectedTarget getBestTarget(String targetType, TargetPriority priority) {\n        List<DetectedTarget> targets = getTargetsByType(targetType);\n        \n        if (targets.isEmpty()) {\n            return null;\n        }\n        \n        // Sort by priority\n        switch (priority) {\n            case CLOSEST:\n                targets.sort((a, b) -> Double.compare(a.getDistance(), b.getDistance()));\n                break;\n            case LARGEST:\n                targets.sort((a, b) -> Double.compare(b.getArea(), a.getArea()));\n                break;\n            case MOST_CENTERED:\n                targets.sort((a, b) -> Double.compare(a.getCenterOffset(), b.getCenterOffset()));\n                break;\n            case HIGHEST_CONFIDENCE:\n                targets.sort((a, b) -> Double.compare(b.getConfidence(), a.getConfidence()));\n                break;\n        }\n        \n        return targets.get(0);\n    }\n    \n    public List<DetectedTarget> getTargetsByType(String targetType) {\n        List<DetectedTarget> targets = new ArrayList<>();\n        \n        for (TargetTracker tracker : targetTrackers.values()) {\n            DetectedTarget target = tracker.getCurrentTarget();\n            if (target != null && target.getType().equals(targetType)) {\n                targets.add(target);\n            }\n        }\n        \n        return targets;\n    }\n    \n    public boolean isTargetVisible(String targetId) {\n        TargetTracker tracker = targetTrackers.get(targetId);\n        return tracker != null && tracker.isTargetVisible();\n    }\n    \n    public DetectedTarget getTargetById(String targetId) {\n        TargetTracker tracker = targetTrackers.get(targetId);\n        return tracker != null ? tracker.getCurrentTarget() : null;\n    }\n    \n    private List<DetectedTarget> detectAprilTags() {\n        List<DetectedTarget> aprilTags = new ArrayList<>();\n        \n        // Get AprilTag detections from vision processor\n        List<AprilTagDetection> detections = visionProcessor.getAprilTagDetections();\n        \n        for (AprilTagDetection detection : detections) {\n            if (detection.confidence > config.getMinConfidence()) {\n                DetectedTarget target = new DetectedTarget(\n                    \"APRILTAG\",\n                    detection.id,\n                    detection.centerX,\n                    detection.centerY,\n                    detection.width,\n                    detection.height,\n                    detection.confidence,\n                    detection.ftcPose.x,\n                    detection.ftcPose.y,\n                    detection.ftcPose.z,\n                    detection.ftcPose.yaw,\n                    detection.ftcPose.pitch,\n                    detection.ftcPose.roll\n                );\n                \n                aprilTags.add(target);\n            }\n        }\n        \n        return aprilTags;\n    }\n    \n    private List<DetectedTarget> detectTensorFlowObjects() {\n        List<DetectedTarget> tfObjects = new ArrayList<>();\n        \n        // Get TensorFlow detections\n        List<Recognition> recognitions = visionProcessor.getTensorFlowDetections();\n        \n        for (Recognition recognition : recognitions) {\n            if (recognition.getConfidence() > config.getMinConfidence()) {\n                DetectedTarget target = new DetectedTarget(\n                    \"TENSORFLOW\",\n                    recognition.getLabel(),\n                    recognition.getLeft() + recognition.getWidth() / 2,\n                    recognition.getTop() + recognition.getHeight() / 2,\n                    recognition.getWidth(),\n                    recognition.getHeight(),\n                    recognition.getConfidence(),\n                    0, 0, 0, 0, 0, 0 // No 3D pose for TF objects\n                );\n                \n                tfObjects.add(target);\n            }\n        }\n        \n        return tfObjects;\n    }\n    \n    private List<DetectedTarget> detectCustomObjects() {\n        List<DetectedTarget> customObjects = new ArrayList<>();\n        \n        // Get custom object detections using OpenCV\n        Mat frame = visionProcessor.getCurrentFrame();\n        \n        if (frame != null) {\n            // Detect game elements (cones, cubes, etc.)\n            List<DetectedTarget> gameElements = detectGameElements(frame);\n            customObjects.addAll(gameElements);\n            \n            // Detect field elements\n            List<DetectedTarget> fieldElements = detectFieldElements(frame);\n            customObjects.addAll(fieldElements);\n            \n            // Detect opponents\n            List<DetectedTarget> opponents = detectOpponents(frame);\n            customObjects.addAll(opponents);\n        }\n        \n        return customObjects;\n    }\n    \n    private List<DetectedTarget> detectGameElements(Mat frame) {\n        List<DetectedTarget> gameElements = new ArrayList<>();\n        \n        // Convert to HSV for color detection\n        Mat hsv = new Mat();\n        Imgproc.cvtColor(frame, hsv, Imgproc.COLOR_RGB2HSV);\n        \n        // Detect different colored game elements\n        for (GameElementType elementType : GameElementType.values()) {\n            Mat mask = createColorMask(hsv, elementType.getColorRange());\n            List<MatOfPoint> contours = findContours(mask);\n            \n            for (MatOfPoint contour : contours) {\n                if (isValidGameElement(contour, elementType)) {\n                    Rect boundingRect = Imgproc.boundingRect(contour);\n                    \n                    DetectedTarget target = new DetectedTarget(\n                        \"GAME_ELEMENT\",\n                        elementType.name(),\n                        boundingRect.x + boundingRect.width / 2,\n                        boundingRect.y + boundingRect.height / 2,\n                        boundingRect.width,\n                        boundingRect.height,\n                        0.8, // Estimated confidence\n                        0, 0, 0, 0, 0, 0\n                    );\n                    \n                    gameElements.add(target);\n                }\n            }\n        }\n        \n        return gameElements;\n    }\n    \n    private List<DetectedTarget> detectFieldElements(Mat frame) {\n        List<DetectedTarget> fieldElements = new ArrayList<>();\n        \n        // Detect field boundaries, scoring areas, etc.\n        // This would use edge detection and shape recognition\n        \n        return fieldElements;\n    }\n    \n    private List<DetectedTarget> detectOpponents(Mat frame) {\n        List<DetectedTarget> opponents = new ArrayList<>();\n        \n        // Detect opponent robots using motion detection or specific markers\n        // This could use background subtraction or specific robot detection\n        \n        return opponents;\n    }\n    \n    private List<DetectedTarget> applyFilters(List<DetectedTarget> targets) {\n        List<DetectedTarget> filteredTargets = new ArrayList<>(targets);\n        \n        for (DetectionFilter filter : filters) {\n            filteredTargets = filter.apply(filteredTargets);\n        }\n        \n        return filteredTargets;\n    }\n    \n    private void updateTrackers(List<DetectedTarget> targets) {\n        // Update existing trackers\n        for (TargetTracker tracker : targetTrackers.values()) {\n            tracker.update(targets);\n        }\n        \n        // Create new trackers for untracked targets\n        for (DetectedTarget target : targets) {\n            String targetId = target.getType() + \"_\" + target.getLabel();\n            if (!targetTrackers.containsKey(targetId)) {\n                targetTrackers.put(targetId, new TargetTracker(targetId));\n            }\n        }\n    }\n    \n    private void initializeFilters() {\n        filters.add(new ConfidenceFilter(config.getMinConfidence()));\n        filters.add(new SizeFilter(config.getMinSize(), config.getMaxSize()));\n        filters.add(new DistanceFilter(config.getMaxDistance()));\n        filters.add(new DuplicateFilter(config.getDuplicateThreshold()));\n    }\n    \n    private Mat createColorMask(Mat hsv, Scalar[] colorRange) {\n        Mat mask = new Mat();\n        Core.inRange(hsv, colorRange[0], colorRange[1], mask);\n        return mask;\n    }\n    \n    private List<MatOfPoint> findContours(Mat mask) {\n        List<MatOfPoint> contours = new ArrayList<>();\n        Mat hierarchy = new Mat();\n        Imgproc.findContours(mask, contours, hierarchy, Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);\n        return contours;\n    }\n    \n    private boolean isValidGameElement(MatOfPoint contour, GameElementType elementType) {\n        double area = Imgproc.contourArea(contour);\n        return area >= elementType.getMinArea() && area <= elementType.getMaxArea();\n    }\n    \n    public enum TargetPriority {\n        CLOSEST, LARGEST, MOST_CENTERED, HIGHEST_CONFIDENCE\n    }\n    \n    public enum GameElementType {\n        CONE_RED(new Scalar[]{new Scalar(0, 100, 100), new Scalar(10, 255, 255)}, 100, 1000),\n        CONE_BLUE(new Scalar[]{new Scalar(100, 100, 100), new Scalar(130, 255, 255)}, 100, 1000),\n        CUBE_RED(new Scalar[]{new Scalar(0, 100, 100), new Scalar(10, 255, 255)}, 200, 2000),\n        CUBE_BLUE(new Scalar[]{new Scalar(100, 100, 100), new Scalar(130, 255, 255)}, 200, 2000);\n        \n        private Scalar[] colorRange;\n        private double minArea, maxArea;\n        \n        GameElementType(Scalar[] colorRange, double minArea, double maxArea) {\n            this.colorRange = colorRange;\n            this.minArea = minArea;\n            this.maxArea = maxArea;\n        }\n        \n        public Scalar[] getColorRange() { return colorRange; }\n        public double getMinArea() { return minArea; }\n        public double getMaxArea() { return maxArea; }\n    }\n}"
    },
    {
      "type": "text",
      "title": "Advanced Vision Filters",
      "content": "Sophisticated filtering techniques to improve detection accuracy and reduce false positives."
    },
    {
      "type": "code",
      "title": "Advanced Vision Filters",
      "content": "package org.firstinspires.ftc.teamcode.vision.filters;\n\nimport org.firstinspires.ftc.teamcode.vision.advanced.DetectedTarget;\nimport java.util.*;\nimport java.util.stream.Collectors;\n\npublic interface DetectionFilter {\n    List<DetectedTarget> apply(List<DetectedTarget> targets);\n}\n\npublic class ConfidenceFilter implements DetectionFilter {\n    private double minConfidence;\n    \n    public ConfidenceFilter(double minConfidence) {\n        this.minConfidence = minConfidence;\n    }\n    \n    @Override\n    public List<DetectedTarget> apply(List<DetectedTarget> targets) {\n        return targets.stream()\n            .filter(target -> target.getConfidence() >= minConfidence)\n            .collect(Collectors.toList());\n    }\n}\n\npublic class SizeFilter implements DetectionFilter {\n    private double minSize, maxSize;\n    \n    public SizeFilter(double minSize, double maxSize) {\n        this.minSize = minSize;\n        this.maxSize = maxSize;\n    }\n    \n    @Override\n    public List<DetectedTarget> apply(List<DetectedTarget> targets) {\n        return targets.stream()\n            .filter(target -> {\n                double size = Math.max(target.getWidth(), target.getHeight());\n                return size >= minSize && size <= maxSize;\n            })\n            .collect(Collectors.toList());\n    }\n}\n\npublic class DistanceFilter implements DetectionFilter {\n    private double maxDistance;\n    \n    public DistanceFilter(double maxDistance) {\n        this.maxDistance = maxDistance;\n    }\n    \n    @Override\n    public List<DetectedTarget> apply(List<DetectedTarget> targets) {\n        return targets.stream()\n            .filter(target -> target.getDistance() <= maxDistance)\n            .collect(Collectors.toList());\n    }\n}\n\npublic class DuplicateFilter implements DetectionFilter {\n    private double threshold;\n    \n    public DuplicateFilter(double threshold) {\n        this.threshold = threshold;\n    }\n    \n    @Override\n    public List<DetectedTarget> apply(List<DetectedTarget> targets) {\n        List<DetectedTarget> filtered = new ArrayList<>();\n        \n        for (DetectedTarget target : targets) {\n            boolean isDuplicate = false;\n            \n            for (DetectedTarget existing : filtered) {\n                if (isDuplicate(target, existing)) {\n                    isDuplicate = true;\n                    // Keep the one with higher confidence\n                    if (target.getConfidence() > existing.getConfidence()) {\n                        filtered.remove(existing);\n                        filtered.add(target);\n                    }\n                    break;\n                }\n            }\n            \n            if (!isDuplicate) {\n                filtered.add(target);\n            }\n        }\n        \n        return filtered;\n    }\n    \n    private boolean isDuplicate(DetectedTarget a, DetectedTarget b) {\n        if (!a.getType().equals(b.getType()) || !a.getLabel().equals(b.getLabel())) {\n            return false;\n        }\n        \n        double distance = Math.sqrt(\n            Math.pow(a.getX() - b.getX(), 2) + \n            Math.pow(a.getY() - b.getY(), 2)\n        );\n        \n        return distance <= threshold;\n    }\n}\n\npublic class TemporalFilter implements DetectionFilter {\n    private Map<String, List<DetectedTarget>> history;\n    private int historySize;\n    private double stabilityThreshold;\n    \n    public TemporalFilter(int historySize, double stabilityThreshold) {\n        this.history = new HashMap<>();\n        this.historySize = historySize;\n        this.stabilityThreshold = stabilityThreshold;\n    }\n    \n    @Override\n    public List<DetectedTarget> apply(List<DetectedTarget> targets) {\n        List<DetectedTarget> filtered = new ArrayList<>();\n        \n        for (DetectedTarget target : targets) {\n            String key = target.getType() + \"_\" + target.getLabel();\n            \n            if (!history.containsKey(key)) {\n                history.put(key, new ArrayList<>());\n            }\n            \n            List<DetectedTarget> targetHistory = history.get(key);\n            targetHistory.add(target);\n            \n            // Keep only recent history\n            if (targetHistory.size() > historySize) {\n                targetHistory.remove(0);\n            }\n            \n            // Check if target is stable over time\n            if (isStable(targetHistory)) {\n                filtered.add(target);\n            }\n        }\n        \n        return filtered;\n    }\n    \n    private boolean isStable(List<DetectedTarget> history) {\n        if (history.size() < 3) {\n            return false;\n        }\n        \n        // Calculate position variance\n        double avgX = history.stream().mapToDouble(DetectedTarget::getX).average().orElse(0);\n        double avgY = history.stream().mapToDouble(DetectedTarget::getY).average().orElse(0);\n        \n        double variance = history.stream()\n            .mapToDouble(target -> \n                Math.pow(target.getX() - avgX, 2) + Math.pow(target.getY() - avgY, 2)\n            )\n            .average()\n            .orElse(0);\n        \n        return variance <= stabilityThreshold;\n    }\n}\n\npublic class RegionFilter implements DetectionFilter {\n    private List<Region> regions;\n    \n    public RegionFilter(List<Region> regions) {\n        this.regions = regions;\n    }\n    \n    @Override\n    public List<DetectedTarget> apply(List<DetectedTarget> targets) {\n        return targets.stream()\n            .filter(target -> {\n                for (Region region : regions) {\n                    if (region.contains(target.getX(), target.getY())) {\n                        return true;\n                    }\n                }\n                return false;\n            })\n            .collect(Collectors.toList());\n    }\n    \n    public static class Region {\n        private double x, y, width, height;\n        \n        public Region(double x, double y, double width, double height) {\n            this.x = x;\n            this.y = y;\n            this.width = width;\n            this.height = height;\n        }\n        \n        public boolean contains(double targetX, double targetY) {\n            return targetX >= x && targetX <= x + width && \n                   targetY >= y && targetY <= y + height;\n        }\n    }\n}"
    },
    {
      "type": "text",
      "title": "3D Localization",
      "content": "Advanced 3D localization techniques to determine precise object positions in 3D space."
    },
    {
      "type": "code",
      "title": "3D Localization System",
      "content": "package org.firstinspires.ftc.teamcode.vision.localization;\n\nimport org.firstinspires.ftc.teamcode.vision.advanced.DetectedTarget;\nimport org.opencv.core.*;\nimport org.opencv.calib3d.Calib3d;\nimport java.util.*;\n\npublic class ThreeDLocalization {\n    \n    private CameraCalibration calibration;\n    private Mat cameraMatrix;\n    private Mat distCoeffs;\n    private double cameraHeight;\n    private double cameraAngle;\n    \n    public ThreeDLocalization(CameraCalibration calibration) {\n        this.calibration = calibration;\n        this.cameraMatrix = calibration.getCameraMatrix();\n        this.distCoeffs = calibration.getDistCoeffs();\n        this.cameraHeight = calibration.getCameraHeight();\n        this.cameraAngle = calibration.getCameraAngle();\n    }\n    \n    public DetectedTarget localizeTarget(DetectedTarget target) {\n        if (target.getType().equals(\"APRILTAG\")) {\n            return localizeAprilTag(target);\n        } else {\n            return localizeGenericTarget(target);\n        }\n    }\n    \n    private DetectedTarget localizeAprilTag(DetectedTarget target) {\n        // AprilTags provide 3D pose directly\n        // Just need to transform to robot coordinate system\n        \n        double x = target.getPoseX();\n        double y = target.getPoseY();\n        double z = target.getPoseZ();\n        double yaw = target.getPoseYaw();\n        double pitch = target.getPosePitch();\n        double roll = target.getPoseRoll();\n        \n        // Transform to robot coordinates\n        double robotX = transformToRobotX(x, y, z);\n        double robotY = transformToRobotY(x, y, z);\n        double robotZ = transformToRobotZ(x, y, z);\n        \n        // Create new target with robot coordinates\n        return new DetectedTarget(\n            target.getType(),\n            target.getLabel(),\n            target.getX(),\n            target.getY(),\n            target.getWidth(),\n            target.getHeight(),\n            target.getConfidence(),\n            robotX, robotY, robotZ, yaw, pitch, roll\n        );\n    }\n    \n    private DetectedTarget localizeGenericTarget(DetectedTarget target) {\n        // For generic targets, estimate 3D position using known object size\n        \n        double objectSize = getKnownObjectSize(target.getType(), target.getLabel());\n        if (objectSize <= 0) {\n            return target; // Can't localize without known size\n        }\n        \n        // Calculate distance using object size and apparent size\n        double distance = calculateDistanceFromSize(target, objectSize);\n        \n        // Calculate 3D position\n        double x = calculateXFromPixel(target.getX(), distance);\n        double y = calculateYFromPixel(target.getY(), distance);\n        double z = distance;\n        \n        // Transform to robot coordinates\n        double robotX = transformToRobotX(x, y, z);\n        double robotY = transformToRobotY(x, y, z);\n        double robotZ = transformToRobotZ(x, y, z);\n        \n        return new DetectedTarget(\n            target.getType(),\n            target.getLabel(),\n            target.getX(),\n            target.getY(),\n            target.getWidth(),\n            target.getHeight(),\n            target.getConfidence(),\n            robotX, robotY, robotZ, 0, 0, 0\n        );\n    }\n    \n    private double getKnownObjectSize(String type, String label) {\n        // Known object sizes in inches\n        Map<String, Double> objectSizes = new HashMap<>();\n        objectSizes.put(\"CONE_RED\", 4.0);\n        objectSizes.put(\"CONE_BLUE\", 4.0);\n        objectSizes.put(\"CUBE_RED\", 6.0);\n        objectSizes.put(\"CUBE_BLUE\", 6.0);\n        objectSizes.put(\"GAME_ELEMENT\", 5.0);\n        \n        String key = type + \"_\" + label;\n        return objectSizes.getOrDefault(key, 0.0);\n    }\n    \n    private double calculateDistanceFromSize(DetectedTarget target, double realSize) {\n        // Use apparent size to estimate distance\n        double apparentSize = Math.max(target.getWidth(), target.getHeight());\n        \n        // Simple inverse relationship (more sophisticated methods available)\n        double focalLength = cameraMatrix.get(0, 0)[0]; // Assuming fx = fy\n        return (realSize * focalLength) / apparentSize;\n    }\n    \n    private double calculateXFromPixel(double pixelX, double distance) {\n        // Convert pixel coordinates to world coordinates\n        double focalLength = cameraMatrix.get(0, 0)[0];\n        double principalPointX = cameraMatrix.get(0, 2)[0];\n        \n        return (pixelX - principalPointX) * distance / focalLength;\n    }\n    \n    private double calculateYFromPixel(double pixelY, double distance) {\n        // Convert pixel coordinates to world coordinates\n        double focalLength = cameraMatrix.get(1, 1)[0];\n        double principalPointY = cameraMatrix.get(1, 2)[0];\n        \n        return (pixelY - principalPointY) * distance / focalLength;\n    }\n    \n    private double transformToRobotX(double x, double y, double z) {\n        // Transform from camera coordinates to robot coordinates\n        // This depends on camera mounting position and orientation\n        return x; // Simplified - adjust based on actual mounting\n    }\n    \n    private double transformToRobotY(double x, double y, double z) {\n        // Transform from camera coordinates to robot coordinates\n        return y; // Simplified - adjust based on actual mounting\n    }\n    \n    private double transformToRobotZ(double x, double y, double z) {\n        // Transform from camera coordinates to robot coordinates\n        return z; // Simplified - adjust based on actual mounting\n    }\n    \n    public List<DetectedTarget> localizeAllTargets(List<DetectedTarget> targets) {\n        return targets.stream()\n            .map(this::localizeTarget)\n            .collect(Collectors.toList());\n    }\n    \n    public DetectedTarget getClosestTarget(List<DetectedTarget> targets) {\n        return targets.stream()\n            .min(Comparator.comparingDouble(DetectedTarget::getDistance))\n            .orElse(null);\n    }\n    \n    public DetectedTarget getTargetInDirection(double angle, List<DetectedTarget> targets) {\n        return targets.stream()\n            .filter(target -> Math.abs(target.getPoseYaw() - angle) < Math.PI / 6) // 30 degrees\n            .min(Comparator.comparingDouble(DetectedTarget::getDistance))\n            .orElse(null);\n    }\n}"
    },
    {
      "type": "text",
      "title": "Vision-Based Navigation",
      "content": "Advanced vision-based navigation systems that use computer vision for autonomous movement and positioning."
    },
    {
      "type": "code",
      "title": "Vision-Based Navigation System",
      "content": "package org.firstinspires.ftc.teamcode.vision.navigation;\n\nimport org.firstinspires.ftc.teamcode.vision.advanced.*;\nimport org.firstinspires.ftc.teamcode.subsystems.Drivetrain;\nimport org.firstinspires.ftc.teamcode.subsystems.Odometry;\nimport java.util.*;\n\npublic class VisionBasedNavigation {\n    \n    private AdvancedMultiTargetDetector detector;\n    private ThreeDLocalization localizer;\n    private Drivetrain drivetrain;\n    private Odometry odometry;\n    private NavigationConfig config;\n    \n    public VisionBasedNavigation(AdvancedMultiTargetDetector detector, \n                               ThreeDLocalization localizer,\n                               Drivetrain drivetrain,\n                               Odometry odometry) {\n        this.detector = detector;\n        this.localizer = localizer;\n        this.drivetrain = drivetrain;\n        this.odometry = odometry;\n        this.config = new NavigationConfig();\n    }\n    \n    public boolean navigateToTarget(String targetType, String targetLabel) {\n        DetectedTarget target = detector.getBestTarget(targetType, \n            AdvancedMultiTargetDetector.TargetPriority.CLOSEST);\n        \n        if (target == null || !target.getLabel().equals(targetLabel)) {\n            return false;\n        }\n        \n        return navigateToPosition(target.getPoseX(), target.getPoseY(), target.getPoseYaw());\n    }\n    \n    public boolean navigateToPosition(double targetX, double targetY, double targetHeading) {\n        double currentX = odometry.getX();\n        double currentY = odometry.getY();\n        double currentHeading = odometry.getHeading();\n        \n        // Calculate path to target\n        double distance = Math.sqrt(Math.pow(targetX - currentX, 2) + Math.pow(targetY - currentY, 2));\n        double angle = Math.atan2(targetY - currentY, targetX - currentX);\n        double headingError = angle - currentHeading;\n        \n        // Normalize heading error\n        while (headingError > Math.PI) headingError -= 2 * Math.PI;\n        while (headingError < -Math.PI) headingError += 2 * Math.PI;\n        \n        // Check if we're close enough\n        if (distance < config.getPositionTolerance()) {\n            // Just need to turn to final heading\n            if (Math.abs(headingError) > config.getHeadingTolerance()) {\n                turnToHeading(targetHeading);\n            }\n            return true;\n        }\n        \n        // Move towards target\n        if (Math.abs(headingError) > config.getHeadingTolerance()) {\n            // Turn first\n            turnToHeading(angle);\n        } else {\n            // Move forward\n            moveForward(distance);\n        }\n        \n        return false; // Not yet at target\n    }\n    \n    public boolean followTarget(String targetType, double desiredDistance) {\n        DetectedTarget target = detector.getBestTarget(targetType, \n            AdvancedMultiTargetDetector.TargetPriority.CLOSEST);\n        \n        if (target == null) {\n            return false;\n        }\n        \n        double currentDistance = target.getDistance();\n        double distanceError = currentDistance - desiredDistance;\n        \n        if (Math.abs(distanceError) < config.getDistanceTolerance()) {\n            return true; // At desired distance\n        }\n        \n        // Move to maintain desired distance\n        if (distanceError > 0) {\n            // Too far, move closer\n            moveForward(distanceError);\n        } else {\n            // Too close, move away\n            moveBackward(-distanceError);\n        }\n        \n        return false;\n    }\n    \n    public boolean alignWithTarget(String targetType, double desiredAngle) {\n        DetectedTarget target = detector.getBestTarget(targetType, \n            AdvancedMultiTargetDetector.TargetPriority.MOST_CENTERED);\n        \n        if (target == null) {\n            return false;\n        }\n        \n        double currentAngle = target.getPoseYaw();\n        double angleError = currentAngle - desiredAngle;\n        \n        // Normalize angle error\n        while (angleError > Math.PI) angleError -= 2 * Math.PI;\n        while (angleError < -Math.PI) angleError += 2 * Math.PI;\n        \n        if (Math.abs(angleError) < config.getHeadingTolerance()) {\n            return true; // Aligned\n        }\n        \n        // Turn to align\n        turnToHeading(desiredAngle);\n        return false;\n    }\n    \n    public boolean avoidObstacles() {\n        List<DetectedTarget> obstacles = detector.getTargetsByType(\"OBSTACLE\");\n        \n        if (obstacles.isEmpty()) {\n            return true; // No obstacles\n        }\n        \n        // Find closest obstacle\n        DetectedTarget closestObstacle = localizer.getClosestTarget(obstacles);\n        \n        if (closestObstacle.getDistance() < config.getObstacleThreshold()) {\n            // Need to avoid obstacle\n            double avoidAngle = calculateAvoidanceAngle(closestObstacle);\n            turnToHeading(avoidAngle);\n            moveForward(config.getAvoidanceDistance());\n            return false;\n        }\n        \n        return true; // No immediate obstacles\n    }\n    \n    private void turnToHeading(double targetHeading) {\n        double currentHeading = odometry.getHeading();\n        double headingError = targetHeading - currentHeading;\n        \n        // Normalize heading error\n        while (headingError > Math.PI) headingError -= 2 * Math.PI;\n        while (headingError < -Math.PI) headingError += 2 * Math.PI;\n        \n        // Calculate turn speed based on error\n        double turnSpeed = Math.signum(headingError) * \n            Math.min(Math.abs(headingError) * config.getTurnGain(), config.getMaxTurnSpeed());\n        \n        drivetrain.setPower(0, 0, turnSpeed);\n    }\n    \n    private void moveForward(double distance) {\n        double speed = Math.min(distance * config.getMoveGain(), config.getMaxMoveSpeed());\n        drivetrain.setPower(speed, 0, 0);\n    }\n    \n    private void moveBackward(double distance) {\n        double speed = Math.min(distance * config.getMoveGain(), config.getMaxMoveSpeed());\n        drivetrain.setPower(-speed, 0, 0);\n    }\n    \n    private double calculateAvoidanceAngle(DetectedTarget obstacle) {\n        // Calculate angle to move away from obstacle\n        double currentHeading = odometry.getHeading();\n        double obstacleAngle = obstacle.getPoseYaw();\n        \n        // Move perpendicular to obstacle direction\n        return obstacleAngle + Math.PI / 2; // 90 degrees to the right\n    }\n    \n    public static class NavigationConfig {\n        private double positionTolerance = 2.0; // inches\n        private double headingTolerance = Math.PI / 36; // 5 degrees\n        private double distanceTolerance = 3.0; // inches\n        private double obstacleThreshold = 12.0; // inches\n        private double avoidanceDistance = 6.0; // inches\n        private double turnGain = 0.5;\n        private double moveGain = 0.3;\n        private double maxTurnSpeed = 0.5;\n        private double maxMoveSpeed = 0.7;\n        \n        // Getters and setters\n        public double getPositionTolerance() { return positionTolerance; }\n        public void setPositionTolerance(double positionTolerance) { this.positionTolerance = positionTolerance; }\n        \n        public double getHeadingTolerance() { return headingTolerance; }\n        public void setHeadingTolerance(double headingTolerance) { this.headingTolerance = headingTolerance; }\n        \n        public double getDistanceTolerance() { return distanceTolerance; }\n        public void setDistanceTolerance(double distanceTolerance) { this.distanceTolerance = distanceTolerance; }\n        \n        public double getObstacleThreshold() { return obstacleThreshold; }\n        public void setObstacleThreshold(double obstacleThreshold) { this.obstacleThreshold = obstacleThreshold; }\n        \n        public double getAvoidanceDistance() { return avoidanceDistance; }\n        public void setAvoidanceDistance(double avoidanceDistance) { this.avoidanceDistance = avoidanceDistance; }\n        \n        public double getTurnGain() { return turnGain; }\n        public void setTurnGain(double turnGain) { this.turnGain = turnGain; }\n        \n        public double getMoveGain() { return moveGain; }\n        public void setMoveGain(double moveGain) { this.moveGain = moveGain; }\n        \n        public double getMaxTurnSpeed() { return maxTurnSpeed; }\n        public void setMaxTurnSpeed(double maxTurnSpeed) { this.maxTurnSpeed = maxTurnSpeed; }\n        \n        public double getMaxMoveSpeed() { return maxMoveSpeed; }\n        public void setMaxMoveSpeed(double maxMoveSpeed) { this.maxMoveSpeed = maxMoveSpeed; }\n    }\n}"
    },
    {
      "type": "rules-box",
      "title": "Advanced Computer Vision Best Practices",
      "items": [
        "<strong>Use multiple detection methods:</strong> Combine AprilTags, TensorFlow, and custom detection",
        "<strong>Implement robust filtering:</strong> Use temporal and spatial filters to reduce noise",
        "<strong>Calibrate cameras properly:</strong> Ensure accurate 3D localization",
        "<strong>Optimize for performance:</strong> Balance detection accuracy with processing speed",
        "<strong>Test under various conditions:</strong> Ensure vision works in different lighting and environments",
        "<strong>Plan for failure:</strong> Have backup strategies when vision fails"
      ],
      "subtitle": "Follow these best practices for advanced computer vision implementation:"
    },
    {
      "type": "exercise-box",
      "title": "Advanced Computer Vision Practice",
      "description": "Implement advanced computer vision features for competition-level autonomous routines.",
      "tasks": [
        "Create a multi-target detection system",
        "Implement advanced vision filters",
        "Build 3D localization capabilities",
        "Create vision-based navigation",
        "Integrate multiple detection methods",
        "Test vision under various conditions",
        "Optimize vision performance",
        "Create robust vision-based autonomous routines"
      ],
      "code": "// Example: Complete advanced computer vision system\n// 1. Create multi-target detector\n// AdvancedMultiTargetDetector detector = new AdvancedMultiTargetDetector(visionProcessor);\n// \n// 2. Create 3D localizer\n// ThreeDLocalization localizer = new ThreeDLocalization(calibration);\n// \n// 3. Create vision-based navigation\n// VisionBasedNavigation navigation = new VisionBasedNavigation(detector, localizer, drivetrain, odometry);\n// \n// 4. Detect and localize targets\n// List<DetectedTarget> targets = detector.detectAllTargets();\n// List<DetectedTarget> localizedTargets = localizer.localizeAllTargets(targets);\n// \n// 5. Navigate using vision\n// while (opModeIsActive()) {\n//     if (navigation.navigateToTarget(\"APRILTAG\", \"1\")) {\n//         // Reached target\n//         break;\n//     }\n//     navigation.avoidObstacles();\n//     sleep(10);\n// }"
    }
  ]
}