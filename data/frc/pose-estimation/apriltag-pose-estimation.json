{
  "title": "AprilTag Pose Estimation",
  "sections": [
    {
      "type": "text",
      "title": "Introduction to AprilTags",
      "content": "AprilTags are fiducial markers (visual markers with known patterns) used in FRC for robot localization. Each AprilTag has a unique ID and a known position on the FRC field. By detecting AprilTags with a camera, robots can calculate their exact pose on the field with high accuracy.<br><br>AprilTags are part of the standard FRC field design, with tags placed at strategic locations around the field. The field layout documentation specifies the exact position and ID of each tag. This makes AprilTags ideal for pose estimation - they're always in the same locations, are highly detectable, and provide precise pose information.<br><br>Learn more: <a href='https://docs.wpilib.org/en/stable/docs/software/vision/apriltag/apriltag-intro.html' target='_blank'>WPILib: AprilTag Introduction</a>"
    },
    {
      "type": "text",
      "title": "AprilTag System",
      "content": "Understanding how AprilTags work:<br><br><strong>How AprilTags Work:</strong> AprilTags are square markers with a unique black and white pattern. The pattern encodes a unique ID (typically 0-15 or higher). The tag's size is known, allowing the system to calculate distance and angle from the camera.<br><br><strong>Detection Algorithm:</strong> Vision systems use computer vision algorithms to detect AprilTags in camera images. The algorithm finds square patterns, decodes the tag ID, and measures the tag's position and orientation in the image. This information is used to calculate the camera's pose relative to the tag.<br><br><strong>Pose Calculation:</strong> By knowing the tag's field position and measuring where it appears in the camera image, the system calculates the camera's position and orientation. This involves camera calibration (to correct for lens distortion) and geometric calculations (to convert image measurements to 3D pose)."
    },
    {
      "type": "text",
      "title": "FRC Field AprilTags",
      "content": "FRC fields have AprilTags at known locations:<br><br><strong>Field Layout:</strong> Each FRC game specifies AprilTag positions in the field layout documentation. Tags are typically placed at strategic locations (scoring areas, corners, mid-field). The documentation provides exact X, Y, Z coordinates and orientation for each tag.<br><br><strong>Tag IDs:</strong> Each AprilTag has a unique ID that corresponds to its field position. The field layout documentation maps tag IDs to positions. Common tag IDs might be 1-8 or similar, depending on the game design.<br><br><strong>Known Positions:</strong> Tag positions are measured in the field coordinate system. This allows robots to calculate their pose by detecting tags - if the robot sees tag ID 5, and tag 5 is at position (3.0, 2.0, 0.5), the robot can calculate where it must be to see the tag at that angle and distance."
    },
    {
      "type": "text",
      "title": "Camera Setup for AprilTags",
      "content": "Proper camera setup is essential for AprilTag detection:<br><br><strong>Camera Requirements:</strong> Use cameras suitable for AprilTag detection (most USB and network cameras work). Consider resolution (higher = better detection at distance), frame rate (higher = more updates), and field of view (wider = see more tags).<br><br><strong>Mounting:</strong> Mount camera to see AprilTags during robot operation. Consider height (higher = better tag visibility), angle (tilt to see tags at different heights), and position (avoid obstructions). Ensure camera doesn't move relative to robot (affects pose calculation).<br><br><strong>Field of View:</strong> Camera field of view determines which tags are visible. Wider field of view sees more tags but may reduce detection accuracy at distance. Narrow field of view provides better accuracy but sees fewer tags. Balance based on robot's typical operating positions."
    },
    {
      "type": "text",
      "title": "WPILib AprilTag Support",
      "content": "WPILib provides AprilTag integration through vision libraries:<br><br><strong>PhotonVision AprilTag Integration:</strong> PhotonVision is a popular vision library that provides AprilTag detection and pose estimation. It integrates with WPILib robot code and provides easy-to-use APIs. PhotonVision handles tag detection, pose calculation, and provides pose estimates to robot code.<br><br><strong>Pose Estimation:</strong> Vision libraries calculate pose from AprilTag observations. The library detects tags, looks up their field positions, and calculates robot pose. This typically returns a <code>Pose2d</code> or similar pose representation that can be used in robot code.<br><br><strong>Integration:</strong> AprilTag pose estimates can be integrated with odometry for sensor fusion. WPILib's <code>PoseEstimator</code> class can combine AprilTag poses with odometry for highly accurate pose estimation."
    },
    {
      "type": "code-tabs",
      "title": "AprilTag Detection Setup",
      "content": "Setting up AprilTag detection with different vision solutions:",
      "tabs": [
        {
          "label": "PhotonVision",
          "code": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.math.geometry.Transform3d;\nimport org.photonvision.PhotonCamera;\nimport org.photonvision.targeting.PhotonPipelineResult;\nimport org.photonvision.targeting.PhotonTrackedTarget;\nimport java.util.Optional;\n\npublic class AprilTagVision {\n    private final PhotonCamera m_camera;\n    \n    // Camera position relative to robot center (in meters)\n    // Adjust these values based on your camera mounting\n    private static final Transform3d kRobotToCamera = new Transform3d(\n        0.3, 0.0, 0.2,  // X, Y, Z position (meters)\n        new edu.wpi.first.math.geometry.Rotation3d()  // Rotation\n    );\n    \n    public AprilTagVision() {\n        // Initialize PhotonVision camera\n        // Camera name must match the name configured in PhotonVision UI\n        m_camera = new PhotonCamera(\"MainCamera\");\n    }\n    \n    /**\n     * Get pose estimate from AprilTag detection\n     */\n    public Optional<Pose2d> getAprilTagPose() {\n        PhotonPipelineResult result = m_camera.getLatestResult();\n        \n        if (result.hasTargets()) {\n            // Get best target (closest or highest confidence)\n            PhotonTrackedTarget bestTarget = result.getBestTarget();\n            \n            // Check if it's a valid AprilTag (fiducial ID >= 0)\n            if (bestTarget.getFiducialId() >= 0) {\n                // Get pose estimate from PhotonVision\n                var poseEstimate = result.getEstimatedPose();\n                \n                if (poseEstimate.isPresent()) {\n                    // Convert to Pose2d (2D pose)\n                    return Optional.of(poseEstimate.get().toPose2d());\n                }\n            }\n        }\n        \n        return Optional.empty();\n    }\n    \n    /**\n     * Check if AprilTag is detected\n     */\n    public boolean hasAprilTag() {\n        return getAprilTagPose().isPresent();\n    }\n    \n    /**\n     * Get detected AprilTag ID\n     */\n    public Optional<Integer> getDetectedTagId() {\n        PhotonPipelineResult result = m_camera.getLatestResult();\n        \n        if (result.hasTargets()) {\n            PhotonTrackedTarget bestTarget = result.getBestTarget();\n            int fiducialId = bestTarget.getFiducialId();\n            \n            if (fiducialId >= 0) {\n                return Optional.of(fiducialId);\n            }\n        }\n        \n        return Optional.empty();\n    }\n}"
        },
        {
          "label": "Limelight",
          "code": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.math.geometry.Rotation2d;\nimport edu.wpi.first.networktables.NetworkTable;\nimport edu.wpi.first.networktables.NetworkTableInstance;\nimport java.util.Optional;\n\npublic class AprilTagVision {\n    private final NetworkTable m_limelight;\n    \n    public AprilTagVision() {\n        // Get Limelight network table\n        // Use \"limelight\" for default, or your custom table name\n        m_limelight = NetworkTableInstance.getDefault().getTable(\"limelight\");\n    }\n    \n    /**\n     * Get pose estimate from AprilTag detection\n     * Limelight provides robot pose in field coordinates\n     */\n    public Optional<Pose2d> getAprilTagPose() {\n        // Check if Limelight has valid targets\n        double tv = m_limelight.getEntry(\"tv\").getDouble(0);\n        \n        if (tv == 1.0) {  // Valid target detected\n            // Get robot pose from Limelight (in field coordinates)\n            double[] botpose = m_limelight.getEntry(\"botpose\").getDoubleArray(new double[6]);\n            \n            if (botpose.length >= 6) {\n                // botpose: [x, y, z, roll, pitch, yaw]\n                double x = botpose[0];\n                double y = botpose[1];\n                double yaw = botpose[5];  // Yaw is the heading\n                \n                return Optional.of(new Pose2d(x, y, Rotation2d.fromDegrees(yaw)));\n            }\n        }\n        \n        return Optional.empty();\n    }\n    \n    /**\n     * Check if AprilTag is detected\n     */\n    public boolean hasAprilTag() {\n        double tv = m_limelight.getEntry(\"tv\").getDouble(0);\n        return tv == 1.0;\n    }\n    \n    /**\n     * Get detected AprilTag ID\n     */\n    public Optional<Integer> getDetectedTagId() {\n        if (hasAprilTag()) {\n            // Get tid (target ID) from Limelight\n            double tid = m_limelight.getEntry(\"tid\").getDouble(-1);\n            \n            if (tid >= 0) {\n                return Optional.of((int) tid);\n            }\n        }\n        \n        return Optional.empty();\n    }\n}"
        },
        {
          "label": "WPILib (AprilTag)",
          "code": "package frc.robot.subsystems;\n\nimport edu.wpi.first.apriltag.AprilTagFieldLayout;\nimport edu.wpi.first.apriltag.AprilTagFields;\nimport edu.wpi.first.cameraserver.CameraServer;\nimport edu.wpi.first.cscore.UsbCamera;\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.math.geometry.Transform3d;\nimport edu.wpi.first.wpilibj2.command.SubsystemBase;\nimport java.util.Optional;\n\npublic class AprilTagVision extends SubsystemBase {\n    private final UsbCamera m_camera;\n    private final AprilTagFieldLayout m_fieldLayout;\n    \n    // Camera position relative to robot center\n    private static final Transform3d kRobotToCamera = new Transform3d(\n        0.3, 0.0, 0.2,  // X, Y, Z position (meters)\n        new edu.wpi.first.math.geometry.Rotation3d()  // Rotation\n    );\n    \n    public AprilTagVision() {\n        // Start camera server\n        m_camera = CameraServer.startAutomaticCapture(0);\n        m_camera.setResolution(640, 480);\n        m_camera.setFPS(30);\n        \n        // Load field layout (contains AprilTag positions)\n        // This loads the standard FRC field layout for the current year\n        try {\n            m_fieldLayout = AprilTagFieldLayout.loadField(AprilTagFields.kDefaultField);\n        } catch (Exception e) {\n            System.err.println(\"Failed to load AprilTag field layout: \" + e.getMessage());\n            m_fieldLayout = null;\n        }\n        \n        // Note: WPILib's AprilTag support requires additional vision processing\n        // You would typically use PhotonVision or Limelight for actual detection\n        // This example shows the field layout setup\n    }\n    \n    /**\n     * Get pose estimate from AprilTag detection\n     * Note: This is a structure example - actual detection requires\n     * vision processing (PhotonVision, Limelight, or custom pipeline)\n     */\n    public Optional<Pose2d> getAprilTagPose() {\n        // In a real implementation, you would:\n        // 1. Process camera images to detect AprilTags\n        // 2. Get tag ID and pose relative to camera\n        // 3. Look up tag position in field layout\n        // 4. Calculate robot pose from tag pose\n        \n        // For actual implementation, use PhotonVision or Limelight\n        // which handle the vision processing\n        \n        return Optional.empty();\n    }\n    \n    /**\n     * Get field layout (for reference)\n     */\n    public AprilTagFieldLayout getFieldLayout() {\n        return m_fieldLayout;\n    }\n}"
        }
      ]
    },
    {
      "type": "code-tabs",
      "title": "Reading AprilTag Poses",
      "content": "Reading and displaying AprilTag pose estimates:",
      "tabs": [
        {
          "label": "PhotonVision",
          "code": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.wpilibj.smartdashboard.SmartDashboard;\nimport edu.wpi.first.wpilibj2.command.SubsystemBase;\nimport java.util.Optional;\n\npublic class AprilTagPoseReader extends SubsystemBase {\n    private final AprilTagVision m_aprilTagVision;\n    \n    public AprilTagPoseReader(AprilTagVision aprilTagVision) {\n        m_aprilTagVision = aprilTagVision;\n    }\n    \n    @Override\n    public void periodic() {\n        // Get AprilTag pose estimate\n        Optional<Pose2d> aprilTagPose = m_aprilTagVision.getAprilTagPose();\n        \n        if (aprilTagPose.isPresent()) {\n            Pose2d pose = aprilTagPose.get();\n            \n            // Display AprilTag pose on SmartDashboard\n            SmartDashboard.putNumber(\"AprilTag X\", pose.getX());\n            SmartDashboard.putNumber(\"AprilTag Y\", pose.getY());\n            SmartDashboard.putNumber(\"AprilTag Heading\", \n                pose.getRotation().getDegrees());\n            \n            // Get detected tag ID\n            Optional<Integer> tagId = m_aprilTagVision.getDetectedTagId();\n            if (tagId.isPresent()) {\n                SmartDashboard.putNumber(\"Detected AprilTag ID\", tagId.get());\n            }\n            \n            SmartDashboard.putBoolean(\"AprilTag Detected\", true);\n        } else {\n            SmartDashboard.putString(\"AprilTag Pose\", \"Not Available\");\n            SmartDashboard.putBoolean(\"AprilTag Detected\", false);\n        }\n    }\n}"
        },
        {
          "label": "Limelight",
          "code": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.wpilibj.smartdashboard.SmartDashboard;\nimport edu.wpi.first.wpilibj2.command.SubsystemBase;\nimport java.util.Optional;\n\npublic class AprilTagPoseReader extends SubsystemBase {\n    private final AprilTagVision m_aprilTagVision;\n    \n    public AprilTagPoseReader(AprilTagVision aprilTagVision) {\n        m_aprilTagVision = aprilTagVision;\n    }\n    \n    @Override\n    public void periodic() {\n        // Get AprilTag pose estimate\n        Optional<Pose2d> aprilTagPose = m_aprilTagVision.getAprilTagPose();\n        \n        if (aprilTagPose.isPresent()) {\n            Pose2d pose = aprilTagPose.get();\n            \n            // Display AprilTag pose on SmartDashboard\n            SmartDashboard.putNumber(\"AprilTag X\", pose.getX());\n            SmartDashboard.putNumber(\"AprilTag Y\", pose.getY());\n            SmartDashboard.putNumber(\"AprilTag Heading\", \n                pose.getRotation().getDegrees());\n            \n            // Get detected tag ID\n            Optional<Integer> tagId = m_aprilTagVision.getDetectedTagId();\n            if (tagId.isPresent()) {\n                SmartDashboard.putNumber(\"Detected AprilTag ID\", tagId.get());\n            }\n            \n            SmartDashboard.putBoolean(\"AprilTag Detected\", true);\n        } else {\n            SmartDashboard.putString(\"AprilTag Pose\", \"Not Available\");\n            SmartDashboard.putBoolean(\"AprilTag Detected\", false);\n        }\n    }\n}"
        },
        {
          "label": "WPILib",
          "code": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.wpilibj.smartdashboard.SmartDashboard;\nimport edu.wpi.first.wpilibj2.command.SubsystemBase;\nimport java.util.Optional;\n\npublic class AprilTagPoseReader extends SubsystemBase {\n    private final AprilTagVision m_aprilTagVision;\n    \n    public AprilTagPoseReader(AprilTagVision aprilTagVision) {\n        m_aprilTagVision = aprilTagVision;\n    }\n    \n    @Override\n    public void periodic() {\n        // Get AprilTag pose estimate\n        Optional<Pose2d> aprilTagPose = m_aprilTagVision.getAprilTagPose();\n        \n        if (aprilTagPose.isPresent()) {\n            Pose2d pose = aprilTagPose.get();\n            \n            // Display AprilTag pose on SmartDashboard\n            SmartDashboard.putNumber(\"AprilTag X\", pose.getX());\n            SmartDashboard.putNumber(\"AprilTag Y\", pose.getY());\n            SmartDashboard.putNumber(\"AprilTag Heading\", \n                pose.getRotation().getDegrees());\n            \n            SmartDashboard.putBoolean(\"AprilTag Detected\", true);\n        } else {\n            SmartDashboard.putString(\"AprilTag Pose\", \"Not Available\");\n            SmartDashboard.putBoolean(\"AprilTag Detected\", false);\n        }\n    }\n}"
        }
      ]
    },
    {
      "type": "text",
      "title": "AprilTag Pose Calculation",
      "content": "Understanding how pose is calculated from AprilTag observations:<br><br><strong>How Pose is Calculated:</strong> When a camera detects an AprilTag, the vision system measures the tag's position and orientation in the camera image. By knowing the tag's field position (from field layout) and the camera's calibration parameters, the system calculates the camera's pose relative to the tag. This camera pose is then converted to robot pose by accounting for the camera's mounting position relative to the robot center.<br><br><strong>Camera Calibration:</strong> Accurate pose calculation requires camera calibration. Calibration measures camera parameters (focal length, lens distortion, etc.) that are used in pose calculations. Without proper calibration, pose estimates will be inaccurate. Vision libraries typically provide calibration tools.<br><br><strong>Coordinate Transformations:</strong> The system performs several coordinate transformations: image coordinates → camera coordinates → robot coordinates → field coordinates. Each transformation accounts for camera mounting, robot orientation, and field coordinate system."
    },
    {
      "type": "text",
      "title": "Multiple Tag Detection",
      "content": "Using multiple tags improves accuracy:<br><br><strong>Better Accuracy:</strong> Detecting multiple AprilTags simultaneously provides more observations for pose calculation. More observations reduce error and improve accuracy. The vision system can average or weight multiple tag observations.<br><br><strong>Redundancy:</strong> Multiple tags provide redundancy - if one tag is temporarily blocked, others may still be visible. This improves reliability and continuous pose estimation.<br><br><strong>Fusion:</strong> Vision systems can combine observations from multiple tags. This typically involves averaging poses or using weighted combinations based on detection confidence or tag distance. Multiple tags also help validate pose estimates - if multiple tags agree, the estimate is more reliable."
    },
    {
      "type": "code-tabs",
      "title": "Multiple Tag Fusion",
      "content": "Using multiple AprilTag detections for improved accuracy:",
      "tabs": [
        {
          "label": "PhotonVision",
          "code": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.math.geometry.Rotation2d;\nimport org.photonvision.PhotonCamera;\nimport org.photonvision.targeting.PhotonPipelineResult;\nimport org.photonvision.targeting.PhotonTrackedTarget;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Optional;\n\npublic class MultipleTagFusion {\n    private final PhotonCamera m_camera;\n    \n    public MultipleTagFusion() {\n        m_camera = new PhotonCamera(\"MainCamera\");\n    }\n    \n    /**\n     * Get pose estimate from multiple AprilTag detections\n     */\n    public Optional<Pose2d> getFusedAprilTagPose() {\n        PhotonPipelineResult result = m_camera.getLatestResult();\n        \n        if (result.hasTargets()) {\n            List<Pose2d> tagPoses = new ArrayList<>();\n            \n            // Process all detected targets\n            for (PhotonTrackedTarget target : result.getTargets()) {\n                // Check if it's a valid AprilTag\n                if (target.getFiducialId() >= 0) {\n                    // Get pose estimate for this tag\n                    var poseEstimate = result.getEstimatedPose();\n                    \n                    if (poseEstimate.isPresent()) {\n                        tagPoses.add(poseEstimate.get().toPose2d());\n                    }\n                }\n            }\n            \n            // Combine poses if we have multiple\n            if (tagPoses.size() > 0) {\n                if (tagPoses.size() == 1) {\n                    return Optional.of(tagPoses.get(0));\n                } else {\n                    // Average multiple poses\n                    return Optional.of(averagePoses(tagPoses));\n                }\n            }\n        }\n        \n        return Optional.empty();\n    }\n    \n    /**\n     * Average multiple pose estimates\n     * Simple approach - in practice, you might weight by confidence or distance\n     */\n    private Pose2d averagePoses(List<Pose2d> poses) {\n        double avgX = poses.stream().mapToDouble(Pose2d::getX).average().orElse(0.0);\n        double avgY = poses.stream().mapToDouble(Pose2d::getY).average().orElse(0.0);\n        double avgHeading = poses.stream()\n            .mapToDouble(p -> p.getRotation().getDegrees())\n            .average().orElse(0.0);\n        \n        return new Pose2d(avgX, avgY, Rotation2d.fromDegrees(avgHeading));\n    }\n}"
        },
        {
          "label": "Limelight",
          "code": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.math.geometry.Rotation2d;\nimport edu.wpi.first.networktables.NetworkTable;\nimport edu.wpi.first.networktables.NetworkTableInstance;\nimport java.util.Optional;\n\npublic class MultipleTagFusion {\n    private final NetworkTable m_limelight;\n    \n    public MultipleTagFusion() {\n        m_limelight = NetworkTableInstance.getDefault().getTable(\"limelight\");\n    }\n    \n    /**\n     * Get pose estimate from multiple AprilTag detections\n     * Limelight automatically fuses multiple tags when available\n     */\n    public Optional<Pose2d> getFusedAprilTagPose() {\n        // Check if Limelight has valid targets\n        double tv = m_limelight.getEntry(\"tv\").getDouble(0);\n        \n        if (tv == 1.0) {  // Valid target detected\n            // Get robot pose from Limelight (already fused if multiple tags)\n            double[] botpose = m_limelight.getEntry(\"botpose\").getDoubleArray(new double[6]);\n            \n            if (botpose.length >= 6) {\n                // botpose: [x, y, z, roll, pitch, yaw]\n                double x = botpose[0];\n                double y = botpose[1];\n                double yaw = botpose[5];\n                \n                return Optional.of(new Pose2d(x, y, Rotation2d.fromDegrees(yaw)));\n            }\n        }\n        \n        return Optional.empty();\n    }\n    \n    /**\n     * Get number of detected tags\n     */\n    public int getDetectedTagCount() {\n        // Limelight provides tid (target ID) for the primary target\n        // For multiple tags, you may need to use botpose_wpired or botpose_wpiblue\n        // which provide fused poses from multiple tags\n        double tv = m_limelight.getEntry(\"tv\").getDouble(0);\n        return tv == 1.0 ? 1 : 0;  // Limelight shows primary target\n    }\n}"
        },
        {
          "label": "WPILib",
          "code": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.math.geometry.Rotation2d;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Optional;\n\npublic class MultipleTagFusion {\n    private final AprilTagVision m_aprilTagVision;\n    \n    public MultipleTagFusion(AprilTagVision aprilTagVision) {\n        m_aprilTagVision = aprilTagVision;\n    }\n    \n    /**\n     * Get pose estimate from multiple AprilTag detections\n     * Note: This is a structure example - actual implementation\n     * would depend on your vision processing pipeline\n     */\n    public Optional<Pose2d> getFusedAprilTagPose() {\n        // In a real implementation with WPILib's AprilTag support:\n        // 1. Process camera images to detect all AprilTags\n        // 2. For each detected tag, calculate pose\n        // 3. Combine poses (average, weighted average, or filter)\n        \n        // For actual implementation, use PhotonVision or Limelight\n        // which handle multiple tag detection and fusion\n        \n        return Optional.empty();\n    }\n    \n    /**\n     * Average multiple pose estimates\n     */\n    private Pose2d averagePoses(List<Pose2d> poses) {\n        double avgX = poses.stream().mapToDouble(Pose2d::getX).average().orElse(0.0);\n        double avgY = poses.stream().mapToDouble(Pose2d::getY).average().orElse(0.0);\n        double avgHeading = poses.stream()\n            .mapToDouble(p -> p.getRotation().getDegrees())\n            .average().orElse(0.0);\n        \n        return new Pose2d(avgX, avgY, Rotation2d.fromDegrees(avgHeading));\n    }\n}"
        }
      ]
    },
    {
      "type": "code-tabs",
      "title": "AprilTag Pose Integration with Odometry",
      "content": "Integrating AprilTag poses with odometry for sensor fusion:",
      "tabs": [
        {
          "label": "PhotonVision",
          "code": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.wpilibj.Timer;\nimport edu.wpi.first.wpilibj2.command.SubsystemBase;\nimport java.util.Optional;\n\npublic class AprilTagOdometryIntegration extends SubsystemBase {\n    private final AprilTagVision m_aprilTagVision;\n    private final DrivetrainOdometry m_odometry;\n    \n    public AprilTagOdometryIntegration(\n            AprilTagVision aprilTagVision,\n            DrivetrainOdometry odometry) {\n        m_aprilTagVision = aprilTagVision;\n        m_odometry = odometry;\n    }\n    \n    @Override\n    public void periodic() {\n        // Update odometry continuously\n        m_odometry.updateOdometry();\n        \n        // Get AprilTag pose estimate\n        Optional<Pose2d> aprilTagPose = m_aprilTagVision.getAprilTagPose();\n        \n        if (aprilTagPose.isPresent()) {\n            // Simple approach: Reset odometry to AprilTag pose (corrects drift)\n            // This is a simple approach - sensor fusion is more sophisticated\n            m_odometry.resetOdometry(aprilTagPose.get());\n            \n            // In a more sophisticated implementation, you would use\n            // WPILib's PoseEstimator class for sensor fusion (covered in next lesson)\n            // Example:\n            // double timestamp = Timer.getFPGATimestamp();\n            // m_poseEstimator.addVisionMeasurement(aprilTagPose.get(), timestamp);\n        }\n        \n        // Use odometry pose (now corrected by AprilTag when available)\n        Pose2d currentPose = m_odometry.getPose();\n        // Use pose for autonomous navigation, etc.\n    }\n}"
        },
        {
          "label": "Limelight",
          "code": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.wpilibj.Timer;\nimport edu.wpi.first.wpilibj2.command.SubsystemBase;\nimport java.util.Optional;\n\npublic class AprilTagOdometryIntegration extends SubsystemBase {\n    private final AprilTagVision m_aprilTagVision;\n    private final DrivetrainOdometry m_odometry;\n    \n    public AprilTagOdometryIntegration(\n            AprilTagVision aprilTagVision,\n            DrivetrainOdometry odometry) {\n        m_aprilTagVision = aprilTagVision;\n        m_odometry = odometry;\n    }\n    \n    @Override\n    public void periodic() {\n        // Update odometry continuously\n        m_odometry.updateOdometry();\n        \n        // Get AprilTag pose estimate from Limelight\n        Optional<Pose2d> aprilTagPose = m_aprilTagVision.getAprilTagPose();\n        \n        if (aprilTagPose.isPresent()) {\n            // Simple approach: Reset odometry to AprilTag pose (corrects drift)\n            m_odometry.resetOdometry(aprilTagPose.get());\n            \n            // For sensor fusion, use WPILib's PoseEstimator:\n            // double timestamp = Timer.getFPGATimestamp();\n            // m_poseEstimator.addVisionMeasurement(aprilTagPose.get(), timestamp);\n        }\n        \n        // Use odometry pose (now corrected by AprilTag when available)\n        Pose2d currentPose = m_odometry.getPose();\n    }\n}"
        },
        {
          "label": "WPILib",
          "code": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.wpilibj.Timer;\nimport edu.wpi.first.wpilibj2.command.SubsystemBase;\nimport java.util.Optional;\n\npublic class AprilTagOdometryIntegration extends SubsystemBase {\n    private final AprilTagVision m_aprilTagVision;\n    private final DrivetrainOdometry m_odometry;\n    \n    public AprilTagOdometryIntegration(\n            AprilTagVision aprilTagVision,\n            DrivetrainOdometry odometry) {\n        m_aprilTagVision = aprilTagVision;\n        m_odometry = odometry;\n    }\n    \n    @Override\n    public void periodic() {\n        // Update odometry continuously\n        m_odometry.updateOdometry();\n        \n        // Get AprilTag pose estimate\n        Optional<Pose2d> aprilTagPose = m_aprilTagVision.getAprilTagPose();\n        \n        if (aprilTagPose.isPresent()) {\n            // Reset odometry to AprilTag pose (corrects drift)\n            m_odometry.resetOdometry(aprilTagPose.get());\n            \n            // For sensor fusion, use WPILib's PoseEstimator:\n            // double timestamp = Timer.getFPGATimestamp();\n            // m_poseEstimator.addVisionMeasurement(aprilTagPose.get(), timestamp);\n        }\n        \n        // Use odometry pose (now corrected by AprilTag when available)\n        Pose2d currentPose = m_odometry.getPose();\n    }\n}"
        }
      ]
    },
    {
      "type": "link-grid",
      "title": "Documentation Resources",
      "links": [
        {
          "label": "WPILib AprilTag Introduction",
          "url": "https://docs.wpilib.org/en/stable/docs/software/vision/apriltag/apriltag-intro.html"
        },
        {
          "label": "PhotonVision AprilTag",
          "url": "https://docs.photonvision.org/en/latest/docs/apriltag/apriltag-intro.html"
        },
        {
          "label": "WPILib Vision Overview",
          "url": "https://docs.wpilib.org/en/stable/docs/software/vision/index.html"
        }
      ]
    }
  ]
}

