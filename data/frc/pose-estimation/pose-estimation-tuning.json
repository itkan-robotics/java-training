{
  "title": "Pose Estimation Tuning",
  "sections": [
    {
      "type": "text",
      "title": "Introduction to Pose Tuning",
      "content": "Tuning pose estimation systems is essential for achieving accurate robot localization. Even with properly configured sensors, pose estimation requires calibration and tuning to match your specific robot hardware and field conditions. Good tuning ensures your robot knows where it is accurately, enabling reliable autonomous navigation and precise movements.<br><br>Tuning involves calibrating sensor parameters (encoder distances, gyro offsets, camera calibration), optimizing fusion weights, and validating accuracy through testing. The goal is to minimize pose estimation error and ensure consistent, reliable performance across different conditions."
    },
    {
      "type": "rules-box",
      "title": "Tuning Goals",
      "subtitle": "What good pose estimation looks like:",
      "items": [
        "Accuracy (pose estimate matches actual robot position within acceptable tolerance)",
        "Consistency (pose estimate is reliable across multiple runs)",
        "Reliability (works in various conditions - lighting, surfaces, speeds)",
        "Low drift (odometry error accumulates slowly)",
        "Fast convergence (vision corrections are incorporated quickly)",
        "Robust operation (handles sensor noise and temporary failures)",
        "Validated performance (tested and verified through field testing)",
        "Maintainable (easy to re-calibrate when hardware changes)"
      ]
    },
    {
      "type": "text",
      "title": "Odometry Tuning",
      "content": "Odometry requires careful calibration of several parameters:<br><br><strong>Calibrating Wheel Diameters:</strong> Measure actual wheel diameter accurately (use calipers for precision). Wheel diameter directly affects distance calculations - incorrect diameter causes systematic errors. Test by driving a known distance and comparing to odometry reading. Adjust encoder distance per pulse calculation based on measured diameter.<br><br><strong>Track Width:</strong> Measure distance between wheel centers accurately (for differential drive) or module positions (for swerve). Track width affects rotation calculations - incorrect track width causes heading errors. Measure carefully using precise tools. For swerve, measure both track width and wheelbase.<br><br><strong>Encoder Offsets:</strong> Ensure encoders read zero when robot is stationary. Calibrate encoder directions (forward should be positive). Verify encoder counts per revolution match actual encoder specifications. Test encoder readings match actual wheel movement."
    },
    {
      "type": "code",
      "title": "Odometry Calibration Code",
      "content": "package frc.robot.subsystems;\n\nimport edu.wpi.first.wpilibj.Encoder;\nimport edu.wpi.first.wpilibj.smartdashboard.SmartDashboard;\n\npublic class OdometryCalibration {\n    private final Encoder m_leftEncoder;\n    private final Encoder m_rightEncoder;\n    \n    // Measured values (calibrate these)\n    private static final double kMeasuredWheelDiameter = 0.1524;  // 6 inches in meters\n    private static final double kEncoderCPR = 2048.0;\n    private static final double kMeasuredTrackWidth = 0.6;  // meters\n    \n    private static final double kDistancePerPulse = \n        (kMeasuredWheelDiameter * Math.PI) / kEncoderCPR;\n    \n    public OdometryCalibration() {\n        m_leftEncoder = new Encoder(0, 1);\n        m_rightEncoder = new Encoder(2, 3);\n        \n        // Configure encoders with calibrated values\n        m_leftEncoder.setDistancePerPulse(kDistancePerPulse);\n        m_rightEncoder.setDistancePerPulse(kDistancePerPulse);\n        \n        m_leftEncoder.reset();\n        m_rightEncoder.reset();\n    }\n    \n    /**\n     * Calibration test: drive known distance and compare\n     */\n    public void testCalibration(double knownDistanceMeters) {\n        \n        double leftDistance = m_leftEncoder.getDistance();\n        double rightDistance = m_rightEncoder.getDistance();\n        double averageDistance = (leftDistance + rightDistance) / 2.0;\n        \n        double error = Math.abs(averageDistance - knownDistanceMeters);\n        double errorPercent = (error / knownDistanceMeters) * 100.0;\n        \n        SmartDashboard.putNumber(\"Calibration Error (m)\", error);\n        SmartDashboard.putNumber(\"Calibration Error (%)\", errorPercent);\n        \n        // If error is significant, adjust kMeasuredWheelDiameter and recalculate\n        // kDistancePerPulse, then reconfigure encoders\n    }\n}"
    },
    {
      "type": "text",
      "title": "Vision Tuning",
      "content": "Vision systems require calibration and tuning:<br><br><strong>Camera Calibration:</strong> Calibrate camera to correct lens distortion and measure camera parameters. Use calibration tools provided by vision libraries (PhotonVision, etc.). Calibration provides camera matrix and distortion coefficients essential for accurate pose calculation. Re-calibrate if camera is moved or replaced.<br><br><strong>Pose Estimation Accuracy:</strong> Test vision pose accuracy by comparing vision estimates to known robot positions. Place robot at known field positions and compare vision pose to actual position. Adjust camera calibration or mounting if accuracy is poor.<br><br><strong>Tag Detection Settings:</strong> Tune AprilTag detection settings for your camera and lighting conditions. Adjust detection threshold, exposure, and gain settings. Test detection reliability across different lighting conditions. Ensure tags are detected consistently at expected distances."
    },
    {
      "type": "code",
      "title": "Vision Calibration Setup",
      "content": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport java.util.Optional;\n\npublic class VisionCalibration {\n    private VisionPoseEstimation m_vision;\n    \n    /**\n     * Test vision accuracy at known position\n     */\n    public void testVisionAccuracy(Pose2d knownActualPose) {\n        Optional<Pose2d> visionPose = m_vision.getVisionPose();\n        \n        if (visionPose.isPresent()) {\n            Pose2d estimatedPose = visionPose.get();\n            \n            double xError = Math.abs(estimatedPose.getX() - knownActualPose.getX());\n            double yError = Math.abs(estimatedPose.getY() - knownActualPose.getY());\n            double headingError = Math.abs(\n                estimatedPose.getRotation().minus(knownActualPose.getRotation()).getDegrees()\n            );\n            \n            SmartDashboard.putNumber(\"Vision X Error (m)\", xError);\n            SmartDashboard.putNumber(\"Vision Y Error (m)\", yError);\n            SmartDashboard.putNumber(\"Vision Heading Error (deg)\", headingError);\n            \n            // If errors are significant, may need to:\n            // - Re-calibrate camera\n            // - Adjust camera mounting offset\n            // - Verify tag field positions\n        }\n    }\n    \n    /**\n     * Validate vision measurements before using\n     */\n    public boolean isValidVisionMeasurement(Pose2d visionPose, Pose2d currentOdometryPose) {\n        // Check if vision pose is reasonable compared to odometry\n        double distance = visionPose.getTranslation()\n            .getDistance(currentOdometryPose.getTranslation());\n        \n        // Reject if vision pose is too far from odometry (likely bad measurement)\n        // Threshold depends on your system - typically 0.5-1.0 meters\n        double maxReasonableDistance = 1.0;  // meters\n        \n        return distance < maxReasonableDistance;\n    }\n}"
    },
    {
      "type": "text",
      "title": "Fusion Tuning",
      "content": "Sensor fusion requires tuning weights and parameters:<br><br><strong>Weighting Odometry vs Vision:</strong> In WPILib's PoseEstimator, weighting is controlled by standard deviation parameters. Lower standard deviations mean more trust (higher weight). Tune state standard deviations (odometry uncertainty) and vision standard deviations (vision measurement uncertainty) based on your sensor accuracy.<br><br><strong>Update Rates:</strong> Ensure odometry updates every robot loop (50 Hz). Vision updates are asynchronous - add them when available. Fusion handles different rates automatically, but consistent odometry updates are essential.<br><br><strong>Confidence Thresholds:</strong> Set thresholds for accepting vision measurements. Reject low-confidence vision estimates. Validate vision measurements before adding to fusion (check if reasonable compared to current odometry)."
    },
    {
      "type": "code",
      "title": "Pose Validation Testing",
      "content": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.wpilibj.smartdashboard.SmartDashboard;\n\npublic class PoseValidation {\n    private FusedPoseEstimation m_poseEstimation;\n    \n    /**\n     * Test pose accuracy by driving to known positions\n     */\n    public void testPoseAccuracy(Pose2d targetPose, Pose2d actualPose) {\n        Pose2d estimatedPose = m_poseEstimation.getPose();\n        \n        double xError = Math.abs(estimatedPose.getX() - actualPose.getX());\n        double yError = Math.abs(estimatedPose.getY() - actualPose.getY());\n        double headingError = Math.abs(\n            estimatedPose.getRotation().minus(actualPose.getRotation()).getDegrees()\n        );\n        \n        double positionError = estimatedPose.getTranslation()\n            .getDistance(actualPose.getTranslation());\n        \n        SmartDashboard.putNumber(\"Pose X Error (m)\", xError);\n        SmartDashboard.putNumber(\"Pose Y Error (m)\", yError);\n        SmartDashboard.putNumber(\"Pose Heading Error (deg)\", headingError);\n        SmartDashboard.putNumber(\"Pose Position Error (m)\", positionError);\n        \n        // Acceptable tolerances (tune based on your requirements)\n        double maxPositionError = 0.1;  // 10 cm\n        double maxHeadingError = 5.0;   // 5 degrees\n        \n        boolean isAccurate = positionError < maxPositionError && \n                            headingError < maxHeadingError;\n        \n        SmartDashboard.putBoolean(\"Pose Accurate\", isAccurate);\n    }\n    \n    /**\n     * Measure odometry drift over time\n     */\n    public void measureOdometryDrift(Pose2d startingPose) {\n        Pose2d currentPose = m_poseEstimation.getPose();\n        \n        double drift = currentPose.getTranslation()\n            .getDistance(startingPose.getTranslation());\n        \n        SmartDashboard.putNumber(\"Odometry Drift (m)\", drift);\n        \n        // If drift is excessive, may need vision corrections more frequently\n        // or odometry calibration improvements\n    }\n}"
    },
    {
      "type": "code",
      "title": "Tuning Helper Utilities",
      "content": "package frc.robot.subsystems;\n\nimport edu.wpi.first.math.geometry.Pose2d;\nimport edu.wpi.first.wpilibj.smartdashboard.SmartDashboard;\n\npublic class TuningUtilities {\n    private FusedPoseEstimation m_poseEstimation;\n    \n    /**\n     * Display pose estimation diagnostics\n     */\n    public void displayDiagnostics() {\n        Pose2d currentPose = m_poseEstimation.getPose();\n        \n        SmartDashboard.putNumber(\"Pose X\", currentPose.getX());\n        SmartDashboard.putNumber(\"Pose Y\", currentPose.getY());\n        SmartDashboard.putNumber(\"Pose Heading\", \n            currentPose.getRotation().getDegrees());\n        \n        // (encoder distances, gyro heading, vision status, etc.)\n        \n        SmartDashboard.putBoolean(\"Vision Available\", \n            m_poseEstimation.hasVisionPose());\n    }\n    \n    /**\n     * Test pose estimation at multiple known positions\n     */\n    public void comprehensiveTest() {\n        // Test at various field positions\n        Pose2d[] testPositions = {\n            new Pose2d(0.0, 0.0, Rotation2d.fromDegrees(0.0)),\n            new Pose2d(3.0, 0.0, Rotation2d.fromDegrees(0.0)),\n            new Pose2d(0.0, 3.0, Rotation2d.fromDegrees(90.0)),\n            new Pose2d(3.0, 3.0, Rotation2d.fromDegrees(180.0))\n        };\n        \n        // (This would be done manually or with autonomous commands)\n        for (Pose2d testPos : testPositions) {\n            // Log results for analysis\n        }\n    }\n}"
    },
    {
      "type": "text",
      "title": "Validation Methods",
      "content": "Testing pose estimation accuracy is essential:<br><br><strong>Testing Pose Accuracy:</strong> Place robot at known field positions and compare pose estimate to actual position. Measure error in X, Y, and heading. Test at multiple positions across the field. Document acceptable error tolerances for your application.<br><br><strong>Measuring Error:</strong> Calculate position error (distance between estimated and actual position) and heading error (angle difference). Measure error over time to track drift. Test under different conditions (lighting, speeds, surfaces).<br><br><strong>Field Testing:</strong> Test on actual competition field when possible. Field conditions (lighting, surfaces) may differ from practice field. Test autonomous routines that depend on pose estimation. Verify pose accuracy throughout entire autonomous sequences."
    },
    {
      "type": "rules-box",
      "title": "Common Tuning Issues",
      "subtitle": "Troubleshooting pose estimation problems:",
      "items": [
        "Drift: Normal for odometry, use vision to reset periodically, improve odometry calibration",
        "Inaccuracy: Calibrate sensors accurately, verify measurements, check coordinate systems",
        "Conflicts: Tune fusion weights, validate measurements, check for sensor failures",
        "Vision not correcting: Verify vision measurements are valid, check fusion standard deviations",
        "Pose jumps: Validate vision measurements, check for multiple conflicting measurements",
        "Slow convergence: Adjust fusion weights, verify vision update frequency",
        "Inconsistent results: Test across conditions, verify sensor stability, check for environmental factors",
        "Large errors: Re-calibrate sensors, verify field coordinate system, test sensor accuracy"
      ]
    },
    {
      "type": "text",
      "title": "Tuning Tools",
      "content": "Various tools help with pose estimation tuning:<br><br><strong>SmartDashboard Visualization:</strong> Display pose estimates, sensor readings, and errors in real-time. Visualize pose on field coordinate system. Compare estimated vs actual positions. Monitor sensor health and fusion status.<br><br><strong>Logging:</strong> Log pose estimates, sensor readings, and errors for analysis. Review logs to identify patterns and issues. Analyze pose accuracy over time. Compare performance across different runs.<br><br><strong>Analysis Tools:</strong> Use data analysis tools (AdvantageScope, custom tools) to analyze pose estimation performance. Visualize pose trajectories. Calculate error statistics. Identify systematic errors or drift patterns."
    },
    {
      "type": "text",
      "title": "Maintenance",
      "content": "Pose estimation requires ongoing maintenance:<br><br><strong>Re-calibration:</strong> Re-calibrate sensors when hardware changes (new wheels, different encoders, camera moved). Periodic re-calibration ensures accuracy over time. Document calibration dates and values.<br><br><strong>Periodic Checks:</strong> Regularly test pose accuracy to catch drift or degradation. Compare pose estimates to known positions. Monitor for increasing errors that may indicate sensor problems.<br><br><strong>Handling Changes:</strong> When robot hardware changes, update calibration parameters. When field layout changes, update field coordinate system and tag positions. When vision system changes, re-calibrate camera and update mounting offsets."
    },
    {
      "type": "link-grid",
      "title": "Related Topics and Documentation",
      "links": [
        {
          "label": "WPILib Odometry",
          "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/index.html#kinematics-and-odometry"
        },
        {
          "label": "WPILib Pose Estimator",
          "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/state-space/state-space-pose-estimator.html"
        },
        {
          "label": "PhotonVision Calibration",
          "url": "https://docs.photonvision.org/en/latest/docs/getting-started/calibration/calibration.html"
        }
      ]
    }
  ]
}